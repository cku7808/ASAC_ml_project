{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from functools import reduce\n",
    "from glob import glob\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\reot1\\OneDrive\\바탕 화면\\ml2\\web_crawling\\merge_dataset\\raw_merge.csv\n",
      "\n",
      "c:\\Users\\reot1\\OneDrive\\바탕 화면\\ml2\\web_crawling\\merge_dataset\\tag_merge.csv\n"
     ]
    }
   ],
   "source": [
    "pwd = os.getcwd()\n",
    "gp_path = pwd.split('EDA')[0][:-1]\n",
    "raw_path = glob(f'{gp_path}\\\\**\\\\merge_dataset\\\\raw*.csv', recursive=True)[0]\n",
    "tag_path = glob(f'{gp_path}\\\\**\\\\merge_dataset\\\\tag*.csv', recursive=True)[0]\n",
    "\n",
    "print(raw_path, tag_path, sep='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv(raw_path, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Indie, Simulation, Strategy', 'Strategy',\n",
       "       'Action, Adventure, Indie', ...,\n",
       "       'Adventure, Casual, Massively Multiplayer, RPG, Simulation, Strategy',\n",
       "       'Action, Adventure, Free to Play, Indie, Massively Multiplayer, Racing, RPG, Early Access',\n",
       "       'Action, Massively Multiplayer, RPG, Simulation, Early Access'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw['genre'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_set = reduce(lambda x,y : x|y, raw['genre'].apply(lambda x : set(str(x).replace(' ', '').split(','))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(genre_set)\n",
    "\n",
    "genre_dict = {genre : deque([0 for i in range(len(raw))])for genre in genre_set}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw['genre_set'] = raw['genre'].apply(lambda x : set(str(x).replace(' ', '').split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(raw)):\n",
    "    for genre in raw.loc[idx,'genre_set']:\n",
    "        genre_dict[genre][idx] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_dict['appid'] = raw['appid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_df = pd.DataFrame(genre_dict)\n",
    "genre_df = genre_df[genre_df.columns.to_list()[-1:]+ genre_df.columns.to_list()[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "genre 컬럼 TF-IDF\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "b = set()\n",
    "for csv in csv_list[0::2]:\n",
    "    print(os.path.split(csv)[1])\n",
    "    \n",
    "    df = pd.read_csv(csv, sep='\\t')\n",
    "    set(df.loc[0,'genre'].replace(' ','').split(','))\n",
    "    a = reduce(lambda x,y : x | y, df['genre'].apply(lambda x: set(str(x).replace(' ','').split(','))))\n",
    "    print(reduce(lambda x,y : x | y, df['genre'].apply(lambda x: set(str(x).replace(' ','').split(',')))))\n",
    "    print(len(reduce(lambda x,y : x | y, df['genre'].apply(lambda x: set(str(x).replace(' ','').split(','))))))\n",
    "    b |= a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_list[0], sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag_key'] = df['tags'].apply(lambda x:set(eval(x)) if x != '[]' else set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['genre', 'tag_key']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag_list'] = df['tag_key'].apply(lambda x: ', '.join(list(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre'].fillna('',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:,['genre', 'tag_list']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punct_dict = dict((ord(punct),None) for punct in string.punctuation)\n",
    "lemmar = WordNetLemmatizer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "string_punctuation -> 특수문자 사전\n",
    "ord() ascii 코드 반환\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화한 각 단어들의 원형을 리스트로 반환\n",
    "def LemTokens(tokens):\n",
    "    return [lemmar.lemmatize(token) for token in tokens]\n",
    "\n",
    "# 텍스트를 인풋으로 넣고 토큰화시키고 토큰화된 단언들의 원형을 리스트로 반환\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(str(text).lower().translate(remove_punct_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize,\n",
    "                            stop_words='english', ngram_range=(1,2),\n",
    "                            min_df=0.05, max_df =0.85)\n",
    "ftr_vect = tfidf_vect.fit_transform(df['genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMeans: 10\n",
    "km_cluster = KMeans(n_clusters=10, max_iter=10000, random_state=0)\n",
    "km_cluster.fit(ftr_vect)\n",
    "\n",
    "# cluster 및 중심 좌표 정보\n",
    "cluster_label = km_cluster.labels_\n",
    "cluster_centers = km_cluster.cluster_centers_\n",
    "\n",
    "# cluster 라벨 추가\n",
    "df['cluster_label'] = cluster_label\n",
    "df[['genre', 'cluster_label']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['cluster_label']==0][['genre', 'tag_list']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_centers = km_cluster.cluster_centers_\n",
    "\n",
    "print('cluster_centers shape :', cluster_centers.shape)\n",
    "print(cluster_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_details(cluster_model, cluster_data, cluster_nums, \n",
    "                        feature_names, top_n_features=10):\n",
    "    \n",
    "    # 핵심 단어 등 정보를 담을 사전 생성\n",
    "    cluster_details = {}\n",
    "    \n",
    "    # word 피처 중심과의 거리 내림차순 정렬시 값들의 index 반환\n",
    "    center_info = cluster_model.cluster_centers_        # 군집 중심 정보\n",
    "    center_descend_ind = center_info.argsort()[:, ::-1] # 행별(군집별)로 역순 정렬\n",
    "    \n",
    "    # 군집별 정보 담기\n",
    "    for i in range(cluster_nums):\n",
    "        # 군집별 정보를 담을 데이터 초기화\n",
    "        cluster_details[i] = {} # 사전 안에 사전\n",
    "        \n",
    "        # 각 군집에 속하는 파일명\n",
    "        genre = cluster_data[cluster_data[\"cluster_label\"] == i][\"genre\"]\n",
    "        genre = genre.values.tolist()\n",
    "        \n",
    "        # 군집별 중심 정보\n",
    "        top_feature_values = center_info[i, :top_n_features].tolist()\n",
    "\n",
    "        # 군집별 핵심 단어 피처명\n",
    "        top_feature_indexes = center_descend_ind[i, :top_n_features]\n",
    "        top_features = [feature_names[ind] for ind in top_feature_indexes]\n",
    "        \n",
    "        # 각 군집별 정보 사전에 담기\n",
    "        cluster_details[i][\"cluster\"] = i                              # i번째 군집\n",
    "        cluster_details[i][\"top_features\"] = top_features              # 군집별 핵심 단어\n",
    "        cluster_details[i][\"top_feature_values\"] = top_feature_values  # 군집별 중심 정보\n",
    "        cluster_details[i][\"genre\"] = genre                    # 군집 속 파일명\n",
    "        \n",
    "    return cluster_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 객체의 전체 word 명칭\n",
    "feature_names = tfidf_vect.get_feature_names_out()\n",
    "\n",
    "# 함수 적용\n",
    "cluster_details = get_cluster_details(cluster_model=km_cluster, cluster_data=df, cluster_nums=10,\n",
    "                                feature_names=feature_names, top_n_features=10 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_details.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_details[0]['genre']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

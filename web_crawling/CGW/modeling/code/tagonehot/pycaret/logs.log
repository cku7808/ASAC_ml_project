2023-05-24 15:50:38,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 15:50:38,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 15:50:38,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 15:50:38,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 15:50:39,862:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-24 15:52:04,588:INFO:PyCaret ClassificationExperiment
2023-05-24 15:52:04,588:INFO:Logging name: clf-default-name
2023-05-24 15:52:04,588:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 15:52:04,588:INFO:version 3.0.2
2023-05-24 15:52:04,588:INFO:Initializing setup()
2023-05-24 15:52:04,588:INFO:self.USI: cde9
2023-05-24 15:52:04,588:INFO:self._variable_keys: {'pipeline', 'X_test', 'fold_shuffle_param', 'log_plots_param', 'idx', 'y', 'USI', 'n_jobs_param', 'exp_name_log', 'gpu_n_jobs_param', 'X', 'fix_imbalance', 'memory', 'data', 'X_train', 'y_test', 'exp_id', 'is_multiclass', '_ml_usecase', 'target_param', 'gpu_param', '_available_plots', 'y_train', 'fold_generator', 'html_param', 'logging_param', 'seed', 'fold_groups_param'}
2023-05-24 15:52:04,588:INFO:Checking environment
2023-05-24 15:52:04,588:INFO:python_version: 3.10.11
2023-05-24 15:52:04,588:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 15:52:04,588:INFO:machine: AMD64
2023-05-24 15:52:04,588:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 15:52:04,591:INFO:Memory: svmem(total=16889774080, available=8720494592, percent=48.4, used=8169279488, free=8720494592)
2023-05-24 15:52:04,591:INFO:Physical Core: 4
2023-05-24 15:52:04,591:INFO:Logical Core: 8
2023-05-24 15:52:04,591:INFO:Checking libraries
2023-05-24 15:52:04,591:INFO:System:
2023-05-24 15:52:04,591:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 15:52:04,591:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 15:52:04,591:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 15:52:04,591:INFO:PyCaret required dependencies:
2023-05-24 15:52:04,592:INFO:                 pip: 23.0.1
2023-05-24 15:52:04,592:INFO:          setuptools: 66.0.0
2023-05-24 15:52:04,592:INFO:             pycaret: 3.0.2
2023-05-24 15:52:04,592:INFO:             IPython: 8.13.2
2023-05-24 15:52:04,592:INFO:          ipywidgets: 8.0.6
2023-05-24 15:52:04,592:INFO:                tqdm: 4.65.0
2023-05-24 15:52:04,592:INFO:               numpy: 1.23.5
2023-05-24 15:52:04,592:INFO:              pandas: 1.5.3
2023-05-24 15:52:04,592:INFO:              jinja2: 3.1.2
2023-05-24 15:52:04,592:INFO:               scipy: 1.10.1
2023-05-24 15:52:04,592:INFO:              joblib: 1.2.0
2023-05-24 15:52:04,592:INFO:             sklearn: 1.2.2
2023-05-24 15:52:04,592:INFO:                pyod: 1.0.9
2023-05-24 15:52:04,592:INFO:            imblearn: 0.10.1
2023-05-24 15:52:04,592:INFO:   category_encoders: 2.6.1
2023-05-24 15:52:04,592:INFO:            lightgbm: 3.3.5
2023-05-24 15:52:04,592:INFO:               numba: 0.57.0
2023-05-24 15:52:04,593:INFO:            requests: 2.31.0
2023-05-24 15:52:04,593:INFO:          matplotlib: 3.7.1
2023-05-24 15:52:04,593:INFO:          scikitplot: 0.3.7
2023-05-24 15:52:04,593:INFO:         yellowbrick: 1.5
2023-05-24 15:52:04,593:INFO:              plotly: 5.14.1
2023-05-24 15:52:04,593:INFO:             kaleido: 0.2.1
2023-05-24 15:52:04,593:INFO:         statsmodels: 0.14.0
2023-05-24 15:52:04,593:INFO:              sktime: 0.17.0
2023-05-24 15:52:04,593:INFO:               tbats: 1.1.3
2023-05-24 15:52:04,593:INFO:            pmdarima: 2.0.3
2023-05-24 15:52:04,593:INFO:              psutil: 5.9.5
2023-05-24 15:52:04,593:INFO:PyCaret optional dependencies:
2023-05-24 15:52:04,604:INFO:                shap: Not installed
2023-05-24 15:52:04,604:INFO:           interpret: Not installed
2023-05-24 15:52:04,604:INFO:                umap: Not installed
2023-05-24 15:52:04,604:INFO:    pandas_profiling: Not installed
2023-05-24 15:52:04,604:INFO:  explainerdashboard: Not installed
2023-05-24 15:52:04,605:INFO:             autoviz: Not installed
2023-05-24 15:52:04,605:INFO:           fairlearn: Not installed
2023-05-24 15:52:04,605:INFO:             xgboost: Not installed
2023-05-24 15:52:04,605:INFO:            catboost: Not installed
2023-05-24 15:52:04,605:INFO:              kmodes: Not installed
2023-05-24 15:52:04,605:INFO:             mlxtend: Not installed
2023-05-24 15:52:04,605:INFO:       statsforecast: Not installed
2023-05-24 15:52:04,605:INFO:        tune_sklearn: Not installed
2023-05-24 15:52:04,605:INFO:                 ray: Not installed
2023-05-24 15:52:04,605:INFO:            hyperopt: Not installed
2023-05-24 15:52:04,605:INFO:              optuna: Not installed
2023-05-24 15:52:04,605:INFO:               skopt: Not installed
2023-05-24 15:52:04,605:INFO:              mlflow: Not installed
2023-05-24 15:52:04,605:INFO:              gradio: Not installed
2023-05-24 15:52:04,605:INFO:             fastapi: Not installed
2023-05-24 15:52:04,605:INFO:             uvicorn: Not installed
2023-05-24 15:52:04,605:INFO:              m2cgen: Not installed
2023-05-24 15:52:04,605:INFO:           evidently: Not installed
2023-05-24 15:52:04,605:INFO:               fugue: Not installed
2023-05-24 15:52:04,605:INFO:           streamlit: Not installed
2023-05-24 15:52:04,605:INFO:             prophet: Not installed
2023-05-24 15:52:04,606:INFO:None
2023-05-24 15:52:04,606:INFO:Set up data.
2023-05-24 15:52:04,855:INFO:Set up train/test split.
2023-05-24 15:52:04,968:INFO:Set up index.
2023-05-24 15:52:04,971:INFO:Set up folding strategy.
2023-05-24 15:52:04,971:INFO:Assigning column types.
2023-05-24 15:52:05,033:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 15:52:05,071:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 15:52:05,074:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:52:05,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,164:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 15:52:05,165:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:52:05,187:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,188:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,188:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 15:52:05,225:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:52:05,248:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,249:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,287:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:52:05,312:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,313:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,313:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 15:52:05,376:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:05,444:INFO:Preparing preprocessing pipeline...
2023-05-24 15:52:05,453:INFO:Set up label encoding.
2023-05-24 15:52:05,453:INFO:Set up simple imputation.
2023-05-24 15:52:05,461:INFO:Set up column name cleaning.
2023-05-24 15:52:06,150:INFO:Finished creating preprocessing pipeline.
2023-05-24 15:52:06,157:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 15:52:06,157:INFO:Creating final display dataframe.
2023-05-24 15:52:07,470:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                              Review  
2                                          Multiclass  
3   Indifference: 0, Mixed: 1, Negative: 2, Positi...  
4                                        (46252, 507)  
5                                        (46252, 507)  
6                                        (32376, 507)  
7                                        (13876, 507)  
8                                                 506  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               cde9  
2023-05-24 15:52:07,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:07,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:07,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:07,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:52:07,678:INFO:setup() successfully completed in 3.19s...............
2023-05-24 15:54:04,509:INFO:PyCaret ClassificationExperiment
2023-05-24 15:54:04,509:INFO:Logging name: clf-default-name
2023-05-24 15:54:04,509:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 15:54:04,509:INFO:version 3.0.2
2023-05-24 15:54:04,509:INFO:Initializing setup()
2023-05-24 15:54:04,509:INFO:self.USI: c75f
2023-05-24 15:54:04,509:INFO:self._variable_keys: {'pipeline', 'X_test', 'fold_shuffle_param', 'log_plots_param', 'idx', 'y', 'USI', 'n_jobs_param', 'exp_name_log', 'gpu_n_jobs_param', 'X', 'fix_imbalance', 'memory', 'data', 'X_train', 'y_test', 'exp_id', 'is_multiclass', '_ml_usecase', 'target_param', 'gpu_param', '_available_plots', 'y_train', 'fold_generator', 'html_param', 'logging_param', 'seed', 'fold_groups_param'}
2023-05-24 15:54:04,509:INFO:Checking environment
2023-05-24 15:54:04,509:INFO:python_version: 3.10.11
2023-05-24 15:54:04,509:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 15:54:04,509:INFO:machine: AMD64
2023-05-24 15:54:04,509:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 15:54:04,514:INFO:Memory: svmem(total=16889774080, available=8375775232, percent=50.4, used=8513998848, free=8375775232)
2023-05-24 15:54:04,514:INFO:Physical Core: 4
2023-05-24 15:54:04,514:INFO:Logical Core: 8
2023-05-24 15:54:04,514:INFO:Checking libraries
2023-05-24 15:54:04,514:INFO:System:
2023-05-24 15:54:04,514:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 15:54:04,514:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 15:54:04,514:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 15:54:04,514:INFO:PyCaret required dependencies:
2023-05-24 15:54:04,514:INFO:                 pip: 23.0.1
2023-05-24 15:54:04,514:INFO:          setuptools: 66.0.0
2023-05-24 15:54:04,514:INFO:             pycaret: 3.0.2
2023-05-24 15:54:04,514:INFO:             IPython: 8.13.2
2023-05-24 15:54:04,514:INFO:          ipywidgets: 8.0.6
2023-05-24 15:54:04,514:INFO:                tqdm: 4.65.0
2023-05-24 15:54:04,514:INFO:               numpy: 1.23.5
2023-05-24 15:54:04,514:INFO:              pandas: 1.5.3
2023-05-24 15:54:04,514:INFO:              jinja2: 3.1.2
2023-05-24 15:54:04,514:INFO:               scipy: 1.10.1
2023-05-24 15:54:04,514:INFO:              joblib: 1.2.0
2023-05-24 15:54:04,515:INFO:             sklearn: 1.2.2
2023-05-24 15:54:04,515:INFO:                pyod: 1.0.9
2023-05-24 15:54:04,515:INFO:            imblearn: 0.10.1
2023-05-24 15:54:04,515:INFO:   category_encoders: 2.6.1
2023-05-24 15:54:04,515:INFO:            lightgbm: 3.3.5
2023-05-24 15:54:04,515:INFO:               numba: 0.57.0
2023-05-24 15:54:04,515:INFO:            requests: 2.31.0
2023-05-24 15:54:04,515:INFO:          matplotlib: 3.7.1
2023-05-24 15:54:04,515:INFO:          scikitplot: 0.3.7
2023-05-24 15:54:04,515:INFO:         yellowbrick: 1.5
2023-05-24 15:54:04,515:INFO:              plotly: 5.14.1
2023-05-24 15:54:04,515:INFO:             kaleido: 0.2.1
2023-05-24 15:54:04,515:INFO:         statsmodels: 0.14.0
2023-05-24 15:54:04,515:INFO:              sktime: 0.17.0
2023-05-24 15:54:04,515:INFO:               tbats: 1.1.3
2023-05-24 15:54:04,515:INFO:            pmdarima: 2.0.3
2023-05-24 15:54:04,515:INFO:              psutil: 5.9.5
2023-05-24 15:54:04,515:INFO:PyCaret optional dependencies:
2023-05-24 15:54:04,515:INFO:                shap: Not installed
2023-05-24 15:54:04,515:INFO:           interpret: Not installed
2023-05-24 15:54:04,515:INFO:                umap: Not installed
2023-05-24 15:54:04,515:INFO:    pandas_profiling: Not installed
2023-05-24 15:54:04,515:INFO:  explainerdashboard: Not installed
2023-05-24 15:54:04,515:INFO:             autoviz: Not installed
2023-05-24 15:54:04,515:INFO:           fairlearn: Not installed
2023-05-24 15:54:04,515:INFO:             xgboost: Not installed
2023-05-24 15:54:04,516:INFO:            catboost: Not installed
2023-05-24 15:54:04,516:INFO:              kmodes: Not installed
2023-05-24 15:54:04,516:INFO:             mlxtend: Not installed
2023-05-24 15:54:04,516:INFO:       statsforecast: Not installed
2023-05-24 15:54:04,516:INFO:        tune_sklearn: Not installed
2023-05-24 15:54:04,516:INFO:                 ray: Not installed
2023-05-24 15:54:04,516:INFO:            hyperopt: Not installed
2023-05-24 15:54:04,516:INFO:              optuna: Not installed
2023-05-24 15:54:04,516:INFO:               skopt: Not installed
2023-05-24 15:54:04,516:INFO:              mlflow: Not installed
2023-05-24 15:54:04,516:INFO:              gradio: Not installed
2023-05-24 15:54:04,516:INFO:             fastapi: Not installed
2023-05-24 15:54:04,516:INFO:             uvicorn: Not installed
2023-05-24 15:54:04,516:INFO:              m2cgen: Not installed
2023-05-24 15:54:04,516:INFO:           evidently: Not installed
2023-05-24 15:54:04,516:INFO:               fugue: Not installed
2023-05-24 15:54:04,516:INFO:           streamlit: Not installed
2023-05-24 15:54:04,516:INFO:             prophet: Not installed
2023-05-24 15:54:04,516:INFO:None
2023-05-24 15:54:04,516:INFO:Set up data.
2023-05-24 15:54:04,773:INFO:Set up train/test split.
2023-05-24 15:54:04,901:INFO:Set up index.
2023-05-24 15:54:04,905:INFO:Set up folding strategy.
2023-05-24 15:54:04,905:INFO:Assigning column types.
2023-05-24 15:54:04,974:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 15:54:05,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 15:54:05,017:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:54:05,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 15:54:05,083:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:54:05,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,109:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 15:54:05,148:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:54:05,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,209:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:54:05,236:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,236:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 15:54:05,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,300:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:05,390:INFO:Preparing preprocessing pipeline...
2023-05-24 15:54:05,400:INFO:Set up label encoding.
2023-05-24 15:54:05,400:INFO:Set up simple imputation.
2023-05-24 15:54:05,407:INFO:Set up column name cleaning.
2023-05-24 15:54:05,733:INFO:Finished creating preprocessing pipeline.
2023-05-24 15:54:05,748:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 15:54:05,749:INFO:Creating final display dataframe.
2023-05-24 15:54:06,496:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                              Review  
2                                          Multiclass  
3   Indifference: 0, Mixed: 1, Negative: 2, Positi...  
4                                        (46252, 507)  
5                                        (46252, 507)  
6                                        (32376, 507)  
7                                        (13876, 507)  
8                                                 506  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               c75f  
2023-05-24 15:54:06,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:06,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:06,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:06,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:06,683:INFO:setup() successfully completed in 2.25s...............
2023-05-24 15:54:06,957:INFO:PyCaret ClassificationExperiment
2023-05-24 15:54:06,957:INFO:Logging name: clf-default-name
2023-05-24 15:54:06,957:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 15:54:06,957:INFO:version 3.0.2
2023-05-24 15:54:06,957:INFO:Initializing setup()
2023-05-24 15:54:06,957:INFO:self.USI: fd48
2023-05-24 15:54:06,957:INFO:self._variable_keys: {'pipeline', 'X_test', 'fold_shuffle_param', 'log_plots_param', 'idx', 'y', 'USI', 'n_jobs_param', 'exp_name_log', 'gpu_n_jobs_param', 'X', 'fix_imbalance', 'memory', 'data', 'X_train', 'y_test', 'exp_id', 'is_multiclass', '_ml_usecase', 'target_param', 'gpu_param', '_available_plots', 'y_train', 'fold_generator', 'html_param', 'logging_param', 'seed', 'fold_groups_param'}
2023-05-24 15:54:06,958:INFO:Checking environment
2023-05-24 15:54:06,958:INFO:python_version: 3.10.11
2023-05-24 15:54:06,958:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 15:54:06,958:INFO:machine: AMD64
2023-05-24 15:54:06,958:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 15:54:06,961:INFO:Memory: svmem(total=16889774080, available=8344604672, percent=50.6, used=8545169408, free=8344604672)
2023-05-24 15:54:06,961:INFO:Physical Core: 4
2023-05-24 15:54:06,961:INFO:Logical Core: 8
2023-05-24 15:54:06,961:INFO:Checking libraries
2023-05-24 15:54:06,962:INFO:System:
2023-05-24 15:54:06,962:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 15:54:06,962:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 15:54:06,962:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 15:54:06,962:INFO:PyCaret required dependencies:
2023-05-24 15:54:06,962:INFO:                 pip: 23.0.1
2023-05-24 15:54:06,962:INFO:          setuptools: 66.0.0
2023-05-24 15:54:06,962:INFO:             pycaret: 3.0.2
2023-05-24 15:54:06,962:INFO:             IPython: 8.13.2
2023-05-24 15:54:06,962:INFO:          ipywidgets: 8.0.6
2023-05-24 15:54:06,962:INFO:                tqdm: 4.65.0
2023-05-24 15:54:06,962:INFO:               numpy: 1.23.5
2023-05-24 15:54:06,962:INFO:              pandas: 1.5.3
2023-05-24 15:54:06,962:INFO:              jinja2: 3.1.2
2023-05-24 15:54:06,964:INFO:               scipy: 1.10.1
2023-05-24 15:54:06,964:INFO:              joblib: 1.2.0
2023-05-24 15:54:06,964:INFO:             sklearn: 1.2.2
2023-05-24 15:54:06,964:INFO:                pyod: 1.0.9
2023-05-24 15:54:06,964:INFO:            imblearn: 0.10.1
2023-05-24 15:54:06,964:INFO:   category_encoders: 2.6.1
2023-05-24 15:54:06,964:INFO:            lightgbm: 3.3.5
2023-05-24 15:54:06,965:INFO:               numba: 0.57.0
2023-05-24 15:54:06,965:INFO:            requests: 2.31.0
2023-05-24 15:54:06,965:INFO:          matplotlib: 3.7.1
2023-05-24 15:54:06,965:INFO:          scikitplot: 0.3.7
2023-05-24 15:54:06,965:INFO:         yellowbrick: 1.5
2023-05-24 15:54:06,965:INFO:              plotly: 5.14.1
2023-05-24 15:54:06,965:INFO:             kaleido: 0.2.1
2023-05-24 15:54:06,966:INFO:         statsmodels: 0.14.0
2023-05-24 15:54:06,966:INFO:              sktime: 0.17.0
2023-05-24 15:54:06,966:INFO:               tbats: 1.1.3
2023-05-24 15:54:06,966:INFO:            pmdarima: 2.0.3
2023-05-24 15:54:06,966:INFO:              psutil: 5.9.5
2023-05-24 15:54:06,966:INFO:PyCaret optional dependencies:
2023-05-24 15:54:06,967:INFO:                shap: Not installed
2023-05-24 15:54:06,967:INFO:           interpret: Not installed
2023-05-24 15:54:06,967:INFO:                umap: Not installed
2023-05-24 15:54:06,967:INFO:    pandas_profiling: Not installed
2023-05-24 15:54:06,967:INFO:  explainerdashboard: Not installed
2023-05-24 15:54:06,967:INFO:             autoviz: Not installed
2023-05-24 15:54:06,968:INFO:           fairlearn: Not installed
2023-05-24 15:54:06,968:INFO:             xgboost: Not installed
2023-05-24 15:54:06,968:INFO:            catboost: Not installed
2023-05-24 15:54:06,968:INFO:              kmodes: Not installed
2023-05-24 15:54:06,968:INFO:             mlxtend: Not installed
2023-05-24 15:54:06,968:INFO:       statsforecast: Not installed
2023-05-24 15:54:06,968:INFO:        tune_sklearn: Not installed
2023-05-24 15:54:06,969:INFO:                 ray: Not installed
2023-05-24 15:54:06,969:INFO:            hyperopt: Not installed
2023-05-24 15:54:06,969:INFO:              optuna: Not installed
2023-05-24 15:54:06,969:INFO:               skopt: Not installed
2023-05-24 15:54:06,969:INFO:              mlflow: Not installed
2023-05-24 15:54:06,969:INFO:              gradio: Not installed
2023-05-24 15:54:06,969:INFO:             fastapi: Not installed
2023-05-24 15:54:06,970:INFO:             uvicorn: Not installed
2023-05-24 15:54:06,970:INFO:              m2cgen: Not installed
2023-05-24 15:54:06,970:INFO:           evidently: Not installed
2023-05-24 15:54:06,970:INFO:               fugue: Not installed
2023-05-24 15:54:06,970:INFO:           streamlit: Not installed
2023-05-24 15:54:06,970:INFO:             prophet: Not installed
2023-05-24 15:54:06,970:INFO:None
2023-05-24 15:54:06,971:INFO:Set up data.
2023-05-24 15:54:07,314:INFO:Set up train/test split.
2023-05-24 15:54:07,437:INFO:Set up index.
2023-05-24 15:54:07,439:INFO:Set up folding strategy.
2023-05-24 15:54:07,439:INFO:Assigning column types.
2023-05-24 15:54:07,522:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 15:54:07,566:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 15:54:07,567:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:54:07,599:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:07,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:07,644:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 15:54:07,646:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:54:07,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:07,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:07,680:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 15:54:07,747:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:54:07,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:07,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:07,838:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 15:54:07,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:07,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:07,869:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 15:54:07,962:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:07,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:08,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:08,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:08,041:INFO:Preparing preprocessing pipeline...
2023-05-24 15:54:08,049:INFO:Set up label encoding.
2023-05-24 15:54:08,049:INFO:Set up simple imputation.
2023-05-24 15:54:08,055:INFO:Set up column name cleaning.
2023-05-24 15:54:08,366:INFO:Finished creating preprocessing pipeline.
2023-05-24 15:54:08,373:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 15:54:08,373:INFO:Creating final display dataframe.
2023-05-24 15:54:09,122:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                              Review  
2                                          Multiclass  
3   Indifference: 0, Mixed: 1, Negative: 2, Positi...  
4                                        (46252, 507)  
5                                        (46252, 507)  
6                                        (32376, 507)  
7                                        (13876, 507)  
8                                                 506  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               fd48  
2023-05-24 15:54:09,206:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:09,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:09,282:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:09,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 15:54:09,282:INFO:setup() successfully completed in 2.41s...............
2023-05-24 15:54:09,340:INFO:Initializing compare_models()
2023-05-24 15:54:09,340:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-24 15:54:09,340:INFO:Checking exceptions
2023-05-24 15:54:09,404:INFO:Preparing display monitor
2023-05-24 15:54:09,433:INFO:Initializing Logistic Regression
2023-05-24 15:54:09,433:INFO:Total runtime is 0.0 minutes
2023-05-24 15:54:09,443:INFO:SubProcess create_model() called ==================================
2023-05-24 15:54:09,445:INFO:Initializing create_model()
2023-05-24 15:54:09,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 15:54:09,446:INFO:Checking exceptions
2023-05-24 15:54:09,446:INFO:Importing libraries
2023-05-24 15:54:09,446:INFO:Copying training dataset
2023-05-24 15:54:09,584:INFO:Defining folds
2023-05-24 15:54:09,584:INFO:Declaring metric variables
2023-05-24 15:54:09,591:INFO:Importing untrained model
2023-05-24 15:54:09,599:INFO:Logistic Regression Imported successfully
2023-05-24 15:54:09,615:INFO:Starting cross validation
2023-05-24 15:54:09,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 15:54:19,943:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-24 15:56:20,943:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 15:56:21,596:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 15:56:22,198:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:22,230:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:22,255:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:56:22,270:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:22,709:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 15:56:22,770:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 15:56:22,792:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 15:56:22,914:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:22,944:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:22,972:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:23,830:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 15:56:23,869:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:23,874:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:23,895:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:23,902:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:23,904:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:23,921:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:56:23,924:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:56:23,933:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:23,934:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:23,937:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:23,949:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:56:23,962:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:24,857:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:24,898:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:24,913:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:56:24,926:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:25,938:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 15:56:25,962:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 15:56:26,587:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:26,605:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:26,620:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:56:26,627:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:26,738:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:26,759:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:56:26,773:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:56:26,787:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:10,155:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 15:57:10,372:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 15:57:10,527:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:10,542:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:10,554:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:10,747:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:10,759:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:10,773:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:11,017:INFO:Calculating mean and std
2023-05-24 15:57:11,018:INFO:Creating metrics dataframe
2023-05-24 15:57:11,081:INFO:Uploading results into container
2023-05-24 15:57:11,081:INFO:Uploading model into container now
2023-05-24 15:57:11,082:INFO:_master_model_container: 1
2023-05-24 15:57:11,082:INFO:_display_container: 2
2023-05-24 15:57:11,083:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-24 15:57:11,083:INFO:create_model() successfully completed......................................
2023-05-24 15:57:11,156:INFO:SubProcess create_model() end ==================================
2023-05-24 15:57:11,157:INFO:Creating metrics dataframe
2023-05-24 15:57:11,163:INFO:Initializing K Neighbors Classifier
2023-05-24 15:57:11,163:INFO:Total runtime is 3.0288313309351604 minutes
2023-05-24 15:57:11,166:INFO:SubProcess create_model() called ==================================
2023-05-24 15:57:11,166:INFO:Initializing create_model()
2023-05-24 15:57:11,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 15:57:11,167:INFO:Checking exceptions
2023-05-24 15:57:11,167:INFO:Importing libraries
2023-05-24 15:57:11,167:INFO:Copying training dataset
2023-05-24 15:57:11,255:INFO:Defining folds
2023-05-24 15:57:11,255:INFO:Declaring metric variables
2023-05-24 15:57:11,258:INFO:Importing untrained model
2023-05-24 15:57:11,263:INFO:K Neighbors Classifier Imported successfully
2023-05-24 15:57:11,269:INFO:Starting cross validation
2023-05-24 15:57:11,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 15:57:25,478:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:25,507:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:25,535:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:25,793:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:25,822:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:25,855:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:25,878:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:25,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:25,912:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,089:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,118:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,147:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,395:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,439:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,464:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,469:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,491:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,519:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,544:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,586:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,619:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,641:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,678:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:26,699:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:32,301:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:32,315:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:32,328:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:32,330:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:32,341:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:32,358:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:32,541:INFO:Calculating mean and std
2023-05-24 15:57:32,543:INFO:Creating metrics dataframe
2023-05-24 15:57:32,608:INFO:Uploading results into container
2023-05-24 15:57:32,609:INFO:Uploading model into container now
2023-05-24 15:57:32,609:INFO:_master_model_container: 2
2023-05-24 15:57:32,609:INFO:_display_container: 2
2023-05-24 15:57:32,610:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-24 15:57:32,610:INFO:create_model() successfully completed......................................
2023-05-24 15:57:32,682:INFO:SubProcess create_model() end ==================================
2023-05-24 15:57:32,682:INFO:Creating metrics dataframe
2023-05-24 15:57:32,689:INFO:Initializing Naive Bayes
2023-05-24 15:57:32,689:INFO:Total runtime is 3.3875888983408613 minutes
2023-05-24 15:57:32,692:INFO:SubProcess create_model() called ==================================
2023-05-24 15:57:32,692:INFO:Initializing create_model()
2023-05-24 15:57:32,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 15:57:32,693:INFO:Checking exceptions
2023-05-24 15:57:32,693:INFO:Importing libraries
2023-05-24 15:57:32,693:INFO:Copying training dataset
2023-05-24 15:57:32,781:INFO:Defining folds
2023-05-24 15:57:32,781:INFO:Declaring metric variables
2023-05-24 15:57:32,784:INFO:Importing untrained model
2023-05-24 15:57:32,788:INFO:Naive Bayes Imported successfully
2023-05-24 15:57:32,795:INFO:Starting cross validation
2023-05-24 15:57:32,799:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 15:57:35,590:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,623:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,632:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,635:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,661:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,664:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,682:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,688:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,696:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,700:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,706:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,712:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,725:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,731:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,746:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,755:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,766:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,778:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,785:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,795:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,802:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,843:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,867:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:35,898:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:37,236:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:37,243:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:37,248:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:37,256:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:37,263:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:37,270:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:37,491:INFO:Calculating mean and std
2023-05-24 15:57:37,492:INFO:Creating metrics dataframe
2023-05-24 15:57:37,560:INFO:Uploading results into container
2023-05-24 15:57:37,561:INFO:Uploading model into container now
2023-05-24 15:57:37,561:INFO:_master_model_container: 3
2023-05-24 15:57:37,561:INFO:_display_container: 2
2023-05-24 15:57:37,561:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-24 15:57:37,561:INFO:create_model() successfully completed......................................
2023-05-24 15:57:37,637:INFO:SubProcess create_model() end ==================================
2023-05-24 15:57:37,637:INFO:Creating metrics dataframe
2023-05-24 15:57:37,646:INFO:Initializing Decision Tree Classifier
2023-05-24 15:57:37,646:INFO:Total runtime is 3.4702105402946475 minutes
2023-05-24 15:57:37,651:INFO:SubProcess create_model() called ==================================
2023-05-24 15:57:37,651:INFO:Initializing create_model()
2023-05-24 15:57:37,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 15:57:37,651:INFO:Checking exceptions
2023-05-24 15:57:37,651:INFO:Importing libraries
2023-05-24 15:57:37,651:INFO:Copying training dataset
2023-05-24 15:57:37,739:INFO:Defining folds
2023-05-24 15:57:37,739:INFO:Declaring metric variables
2023-05-24 15:57:37,743:INFO:Importing untrained model
2023-05-24 15:57:37,747:INFO:Decision Tree Classifier Imported successfully
2023-05-24 15:57:37,755:INFO:Starting cross validation
2023-05-24 15:57:37,760:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 15:57:45,155:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,183:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,215:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,225:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,227:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,254:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,267:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,279:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,287:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,293:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,304:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,315:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,323:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,351:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,353:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,361:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,392:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,395:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,406:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,451:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,585:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,623:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:45,646:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:48,766:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:48,779:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:48,791:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:48,847:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:48,862:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:48,875:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:49,216:INFO:Calculating mean and std
2023-05-24 15:57:49,217:INFO:Creating metrics dataframe
2023-05-24 15:57:49,283:INFO:Uploading results into container
2023-05-24 15:57:49,283:INFO:Uploading model into container now
2023-05-24 15:57:49,284:INFO:_master_model_container: 4
2023-05-24 15:57:49,284:INFO:_display_container: 2
2023-05-24 15:57:49,284:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-24 15:57:49,284:INFO:create_model() successfully completed......................................
2023-05-24 15:57:49,353:INFO:SubProcess create_model() end ==================================
2023-05-24 15:57:49,353:INFO:Creating metrics dataframe
2023-05-24 15:57:49,362:INFO:Initializing SVM - Linear Kernel
2023-05-24 15:57:49,362:INFO:Total runtime is 3.6654805064201357 minutes
2023-05-24 15:57:49,365:INFO:SubProcess create_model() called ==================================
2023-05-24 15:57:49,365:INFO:Initializing create_model()
2023-05-24 15:57:49,366:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 15:57:49,366:INFO:Checking exceptions
2023-05-24 15:57:49,366:INFO:Importing libraries
2023-05-24 15:57:49,366:INFO:Copying training dataset
2023-05-24 15:57:49,452:INFO:Defining folds
2023-05-24 15:57:49,452:INFO:Declaring metric variables
2023-05-24 15:57:49,456:INFO:Importing untrained model
2023-05-24 15:57:49,460:INFO:SVM - Linear Kernel Imported successfully
2023-05-24 15:57:49,466:INFO:Starting cross validation
2023-05-24 15:57:49,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 15:57:59,231:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 15:57:59,243:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:59,268:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:59,282:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:57:59,295:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:59,824:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 15:57:59,848:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:59,875:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:57:59,904:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:01,330:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 15:58:01,345:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:01,353:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 15:58:01,368:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:01,375:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:01,401:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:01,402:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:01,429:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:01,433:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:01,446:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:01,541:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 15:58:01,571:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:01,607:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:01,622:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:01,639:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:02,323:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 15:58:02,338:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:02,367:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:02,416:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:02,592:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 15:58:02,616:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:02,639:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:02,649:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:02,661:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:04,140:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 15:58:04,146:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:04,158:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:04,164:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:04,171:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:05,613:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 15:58:05,632:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:05,644:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:05,650:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:05,659:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:08,924:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 15:58:08,928:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:08,940:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:08,946:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:08,952:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:09,187:INFO:Calculating mean and std
2023-05-24 15:58:09,189:INFO:Creating metrics dataframe
2023-05-24 15:58:09,262:INFO:Uploading results into container
2023-05-24 15:58:09,262:INFO:Uploading model into container now
2023-05-24 15:58:09,263:INFO:_master_model_container: 5
2023-05-24 15:58:09,263:INFO:_display_container: 2
2023-05-24 15:58:09,263:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-24 15:58:09,263:INFO:create_model() successfully completed......................................
2023-05-24 15:58:09,334:INFO:SubProcess create_model() end ==================================
2023-05-24 15:58:09,334:INFO:Creating metrics dataframe
2023-05-24 15:58:09,345:INFO:Initializing Ridge Classifier
2023-05-24 15:58:09,345:INFO:Total runtime is 3.9985223174095155 minutes
2023-05-24 15:58:09,348:INFO:SubProcess create_model() called ==================================
2023-05-24 15:58:09,348:INFO:Initializing create_model()
2023-05-24 15:58:09,348:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 15:58:09,348:INFO:Checking exceptions
2023-05-24 15:58:09,348:INFO:Importing libraries
2023-05-24 15:58:09,348:INFO:Copying training dataset
2023-05-24 15:58:09,437:INFO:Defining folds
2023-05-24 15:58:09,437:INFO:Declaring metric variables
2023-05-24 15:58:09,440:INFO:Importing untrained model
2023-05-24 15:58:09,445:INFO:Ridge Classifier Imported successfully
2023-05-24 15:58:09,453:INFO:Starting cross validation
2023-05-24 15:58:09,457:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 15:58:12,080:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 15:58:12,093:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,107:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 15:58:12,117:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,118:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,119:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 15:58:12,131:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,132:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:12,146:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,147:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,152:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 15:58:12,156:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,164:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:12,165:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,174:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:12,176:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,186:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,190:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,192:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 15:58:12,199:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 15:58:12,203:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,211:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,213:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:12,221:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 15:58:12,227:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,235:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,236:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,260:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 15:58:12,260:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,271:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,273:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:12,276:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:12,280:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,284:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,286:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,311:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:12,327:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:12,343:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:13,668:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 15:58:13,676:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:13,696:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:13,699:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 15:58:13,704:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:13,705:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:13,710:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:13,717:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:13,725:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 15:58:13,746:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:13,947:INFO:Calculating mean and std
2023-05-24 15:58:13,949:INFO:Creating metrics dataframe
2023-05-24 15:58:14,027:INFO:Uploading results into container
2023-05-24 15:58:14,028:INFO:Uploading model into container now
2023-05-24 15:58:14,028:INFO:_master_model_container: 6
2023-05-24 15:58:14,028:INFO:_display_container: 2
2023-05-24 15:58:14,028:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-24 15:58:14,028:INFO:create_model() successfully completed......................................
2023-05-24 15:58:14,102:INFO:SubProcess create_model() end ==================================
2023-05-24 15:58:14,102:INFO:Creating metrics dataframe
2023-05-24 15:58:14,111:INFO:Initializing Random Forest Classifier
2023-05-24 15:58:14,111:INFO:Total runtime is 4.07796802520752 minutes
2023-05-24 15:58:14,114:INFO:SubProcess create_model() called ==================================
2023-05-24 15:58:14,115:INFO:Initializing create_model()
2023-05-24 15:58:14,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 15:58:14,115:INFO:Checking exceptions
2023-05-24 15:58:14,115:INFO:Importing libraries
2023-05-24 15:58:14,115:INFO:Copying training dataset
2023-05-24 15:58:14,201:INFO:Defining folds
2023-05-24 15:58:14,201:INFO:Declaring metric variables
2023-05-24 15:58:14,205:INFO:Importing untrained model
2023-05-24 15:58:14,209:INFO:Random Forest Classifier Imported successfully
2023-05-24 15:58:14,216:INFO:Starting cross validation
2023-05-24 15:58:14,219:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 15:58:43,707:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 15:58:43,840:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 15:58:45,997:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:46,032:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:46,038:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:46,062:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:46,070:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:46,091:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:46,427:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 15:58:46,459:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 15:58:46,700:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 15:58:46,900:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:46,933:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:46,972:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:46,987:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 15:58:47,166:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,193:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,273:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,298:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,335:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,351:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,376:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,378:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,405:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,515:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,558:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,587:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,673:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,738:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:47,799:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:56,269:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:56,283:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:56,295:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:56,462:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:56,475:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:56,488:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:58:56,733:INFO:Calculating mean and std
2023-05-24 15:58:56,736:INFO:Creating metrics dataframe
2023-05-24 15:58:56,833:INFO:Uploading results into container
2023-05-24 15:58:56,833:INFO:Uploading model into container now
2023-05-24 15:58:56,835:INFO:_master_model_container: 7
2023-05-24 15:58:56,835:INFO:_display_container: 2
2023-05-24 15:58:56,836:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-24 15:58:56,836:INFO:create_model() successfully completed......................................
2023-05-24 15:58:56,919:INFO:SubProcess create_model() end ==================================
2023-05-24 15:58:56,919:INFO:Creating metrics dataframe
2023-05-24 15:58:56,930:INFO:Initializing Quadratic Discriminant Analysis
2023-05-24 15:58:56,930:INFO:Total runtime is 4.791612569491069 minutes
2023-05-24 15:58:56,933:INFO:SubProcess create_model() called ==================================
2023-05-24 15:58:56,934:INFO:Initializing create_model()
2023-05-24 15:58:56,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 15:58:56,934:INFO:Checking exceptions
2023-05-24 15:58:56,934:INFO:Importing libraries
2023-05-24 15:58:56,934:INFO:Copying training dataset
2023-05-24 15:58:57,036:INFO:Defining folds
2023-05-24 15:58:57,036:INFO:Declaring metric variables
2023-05-24 15:58:57,041:INFO:Importing untrained model
2023-05-24 15:58:57,045:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-24 15:58:57,052:INFO:Starting cross validation
2023-05-24 15:58:57,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 15:59:01,409:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 15:59:01,410:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 15:59:01,442:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 15:59:01,472:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 15:59:01,504:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 15:59:01,587:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 15:59:01,606:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 15:59:01,622:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 15:59:07,807:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:07,861:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:07,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,244:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,276:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,310:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,346:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,379:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,390:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,415:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,415:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,421:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,424:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,460:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,466:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,489:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,490:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,491:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,519:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,527:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,532:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,558:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,560:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:08,590:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:10,137:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 15:59:10,404:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 15:59:12,341:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:12,366:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:12,378:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:12,600:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:12,611:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:12,622:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:12,857:INFO:Calculating mean and std
2023-05-24 15:59:12,858:INFO:Creating metrics dataframe
2023-05-24 15:59:12,933:INFO:Uploading results into container
2023-05-24 15:59:12,933:INFO:Uploading model into container now
2023-05-24 15:59:12,934:INFO:_master_model_container: 8
2023-05-24 15:59:12,934:INFO:_display_container: 2
2023-05-24 15:59:12,934:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-24 15:59:12,934:INFO:create_model() successfully completed......................................
2023-05-24 15:59:13,006:INFO:SubProcess create_model() end ==================================
2023-05-24 15:59:13,007:INFO:Creating metrics dataframe
2023-05-24 15:59:13,016:INFO:Initializing Ada Boost Classifier
2023-05-24 15:59:13,017:INFO:Total runtime is 5.05972041686376 minutes
2023-05-24 15:59:13,021:INFO:SubProcess create_model() called ==================================
2023-05-24 15:59:13,021:INFO:Initializing create_model()
2023-05-24 15:59:13,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 15:59:13,021:INFO:Checking exceptions
2023-05-24 15:59:13,021:INFO:Importing libraries
2023-05-24 15:59:13,022:INFO:Copying training dataset
2023-05-24 15:59:13,109:INFO:Defining folds
2023-05-24 15:59:13,109:INFO:Declaring metric variables
2023-05-24 15:59:13,112:INFO:Importing untrained model
2023-05-24 15:59:13,116:INFO:Ada Boost Classifier Imported successfully
2023-05-24 15:59:13,126:INFO:Starting cross validation
2023-05-24 15:59:13,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 15:59:31,698:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:31,726:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:31,790:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,053:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,082:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,109:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,251:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,266:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,285:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,294:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,331:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,338:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,386:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,423:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,454:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,558:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,587:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,613:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,830:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,860:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,912:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,939:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:32,979:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:41,699:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:41,712:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:41,724:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:41,775:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:41,789:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:41,822:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 15:59:41,979:INFO:Calculating mean and std
2023-05-24 15:59:41,982:INFO:Creating metrics dataframe
2023-05-24 15:59:42,082:INFO:Uploading results into container
2023-05-24 15:59:42,083:INFO:Uploading model into container now
2023-05-24 15:59:42,083:INFO:_master_model_container: 9
2023-05-24 15:59:42,083:INFO:_display_container: 2
2023-05-24 15:59:42,085:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-24 15:59:42,085:INFO:create_model() successfully completed......................................
2023-05-24 15:59:42,153:INFO:SubProcess create_model() end ==================================
2023-05-24 15:59:42,154:INFO:Creating metrics dataframe
2023-05-24 15:59:42,165:INFO:Initializing Gradient Boosting Classifier
2023-05-24 15:59:42,165:INFO:Total runtime is 5.545534678300222 minutes
2023-05-24 15:59:42,169:INFO:SubProcess create_model() called ==================================
2023-05-24 15:59:42,170:INFO:Initializing create_model()
2023-05-24 15:59:42,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 15:59:42,170:INFO:Checking exceptions
2023-05-24 15:59:42,170:INFO:Importing libraries
2023-05-24 15:59:42,170:INFO:Copying training dataset
2023-05-24 15:59:42,257:INFO:Defining folds
2023-05-24 15:59:42,257:INFO:Declaring metric variables
2023-05-24 15:59:42,261:INFO:Importing untrained model
2023-05-24 15:59:42,265:INFO:Gradient Boosting Classifier Imported successfully
2023-05-24 15:59:42,273:INFO:Starting cross validation
2023-05-24 15:59:42,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:02:23,733:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:02:23,821:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:23,846:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:23,885:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:24,023:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:02:24,199:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:02:24,373:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:02:24,913:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:02:25,027:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:02:25,283:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:02:25,495:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:02:25,625:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:02:25,755:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:25,781:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:25,819:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:25,986:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:26,012:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:26,038:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:26,048:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:02:26,093:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:02:26,134:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:02:26,268:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:26,294:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:26,319:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:26,469:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:26,499:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:26,528:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:26,958:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:26,982:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:27,002:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:27,767:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:27,771:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:27,786:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:27,788:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:27,802:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:02:27,808:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:03:51,312:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:03:51,324:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:03:51,335:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:03:52,461:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:03:52,471:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:03:52,483:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:03:52,821:INFO:Calculating mean and std
2023-05-24 16:03:52,822:INFO:Creating metrics dataframe
2023-05-24 16:03:52,907:INFO:Uploading results into container
2023-05-24 16:03:52,908:INFO:Uploading model into container now
2023-05-24 16:03:52,908:INFO:_master_model_container: 10
2023-05-24 16:03:52,908:INFO:_display_container: 2
2023-05-24 16:03:52,909:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-24 16:03:52,909:INFO:create_model() successfully completed......................................
2023-05-24 16:03:52,982:INFO:SubProcess create_model() end ==================================
2023-05-24 16:03:52,983:INFO:Creating metrics dataframe
2023-05-24 16:03:52,994:INFO:Initializing Linear Discriminant Analysis
2023-05-24 16:03:52,994:INFO:Total runtime is 9.72601402203242 minutes
2023-05-24 16:03:52,997:INFO:SubProcess create_model() called ==================================
2023-05-24 16:03:52,998:INFO:Initializing create_model()
2023-05-24 16:03:52,998:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:03:52,998:INFO:Checking exceptions
2023-05-24 16:03:52,998:INFO:Importing libraries
2023-05-24 16:03:52,998:INFO:Copying training dataset
2023-05-24 16:03:53,089:INFO:Defining folds
2023-05-24 16:03:53,090:INFO:Declaring metric variables
2023-05-24 16:03:53,094:INFO:Importing untrained model
2023-05-24 16:03:53,099:INFO:Linear Discriminant Analysis Imported successfully
2023-05-24 16:03:53,110:INFO:Starting cross validation
2023-05-24 16:03:53,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:04:06,823:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:06,857:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:06,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,085:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,126:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,127:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,166:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,170:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,200:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,281:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,326:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,372:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,407:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,444:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,444:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,498:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,511:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,541:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,583:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,612:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,620:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,646:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,648:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:07,691:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:12,680:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:12,693:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:12,706:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:12,822:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:12,834:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:12,848:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:04:13,086:INFO:Calculating mean and std
2023-05-24 16:04:13,089:INFO:Creating metrics dataframe
2023-05-24 16:04:13,200:INFO:Uploading results into container
2023-05-24 16:04:13,200:INFO:Uploading model into container now
2023-05-24 16:04:13,201:INFO:_master_model_container: 11
2023-05-24 16:04:13,201:INFO:_display_container: 2
2023-05-24 16:04:13,201:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-24 16:04:13,201:INFO:create_model() successfully completed......................................
2023-05-24 16:04:13,278:INFO:SubProcess create_model() end ==================================
2023-05-24 16:04:13,278:INFO:Creating metrics dataframe
2023-05-24 16:04:13,293:INFO:Initializing Extra Trees Classifier
2023-05-24 16:04:13,294:INFO:Total runtime is 10.064329592386882 minutes
2023-05-24 16:04:13,299:INFO:SubProcess create_model() called ==================================
2023-05-24 16:04:13,299:INFO:Initializing create_model()
2023-05-24 16:04:13,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:04:13,299:INFO:Checking exceptions
2023-05-24 16:04:13,299:INFO:Importing libraries
2023-05-24 16:04:13,299:INFO:Copying training dataset
2023-05-24 16:04:13,390:INFO:Defining folds
2023-05-24 16:04:13,390:INFO:Declaring metric variables
2023-05-24 16:04:13,394:INFO:Importing untrained model
2023-05-24 16:04:13,400:INFO:Extra Trees Classifier Imported successfully
2023-05-24 16:04:13,407:INFO:Starting cross validation
2023-05-24 16:04:13,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:05:01,542:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:05:01,803:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:05:03,637:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:05:04,188:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:04,219:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:04,234:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:04,249:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:04,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:04,285:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:04,460:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:05:04,493:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:05:04,637:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:05:04,716:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:05:04,731:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:05:05,280:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,366:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,383:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,415:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,422:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,427:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,437:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,446:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,456:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,466:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,485:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,541:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,641:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,670:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,679:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,715:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,719:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:05,774:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:19,258:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:19,271:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:19,283:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:19,665:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:19,676:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:19,688:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:19,926:INFO:Calculating mean and std
2023-05-24 16:05:19,927:INFO:Creating metrics dataframe
2023-05-24 16:05:20,012:INFO:Uploading results into container
2023-05-24 16:05:20,013:INFO:Uploading model into container now
2023-05-24 16:05:20,013:INFO:_master_model_container: 12
2023-05-24 16:05:20,013:INFO:_display_container: 2
2023-05-24 16:05:20,014:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-24 16:05:20,014:INFO:create_model() successfully completed......................................
2023-05-24 16:05:20,086:INFO:SubProcess create_model() end ==================================
2023-05-24 16:05:20,086:INFO:Creating metrics dataframe
2023-05-24 16:05:20,098:INFO:Initializing Light Gradient Boosting Machine
2023-05-24 16:05:20,098:INFO:Total runtime is 11.177746947606405 minutes
2023-05-24 16:05:20,101:INFO:SubProcess create_model() called ==================================
2023-05-24 16:05:20,102:INFO:Initializing create_model()
2023-05-24 16:05:20,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:05:20,102:INFO:Checking exceptions
2023-05-24 16:05:20,102:INFO:Importing libraries
2023-05-24 16:05:20,102:INFO:Copying training dataset
2023-05-24 16:05:20,193:INFO:Defining folds
2023-05-24 16:05:20,194:INFO:Declaring metric variables
2023-05-24 16:05:20,198:INFO:Importing untrained model
2023-05-24 16:05:20,203:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 16:05:20,211:INFO:Starting cross validation
2023-05-24 16:05:20,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:05:28,014:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,040:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,084:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,114:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,127:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,139:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,154:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,166:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,170:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,175:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,198:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,224:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,283:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,312:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,337:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,576:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,588:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,606:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,615:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,632:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,637:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,651:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,681:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:28,710:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:32,005:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:32,018:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:32,031:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:32,100:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:32,113:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:32,125:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:32,263:INFO:Calculating mean and std
2023-05-24 16:05:32,264:INFO:Creating metrics dataframe
2023-05-24 16:05:32,348:INFO:Uploading results into container
2023-05-24 16:05:32,349:INFO:Uploading model into container now
2023-05-24 16:05:32,349:INFO:_master_model_container: 13
2023-05-24 16:05:32,350:INFO:_display_container: 2
2023-05-24 16:05:32,350:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 16:05:32,350:INFO:create_model() successfully completed......................................
2023-05-24 16:05:32,426:INFO:SubProcess create_model() end ==================================
2023-05-24 16:05:32,426:INFO:Creating metrics dataframe
2023-05-24 16:05:32,439:INFO:Initializing Dummy Classifier
2023-05-24 16:05:32,439:INFO:Total runtime is 11.38341992298762 minutes
2023-05-24 16:05:32,442:INFO:SubProcess create_model() called ==================================
2023-05-24 16:05:32,444:INFO:Initializing create_model()
2023-05-24 16:05:32,444:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DEA2EBA30>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:05:32,444:INFO:Checking exceptions
2023-05-24 16:05:32,444:INFO:Importing libraries
2023-05-24 16:05:32,444:INFO:Copying training dataset
2023-05-24 16:05:32,539:INFO:Defining folds
2023-05-24 16:05:32,539:INFO:Declaring metric variables
2023-05-24 16:05:32,543:INFO:Importing untrained model
2023-05-24 16:05:32,549:INFO:Dummy Classifier Imported successfully
2023-05-24 16:05:32,556:INFO:Starting cross validation
2023-05-24 16:05:32,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:05:33,801:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:33,826:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:33,832:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:33,849:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:05:33,854:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:33,863:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:33,869:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:05:33,882:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:33,916:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:33,947:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:33,963:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:05:33,990:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,010:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,020:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,035:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,044:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,047:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,051:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,052:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:05:34,079:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,084:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,087:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,090:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,096:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:05:34,099:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:05:34,102:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:05:34,107:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,124:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,126:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,146:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:34,161:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:05:34,172:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:35,172:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:35,190:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:35,201:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:05:35,208:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:35,283:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:35,296:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:35,302:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:05:35,308:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:05:35,456:INFO:Calculating mean and std
2023-05-24 16:05:35,458:INFO:Creating metrics dataframe
2023-05-24 16:05:35,587:INFO:Uploading results into container
2023-05-24 16:05:35,587:INFO:Uploading model into container now
2023-05-24 16:05:35,588:INFO:_master_model_container: 14
2023-05-24 16:05:35,588:INFO:_display_container: 2
2023-05-24 16:05:35,588:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-24 16:05:35,588:INFO:create_model() successfully completed......................................
2023-05-24 16:05:35,662:INFO:SubProcess create_model() end ==================================
2023-05-24 16:05:35,663:INFO:Creating metrics dataframe
2023-05-24 16:05:35,687:INFO:Initializing create_model()
2023-05-24 16:05:35,687:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:05:35,688:INFO:Checking exceptions
2023-05-24 16:05:35,689:INFO:Importing libraries
2023-05-24 16:05:35,690:INFO:Copying training dataset
2023-05-24 16:05:35,784:INFO:Defining folds
2023-05-24 16:05:35,784:INFO:Declaring metric variables
2023-05-24 16:05:35,784:INFO:Importing untrained model
2023-05-24 16:05:35,784:INFO:Declaring custom model
2023-05-24 16:05:35,784:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 16:05:35,787:INFO:Cross validation set to False
2023-05-24 16:05:35,787:INFO:Fitting Model
2023-05-24 16:05:38,394:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 16:05:38,394:INFO:create_model() successfully completed......................................
2023-05-24 16:05:38,495:INFO:_master_model_container: 14
2023-05-24 16:05:38,496:INFO:_display_container: 2
2023-05-24 16:05:38,496:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 16:05:38,496:INFO:compare_models() successfully completed......................................
2023-05-24 16:17:25,855:INFO:Initializing tune_model()
2023-05-24 16:17:25,855:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>)
2023-05-24 16:17:25,855:INFO:Checking exceptions
2023-05-24 16:17:25,913:INFO:Copying training dataset
2023-05-24 16:17:26,007:INFO:Checking base model
2023-05-24 16:17:26,008:INFO:Base model : Light Gradient Boosting Machine
2023-05-24 16:17:26,013:INFO:Declaring metric variables
2023-05-24 16:17:26,016:INFO:Defining Hyperparameters
2023-05-24 16:17:26,121:INFO:Tuning with n_jobs=-1
2023-05-24 16:17:26,121:INFO:Initializing RandomizedSearchCV
2023-05-24 16:17:39,303:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:39,475:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:39,525:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:40,648:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:40,668:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:17:40,796:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:17:40,844:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:40,970:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:40,985:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:17:41,148:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:42,156:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:42,285:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:17:42,436:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:17:42,468:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:17:42,663:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:17:43,547:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:17:48,496:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:49,171:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:49,852:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:17:50,723:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:17:58,093:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:58,350:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:17:59,026:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:03,997:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:04,061:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:05,025:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:05,322:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:05,381:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:05,877:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:05,891:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:06,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:06,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:06,380:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:06,593:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:07,139:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:07,664:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:07,771:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:13,492:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:13,621:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:33,499:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:33,810:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:34,602:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:34,689:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:34,925:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:35,209:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:35,945:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:36,749:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:39,419:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:40,404:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:18:41,631:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:56,481:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:18:56,874:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:12,739:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.02s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:15,237:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:15,933:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:17,024:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:17,103:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:17,276:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:18,669:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:19,179:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:19,451:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:19,616:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:19,773:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:20,474:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:21,576:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:21,841:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:22,791:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:24,404:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:32,359:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:33,682:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:34,730:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:35,070:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:35,576:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:36,235:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:36,660:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:37,154:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:37,925:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:39,196:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:39,529:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:40,854:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:40,884:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:40,983:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:43,144:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:43,288:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:48,178:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:48,255:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:48,615:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:49,628:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:49,787:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:50,761:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:51,255:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:51,513:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:51,626:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:52,034:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:52,396:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:19:52,634:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:53,248:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:19:54,074:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:20:00,325:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2023-05-24 16:20:00,326:INFO:Hyperparameter search completed
2023-05-24 16:20:00,326:INFO:SubProcess create_model() called ==================================
2023-05-24 16:20:00,327:INFO:Initializing create_model()
2023-05-24 16:20:00,327:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020DC48EB490>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2023-05-24 16:20:00,327:INFO:Checking exceptions
2023-05-24 16:20:00,327:INFO:Importing libraries
2023-05-24 16:20:00,327:INFO:Copying training dataset
2023-05-24 16:20:00,446:INFO:Defining folds
2023-05-24 16:20:00,446:INFO:Declaring metric variables
2023-05-24 16:20:00,450:INFO:Importing untrained model
2023-05-24 16:20:00,450:INFO:Declaring custom model
2023-05-24 16:20:00,456:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 16:20:00,465:INFO:Starting cross validation
2023-05-24 16:20:00,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:20:02,941:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:20:03,018:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:20:03,029:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:20:03,023:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:20:03,067:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:20:03,085:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:20:03,129:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:20:03,171:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:20:04,229:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,287:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,340:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,377:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,389:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,400:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,415:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,438:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,452:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,461:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,471:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,480:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,485:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,493:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,510:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,512:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,533:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,544:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,554:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,576:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,576:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,589:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,611:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:04,643:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:06,865:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:06,882:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:06,898:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:06,948:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:06,971:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:06,987:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:07,230:INFO:Calculating mean and std
2023-05-24 16:20:07,232:INFO:Creating metrics dataframe
2023-05-24 16:20:07,238:INFO:Finalizing model
2023-05-24 16:20:10,899:INFO:Uploading results into container
2023-05-24 16:20:10,900:INFO:Uploading model into container now
2023-05-24 16:20:10,901:INFO:_master_model_container: 15
2023-05-24 16:20:10,901:INFO:_display_container: 3
2023-05-24 16:20:10,902:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-05-24 16:20:10,902:INFO:create_model() successfully completed......................................
2023-05-24 16:20:10,994:INFO:SubProcess create_model() end ==================================
2023-05-24 16:20:10,994:INFO:choose_better activated
2023-05-24 16:20:11,000:INFO:SubProcess create_model() called ==================================
2023-05-24 16:20:11,001:INFO:Initializing create_model()
2023-05-24 16:20:11,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:20:11,001:INFO:Checking exceptions
2023-05-24 16:20:11,003:INFO:Importing libraries
2023-05-24 16:20:11,003:INFO:Copying training dataset
2023-05-24 16:20:11,110:INFO:Defining folds
2023-05-24 16:20:11,110:INFO:Declaring metric variables
2023-05-24 16:20:11,110:INFO:Importing untrained model
2023-05-24 16:20:11,112:INFO:Declaring custom model
2023-05-24 16:20:11,112:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 16:20:11,112:INFO:Starting cross validation
2023-05-24 16:20:11,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:20:12,710:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:12,733:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:12,756:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:12,765:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:12,786:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:12,793:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:12,811:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:12,821:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:12,836:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:12,972:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,012:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,016:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,017:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,036:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,042:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,049:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,065:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,072:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,088:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,102:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,110:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,128:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,152:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:13,155:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:14,609:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:14,621:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:14,623:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:14,634:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:14,637:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:14,650:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:20:14,923:INFO:Calculating mean and std
2023-05-24 16:20:14,924:INFO:Creating metrics dataframe
2023-05-24 16:20:14,926:INFO:Finalizing model
2023-05-24 16:20:15,422:INFO:Uploading results into container
2023-05-24 16:20:15,422:INFO:Uploading model into container now
2023-05-24 16:20:15,422:INFO:_master_model_container: 16
2023-05-24 16:20:15,422:INFO:_display_container: 4
2023-05-24 16:20:15,424:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 16:20:15,424:INFO:create_model() successfully completed......................................
2023-05-24 16:20:15,496:INFO:SubProcess create_model() end ==================================
2023-05-24 16:20:15,497:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.67
2023-05-24 16:20:15,497:INFO:LGBMClassifier(bagging_fraction=0.7, bagging_freq=6, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=66, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=90, n_jobs=-1, num_leaves=90, objective=None,
               random_state=123, reg_alpha=0.0005, reg_lambda=0.1,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for Accuracy is 0.6685
2023-05-24 16:20:15,498:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-05-24 16:20:15,498:INFO:choose_better completed
2023-05-24 16:20:15,498:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-05-24 16:20:15,509:INFO:_master_model_container: 16
2023-05-24 16:20:15,509:INFO:_display_container: 3
2023-05-24 16:20:15,510:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 16:20:15,510:INFO:tune_model() successfully completed......................................
2023-05-24 16:23:42,791:INFO:Initializing tune_model()
2023-05-24 16:23:42,791:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=optuna, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>)
2023-05-24 16:23:42,804:INFO:Checking exceptions
2023-05-24 16:24:13,697:INFO:Initializing tune_model()
2023-05-24 16:24:13,698:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>)
2023-05-24 16:24:13,698:INFO:Checking exceptions
2023-05-24 16:24:13,698:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2023-05-24 16:25:13,948:INFO:Initializing tune_model()
2023-05-24 16:25:13,948:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>)
2023-05-24 16:25:13,948:INFO:Checking exceptions
2023-05-24 16:25:13,948:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2023-05-24 16:27:22,344:INFO:Initializing tune_model()
2023-05-24 16:27:22,344:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>)
2023-05-24 16:27:22,345:INFO:Checking exceptions
2023-05-24 16:27:22,345:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2023-05-24 16:27:47,647:INFO:Initializing tune_model()
2023-05-24 16:27:47,647:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>)
2023-05-24 16:27:47,647:INFO:Checking exceptions
2023-05-24 16:27:47,649:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2023-05-24 16:28:02,183:INFO:Initializing tune_model()
2023-05-24 16:28:02,183:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020DEC786C80>)
2023-05-24 16:28:02,183:INFO:Checking exceptions
2023-05-24 16:28:02,183:ERROR:
'optuna' is a soft dependency and not included in the pycaret installation. Please run: `pip install optuna` to install.
Alternately, you can install this by running `pip install pycaret[tuners]`
NoneType: None
2023-05-24 16:28:53,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 16:28:53,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 16:28:53,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 16:28:53,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 16:28:54,673:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-24 16:29:15,547:INFO:PyCaret ClassificationExperiment
2023-05-24 16:29:15,547:INFO:Logging name: clf-default-name
2023-05-24 16:29:15,547:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 16:29:15,548:INFO:version 3.0.2
2023-05-24 16:29:15,548:INFO:Initializing setup()
2023-05-24 16:29:15,548:INFO:self.USI: 5155
2023-05-24 16:29:15,548:INFO:self._variable_keys: {'fold_generator', '_available_plots', 'gpu_param', 'target_param', 'X', 'y', 'fold_groups_param', 'fix_imbalance', 'exp_id', 'is_multiclass', 'y_test', 'X_test', 'memory', 'data', 'idx', 'X_train', 'logging_param', 'exp_name_log', 'USI', 'log_plots_param', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'n_jobs_param', 'html_param', 'y_train', 'pipeline', 'fold_shuffle_param'}
2023-05-24 16:29:15,548:INFO:Checking environment
2023-05-24 16:29:15,548:INFO:python_version: 3.10.11
2023-05-24 16:29:15,548:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 16:29:15,548:INFO:machine: AMD64
2023-05-24 16:29:15,549:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 16:29:15,552:INFO:Memory: svmem(total=16889774080, available=8281853952, percent=51.0, used=8607920128, free=8281853952)
2023-05-24 16:29:15,552:INFO:Physical Core: 4
2023-05-24 16:29:15,552:INFO:Logical Core: 8
2023-05-24 16:29:15,552:INFO:Checking libraries
2023-05-24 16:29:15,553:INFO:System:
2023-05-24 16:29:15,553:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 16:29:15,553:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 16:29:15,553:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 16:29:15,553:INFO:PyCaret required dependencies:
2023-05-24 16:29:15,553:INFO:                 pip: 23.0.1
2023-05-24 16:29:15,553:INFO:          setuptools: 66.0.0
2023-05-24 16:29:15,553:INFO:             pycaret: 3.0.2
2023-05-24 16:29:15,553:INFO:             IPython: 8.13.2
2023-05-24 16:29:15,553:INFO:          ipywidgets: 8.0.6
2023-05-24 16:29:15,553:INFO:                tqdm: 4.65.0
2023-05-24 16:29:15,553:INFO:               numpy: 1.23.5
2023-05-24 16:29:15,553:INFO:              pandas: 1.5.3
2023-05-24 16:29:15,553:INFO:              jinja2: 3.1.2
2023-05-24 16:29:15,553:INFO:               scipy: 1.10.1
2023-05-24 16:29:15,555:INFO:              joblib: 1.2.0
2023-05-24 16:29:15,555:INFO:             sklearn: 1.2.2
2023-05-24 16:29:15,555:INFO:                pyod: 1.0.9
2023-05-24 16:29:15,555:INFO:            imblearn: 0.10.1
2023-05-24 16:29:15,555:INFO:   category_encoders: 2.6.1
2023-05-24 16:29:15,555:INFO:            lightgbm: 3.3.5
2023-05-24 16:29:15,555:INFO:               numba: 0.57.0
2023-05-24 16:29:15,555:INFO:            requests: 2.31.0
2023-05-24 16:29:15,555:INFO:          matplotlib: 3.7.1
2023-05-24 16:29:15,555:INFO:          scikitplot: 0.3.7
2023-05-24 16:29:15,555:INFO:         yellowbrick: 1.5
2023-05-24 16:29:15,555:INFO:              plotly: 5.14.1
2023-05-24 16:29:15,555:INFO:             kaleido: 0.2.1
2023-05-24 16:29:15,555:INFO:         statsmodels: 0.14.0
2023-05-24 16:29:15,555:INFO:              sktime: 0.17.0
2023-05-24 16:29:15,555:INFO:               tbats: 1.1.3
2023-05-24 16:29:15,555:INFO:            pmdarima: 2.0.3
2023-05-24 16:29:15,555:INFO:              psutil: 5.9.5
2023-05-24 16:29:15,555:INFO:PyCaret optional dependencies:
2023-05-24 16:29:15,563:INFO:                shap: Not installed
2023-05-24 16:29:15,563:INFO:           interpret: Not installed
2023-05-24 16:29:15,563:INFO:                umap: Not installed
2023-05-24 16:29:15,563:INFO:    pandas_profiling: Not installed
2023-05-24 16:29:15,563:INFO:  explainerdashboard: Not installed
2023-05-24 16:29:15,563:INFO:             autoviz: Not installed
2023-05-24 16:29:15,563:INFO:           fairlearn: Not installed
2023-05-24 16:29:15,563:INFO:             xgboost: Not installed
2023-05-24 16:29:15,563:INFO:            catboost: Not installed
2023-05-24 16:29:15,563:INFO:              kmodes: Not installed
2023-05-24 16:29:15,563:INFO:             mlxtend: Not installed
2023-05-24 16:29:15,563:INFO:       statsforecast: Not installed
2023-05-24 16:29:15,563:INFO:        tune_sklearn: 0.4.5
2023-05-24 16:29:15,563:INFO:                 ray: 2.4.0
2023-05-24 16:29:15,563:INFO:            hyperopt: 0.2.7
2023-05-24 16:29:15,563:INFO:              optuna: 3.1.1
2023-05-24 16:29:15,564:INFO:               skopt: 0.9.0
2023-05-24 16:29:15,564:INFO:              mlflow: Not installed
2023-05-24 16:29:15,564:INFO:              gradio: Not installed
2023-05-24 16:29:15,564:INFO:             fastapi: Not installed
2023-05-24 16:29:15,564:INFO:             uvicorn: Not installed
2023-05-24 16:29:15,564:INFO:              m2cgen: Not installed
2023-05-24 16:29:15,564:INFO:           evidently: Not installed
2023-05-24 16:29:15,564:INFO:               fugue: Not installed
2023-05-24 16:29:15,564:INFO:           streamlit: Not installed
2023-05-24 16:29:15,564:INFO:             prophet: Not installed
2023-05-24 16:29:15,564:INFO:None
2023-05-24 16:29:15,564:INFO:Set up data.
2023-05-24 16:29:15,828:INFO:Set up train/test split.
2023-05-24 16:29:15,945:INFO:Set up index.
2023-05-24 16:29:15,949:INFO:Set up folding strategy.
2023-05-24 16:29:15,949:INFO:Assigning column types.
2023-05-24 16:29:16,028:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 16:29:16,093:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 16:29:16,098:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:29:16,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 16:29:16,228:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:29:16,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,260:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,260:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 16:29:16,330:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:29:16,364:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,418:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:29:16,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,453:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 16:29:16,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:16,618:INFO:Preparing preprocessing pipeline...
2023-05-24 16:29:16,628:INFO:Set up label encoding.
2023-05-24 16:29:16,628:INFO:Set up simple imputation.
2023-05-24 16:29:16,635:INFO:Set up column name cleaning.
2023-05-24 16:29:16,938:INFO:Finished creating preprocessing pipeline.
2023-05-24 16:29:16,948:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 16:29:16,948:INFO:Creating final display dataframe.
2023-05-24 16:29:18,215:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                              Review  
2                                          Multiclass  
3   Indifference: 0, Mixed: 1, Negative: 2, Positi...  
4                                        (46252, 507)  
5                                        (46252, 507)  
6                                        (32376, 507)  
7                                        (13876, 507)  
8                                                 506  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               5155  
2023-05-24 16:29:18,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:18,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:18,474:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:18,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:18,475:INFO:setup() successfully completed in 3.12s...............
2023-05-24 16:29:18,806:INFO:PyCaret ClassificationExperiment
2023-05-24 16:29:18,806:INFO:Logging name: clf-default-name
2023-05-24 16:29:18,806:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 16:29:18,806:INFO:version 3.0.2
2023-05-24 16:29:18,806:INFO:Initializing setup()
2023-05-24 16:29:18,806:INFO:self.USI: 6a33
2023-05-24 16:29:18,806:INFO:self._variable_keys: {'fold_generator', '_available_plots', 'gpu_param', 'target_param', 'X', 'y', 'fold_groups_param', 'fix_imbalance', 'exp_id', 'is_multiclass', 'y_test', 'X_test', 'memory', 'data', 'idx', 'X_train', 'logging_param', 'exp_name_log', 'USI', 'log_plots_param', 'seed', '_ml_usecase', 'gpu_n_jobs_param', 'n_jobs_param', 'html_param', 'y_train', 'pipeline', 'fold_shuffle_param'}
2023-05-24 16:29:18,806:INFO:Checking environment
2023-05-24 16:29:18,806:INFO:python_version: 3.10.11
2023-05-24 16:29:18,806:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 16:29:18,806:INFO:machine: AMD64
2023-05-24 16:29:18,806:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 16:29:18,808:INFO:Memory: svmem(total=16889774080, available=7931768832, percent=53.0, used=8958005248, free=7931768832)
2023-05-24 16:29:18,809:INFO:Physical Core: 4
2023-05-24 16:29:18,809:INFO:Logical Core: 8
2023-05-24 16:29:18,809:INFO:Checking libraries
2023-05-24 16:29:18,809:INFO:System:
2023-05-24 16:29:18,809:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 16:29:18,809:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 16:29:18,809:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 16:29:18,809:INFO:PyCaret required dependencies:
2023-05-24 16:29:18,809:INFO:                 pip: 23.0.1
2023-05-24 16:29:18,809:INFO:          setuptools: 66.0.0
2023-05-24 16:29:18,809:INFO:             pycaret: 3.0.2
2023-05-24 16:29:18,809:INFO:             IPython: 8.13.2
2023-05-24 16:29:18,809:INFO:          ipywidgets: 8.0.6
2023-05-24 16:29:18,809:INFO:                tqdm: 4.65.0
2023-05-24 16:29:18,809:INFO:               numpy: 1.23.5
2023-05-24 16:29:18,809:INFO:              pandas: 1.5.3
2023-05-24 16:29:18,809:INFO:              jinja2: 3.1.2
2023-05-24 16:29:18,809:INFO:               scipy: 1.10.1
2023-05-24 16:29:18,809:INFO:              joblib: 1.2.0
2023-05-24 16:29:18,809:INFO:             sklearn: 1.2.2
2023-05-24 16:29:18,809:INFO:                pyod: 1.0.9
2023-05-24 16:29:18,809:INFO:            imblearn: 0.10.1
2023-05-24 16:29:18,810:INFO:   category_encoders: 2.6.1
2023-05-24 16:29:18,810:INFO:            lightgbm: 3.3.5
2023-05-24 16:29:18,810:INFO:               numba: 0.57.0
2023-05-24 16:29:18,810:INFO:            requests: 2.31.0
2023-05-24 16:29:18,810:INFO:          matplotlib: 3.7.1
2023-05-24 16:29:18,810:INFO:          scikitplot: 0.3.7
2023-05-24 16:29:18,810:INFO:         yellowbrick: 1.5
2023-05-24 16:29:18,810:INFO:              plotly: 5.14.1
2023-05-24 16:29:18,810:INFO:             kaleido: 0.2.1
2023-05-24 16:29:18,810:INFO:         statsmodels: 0.14.0
2023-05-24 16:29:18,810:INFO:              sktime: 0.17.0
2023-05-24 16:29:18,810:INFO:               tbats: 1.1.3
2023-05-24 16:29:18,810:INFO:            pmdarima: 2.0.3
2023-05-24 16:29:18,810:INFO:              psutil: 5.9.5
2023-05-24 16:29:18,810:INFO:PyCaret optional dependencies:
2023-05-24 16:29:18,810:INFO:                shap: Not installed
2023-05-24 16:29:18,810:INFO:           interpret: Not installed
2023-05-24 16:29:18,810:INFO:                umap: Not installed
2023-05-24 16:29:18,810:INFO:    pandas_profiling: Not installed
2023-05-24 16:29:18,811:INFO:  explainerdashboard: Not installed
2023-05-24 16:29:18,811:INFO:             autoviz: Not installed
2023-05-24 16:29:18,811:INFO:           fairlearn: Not installed
2023-05-24 16:29:18,811:INFO:             xgboost: Not installed
2023-05-24 16:29:18,811:INFO:            catboost: Not installed
2023-05-24 16:29:18,811:INFO:              kmodes: Not installed
2023-05-24 16:29:18,811:INFO:             mlxtend: Not installed
2023-05-24 16:29:18,811:INFO:       statsforecast: Not installed
2023-05-24 16:29:18,811:INFO:        tune_sklearn: 0.4.5
2023-05-24 16:29:18,811:INFO:                 ray: 2.4.0
2023-05-24 16:29:18,811:INFO:            hyperopt: 0.2.7
2023-05-24 16:29:18,811:INFO:              optuna: 3.1.1
2023-05-24 16:29:18,811:INFO:               skopt: 0.9.0
2023-05-24 16:29:18,811:INFO:              mlflow: Not installed
2023-05-24 16:29:18,811:INFO:              gradio: Not installed
2023-05-24 16:29:18,811:INFO:             fastapi: Not installed
2023-05-24 16:29:18,811:INFO:             uvicorn: Not installed
2023-05-24 16:29:18,811:INFO:              m2cgen: Not installed
2023-05-24 16:29:18,811:INFO:           evidently: Not installed
2023-05-24 16:29:18,811:INFO:               fugue: Not installed
2023-05-24 16:29:18,811:INFO:           streamlit: Not installed
2023-05-24 16:29:18,811:INFO:             prophet: Not installed
2023-05-24 16:29:18,811:INFO:None
2023-05-24 16:29:18,811:INFO:Set up data.
2023-05-24 16:29:19,190:INFO:Set up train/test split.
2023-05-24 16:29:19,350:INFO:Set up index.
2023-05-24 16:29:19,354:INFO:Set up folding strategy.
2023-05-24 16:29:19,354:INFO:Assigning column types.
2023-05-24 16:29:19,422:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 16:29:19,470:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 16:29:19,471:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:29:19,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,546:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 16:29:19,547:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:29:19,572:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,573:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 16:29:19,612:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:29:19,637:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,677:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:29:19,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,702:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 16:29:19,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:19,827:INFO:Preparing preprocessing pipeline...
2023-05-24 16:29:19,836:INFO:Set up label encoding.
2023-05-24 16:29:19,837:INFO:Set up simple imputation.
2023-05-24 16:29:19,844:INFO:Set up column name cleaning.
2023-05-24 16:29:20,120:INFO:Finished creating preprocessing pipeline.
2023-05-24 16:29:20,126:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 16:29:20,126:INFO:Creating final display dataframe.
2023-05-24 16:29:20,783:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                              Review  
2                                          Multiclass  
3   Indifference: 0, Mixed: 1, Negative: 2, Positi...  
4                                        (46252, 507)  
5                                        (46252, 507)  
6                                        (32376, 507)  
7                                        (13876, 507)  
8                                                 506  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               6a33  
2023-05-24 16:29:20,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:20,861:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:20,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:20,926:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:29:20,927:INFO:setup() successfully completed in 2.27s...............
2023-05-24 16:29:20,981:INFO:Initializing compare_models()
2023-05-24 16:29:20,981:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-24 16:29:20,981:INFO:Checking exceptions
2023-05-24 16:29:21,044:INFO:Preparing display monitor
2023-05-24 16:29:21,072:INFO:Initializing Logistic Regression
2023-05-24 16:29:21,072:INFO:Total runtime is 0.0 minutes
2023-05-24 16:29:21,076:INFO:SubProcess create_model() called ==================================
2023-05-24 16:29:21,076:INFO:Initializing create_model()
2023-05-24 16:29:21,076:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:29:21,076:INFO:Checking exceptions
2023-05-24 16:29:21,078:INFO:Importing libraries
2023-05-24 16:29:21,078:INFO:Copying training dataset
2023-05-24 16:29:21,213:INFO:Defining folds
2023-05-24 16:29:21,213:INFO:Declaring metric variables
2023-05-24 16:29:21,218:INFO:Importing untrained model
2023-05-24 16:29:21,223:INFO:Logistic Regression Imported successfully
2023-05-24 16:29:21,229:INFO:Starting cross validation
2023-05-24 16:29:21,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:31:39,597:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:31:40,590:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:31:40,673:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:31:40,947:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:40,976:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:40,991:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:31:41,005:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:41,421:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:31:41,724:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:41,744:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:41,750:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:41,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:31:41,769:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:41,775:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:41,792:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:31:41,795:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:42,493:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:42,522:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:42,535:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:31:42,548:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:42,841:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:42,857:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:31:42,869:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:42,882:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:31:42,894:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:43,822:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:43,859:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:43,881:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:31:43,894:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:44,112:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:31:45,075:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:45,093:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:45,106:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:31:45,109:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:31:45,124:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:45,838:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:45,864:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:31:45,874:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:31:45,882:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:32:48,271:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:32:48,948:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:32:48,975:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:32:48,997:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:32:49,087:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:32:49,855:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:32:49,887:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:32:49,903:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:32:50,245:INFO:Calculating mean and std
2023-05-24 16:32:50,248:INFO:Creating metrics dataframe
2023-05-24 16:32:50,526:INFO:Uploading results into container
2023-05-24 16:32:50,527:INFO:Uploading model into container now
2023-05-24 16:32:50,528:INFO:_master_model_container: 1
2023-05-24 16:32:50,529:INFO:_display_container: 2
2023-05-24 16:32:50,530:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-24 16:32:50,530:INFO:create_model() successfully completed......................................
2023-05-24 16:32:50,648:INFO:SubProcess create_model() end ==================================
2023-05-24 16:32:50,649:INFO:Creating metrics dataframe
2023-05-24 16:32:50,663:INFO:Initializing K Neighbors Classifier
2023-05-24 16:32:50,663:INFO:Total runtime is 3.493184665838877 minutes
2023-05-24 16:32:50,668:INFO:SubProcess create_model() called ==================================
2023-05-24 16:32:50,669:INFO:Initializing create_model()
2023-05-24 16:32:50,669:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:32:50,669:INFO:Checking exceptions
2023-05-24 16:32:50,669:INFO:Importing libraries
2023-05-24 16:32:50,669:INFO:Copying training dataset
2023-05-24 16:32:50,804:INFO:Defining folds
2023-05-24 16:32:50,805:INFO:Declaring metric variables
2023-05-24 16:32:50,812:INFO:Importing untrained model
2023-05-24 16:32:50,822:INFO:K Neighbors Classifier Imported successfully
2023-05-24 16:32:50,838:INFO:Starting cross validation
2023-05-24 16:32:50,850:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:33:03,113:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,140:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,177:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,283:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,294:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,309:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,321:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,334:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,353:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,445:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,470:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,496:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,553:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,582:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,607:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,640:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,667:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,710:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,754:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,782:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,807:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,859:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,889:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:03,915:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:13,016:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:13,041:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:13,054:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:13,121:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:13,152:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:13,191:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:13,454:INFO:Calculating mean and std
2023-05-24 16:33:13,457:INFO:Creating metrics dataframe
2023-05-24 16:33:13,827:INFO:Uploading results into container
2023-05-24 16:33:13,828:INFO:Uploading model into container now
2023-05-24 16:33:13,830:INFO:_master_model_container: 2
2023-05-24 16:33:13,830:INFO:_display_container: 2
2023-05-24 16:33:13,831:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-24 16:33:13,831:INFO:create_model() successfully completed......................................
2023-05-24 16:33:13,943:INFO:SubProcess create_model() end ==================================
2023-05-24 16:33:13,943:INFO:Creating metrics dataframe
2023-05-24 16:33:13,963:INFO:Initializing Naive Bayes
2023-05-24 16:33:13,964:INFO:Total runtime is 3.8815183162689206 minutes
2023-05-24 16:33:13,969:INFO:SubProcess create_model() called ==================================
2023-05-24 16:33:13,969:INFO:Initializing create_model()
2023-05-24 16:33:13,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:33:13,969:INFO:Checking exceptions
2023-05-24 16:33:13,969:INFO:Importing libraries
2023-05-24 16:33:13,970:INFO:Copying training dataset
2023-05-24 16:33:14,100:INFO:Defining folds
2023-05-24 16:33:14,100:INFO:Declaring metric variables
2023-05-24 16:33:14,108:INFO:Importing untrained model
2023-05-24 16:33:14,113:INFO:Naive Bayes Imported successfully
2023-05-24 16:33:14,129:INFO:Starting cross validation
2023-05-24 16:33:14,136:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:33:16,831:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,865:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,871:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,875:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,877:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,891:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,901:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,916:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,921:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,926:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,927:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,938:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,940:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,959:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,960:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,969:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,983:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:16,994:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:17,007:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:17,025:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:17,047:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:17,070:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:19,070:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:19,116:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:19,152:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:19,389:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:19,422:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:19,461:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:19,671:INFO:Calculating mean and std
2023-05-24 16:33:19,674:INFO:Creating metrics dataframe
2023-05-24 16:33:20,104:INFO:Uploading results into container
2023-05-24 16:33:20,106:INFO:Uploading model into container now
2023-05-24 16:33:20,107:INFO:_master_model_container: 3
2023-05-24 16:33:20,107:INFO:_display_container: 2
2023-05-24 16:33:20,107:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-24 16:33:20,108:INFO:create_model() successfully completed......................................
2023-05-24 16:33:20,212:INFO:SubProcess create_model() end ==================================
2023-05-24 16:33:20,212:INFO:Creating metrics dataframe
2023-05-24 16:33:20,225:INFO:Initializing Decision Tree Classifier
2023-05-24 16:33:20,226:INFO:Total runtime is 3.9858976602554317 minutes
2023-05-24 16:33:20,235:INFO:SubProcess create_model() called ==================================
2023-05-24 16:33:20,237:INFO:Initializing create_model()
2023-05-24 16:33:20,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:33:20,237:INFO:Checking exceptions
2023-05-24 16:33:20,238:INFO:Importing libraries
2023-05-24 16:33:20,238:INFO:Copying training dataset
2023-05-24 16:33:20,435:INFO:Defining folds
2023-05-24 16:33:20,435:INFO:Declaring metric variables
2023-05-24 16:33:20,445:INFO:Importing untrained model
2023-05-24 16:33:20,454:INFO:Decision Tree Classifier Imported successfully
2023-05-24 16:33:20,468:INFO:Starting cross validation
2023-05-24 16:33:20,476:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:33:27,654:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,695:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,717:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,805:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,848:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,866:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,871:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,902:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,925:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,945:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,947:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,950:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,967:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,969:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,991:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:27,994:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:28,014:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:28,018:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:28,024:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:28,042:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:28,048:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:28,066:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:28,071:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:32,718:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:32,734:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:32,750:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:33,183:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:33,205:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:33,218:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:33,465:INFO:Calculating mean and std
2023-05-24 16:33:33,467:INFO:Creating metrics dataframe
2023-05-24 16:33:33,704:INFO:Uploading results into container
2023-05-24 16:33:33,705:INFO:Uploading model into container now
2023-05-24 16:33:33,706:INFO:_master_model_container: 4
2023-05-24 16:33:33,707:INFO:_display_container: 2
2023-05-24 16:33:33,707:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-24 16:33:33,707:INFO:create_model() successfully completed......................................
2023-05-24 16:33:33,802:INFO:SubProcess create_model() end ==================================
2023-05-24 16:33:33,802:INFO:Creating metrics dataframe
2023-05-24 16:33:33,815:INFO:Initializing SVM - Linear Kernel
2023-05-24 16:33:33,815:INFO:Total runtime is 4.212389679749807 minutes
2023-05-24 16:33:33,825:INFO:SubProcess create_model() called ==================================
2023-05-24 16:33:33,826:INFO:Initializing create_model()
2023-05-24 16:33:33,826:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:33:33,827:INFO:Checking exceptions
2023-05-24 16:33:33,827:INFO:Importing libraries
2023-05-24 16:33:33,827:INFO:Copying training dataset
2023-05-24 16:33:34,008:INFO:Defining folds
2023-05-24 16:33:34,009:INFO:Declaring metric variables
2023-05-24 16:33:34,016:INFO:Importing untrained model
2023-05-24 16:33:34,025:INFO:SVM - Linear Kernel Imported successfully
2023-05-24 16:33:34,043:INFO:Starting cross validation
2023-05-24 16:33:34,050:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:33:42,395:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:33:42,405:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:42,427:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:42,442:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:42,452:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:43,331:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:33:43,342:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:43,364:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:43,389:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:44,827:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:33:44,836:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:44,867:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:44,881:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:44,893:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:45,530:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:33:45,561:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:45,584:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:45,600:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:45,611:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:45,742:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:33:45,762:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:45,789:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:45,835:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:46,252:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:33:46,265:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:46,301:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:46,315:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:46,329:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:46,735:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:33:46,745:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:46,767:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:46,779:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:46,789:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:48,362:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:33:48,381:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:48,405:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:48,415:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:48,425:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:50,872:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:33:50,884:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:50,909:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:50,916:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:50,922:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:53,623:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:33:53,629:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:53,639:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:53,645:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:53,650:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:53,885:INFO:Calculating mean and std
2023-05-24 16:33:53,887:INFO:Creating metrics dataframe
2023-05-24 16:33:54,010:INFO:Uploading results into container
2023-05-24 16:33:54,011:INFO:Uploading model into container now
2023-05-24 16:33:54,011:INFO:_master_model_container: 5
2023-05-24 16:33:54,012:INFO:_display_container: 2
2023-05-24 16:33:54,012:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-24 16:33:54,012:INFO:create_model() successfully completed......................................
2023-05-24 16:33:54,087:INFO:SubProcess create_model() end ==================================
2023-05-24 16:33:54,087:INFO:Creating metrics dataframe
2023-05-24 16:33:54,100:INFO:Initializing Ridge Classifier
2023-05-24 16:33:54,100:INFO:Total runtime is 4.550471409161886 minutes
2023-05-24 16:33:54,104:INFO:SubProcess create_model() called ==================================
2023-05-24 16:33:54,104:INFO:Initializing create_model()
2023-05-24 16:33:54,104:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:33:54,104:INFO:Checking exceptions
2023-05-24 16:33:54,104:INFO:Importing libraries
2023-05-24 16:33:54,104:INFO:Copying training dataset
2023-05-24 16:33:54,189:INFO:Defining folds
2023-05-24 16:33:54,189:INFO:Declaring metric variables
2023-05-24 16:33:54,195:INFO:Importing untrained model
2023-05-24 16:33:54,200:INFO:Ridge Classifier Imported successfully
2023-05-24 16:33:54,208:INFO:Starting cross validation
2023-05-24 16:33:54,211:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:33:56,753:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:33:56,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,789:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,801:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:33:56,802:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:56,812:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,813:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,816:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:33:56,826:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,839:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,842:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:33:56,850:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,852:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:56,852:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,861:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,862:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:56,872:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,874:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,887:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:56,897:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,947:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:33:56,958:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,969:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:33:56,977:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:33:56,978:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:33:56,979:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,981:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,988:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:56,993:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:57,004:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:57,004:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:57,005:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:57,011:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:57,017:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:57,023:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:57,028:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:57,030:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:57,034:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:57,046:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:57,056:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:58,533:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:33:58,538:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:58,564:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:58,571:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:58,573:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:33:58,576:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:58,578:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:58,591:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:58,598:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:33:58,604:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:33:58,866:INFO:Calculating mean and std
2023-05-24 16:33:58,867:INFO:Creating metrics dataframe
2023-05-24 16:33:58,998:INFO:Uploading results into container
2023-05-24 16:33:58,999:INFO:Uploading model into container now
2023-05-24 16:33:58,999:INFO:_master_model_container: 6
2023-05-24 16:33:58,999:INFO:_display_container: 2
2023-05-24 16:33:59,000:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-24 16:33:59,000:INFO:create_model() successfully completed......................................
2023-05-24 16:33:59,080:INFO:SubProcess create_model() end ==================================
2023-05-24 16:33:59,081:INFO:Creating metrics dataframe
2023-05-24 16:33:59,093:INFO:Initializing Random Forest Classifier
2023-05-24 16:33:59,094:INFO:Total runtime is 4.6336933692296345 minutes
2023-05-24 16:33:59,097:INFO:SubProcess create_model() called ==================================
2023-05-24 16:33:59,097:INFO:Initializing create_model()
2023-05-24 16:33:59,098:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:33:59,098:INFO:Checking exceptions
2023-05-24 16:33:59,098:INFO:Importing libraries
2023-05-24 16:33:59,098:INFO:Copying training dataset
2023-05-24 16:33:59,185:INFO:Defining folds
2023-05-24 16:33:59,185:INFO:Declaring metric variables
2023-05-24 16:33:59,188:INFO:Importing untrained model
2023-05-24 16:33:59,194:INFO:Random Forest Classifier Imported successfully
2023-05-24 16:33:59,202:INFO:Starting cross validation
2023-05-24 16:33:59,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:34:28,682:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:34:29,042:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:34:29,267:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:34:30,710:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:34:30,718:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:34:31,388:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:31,390:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:31,417:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:31,417:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:31,464:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:31,471:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:31,507:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:31,535:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:31,575:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:31,694:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:34:31,709:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:34:31,744:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:34:31,765:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:34:31,829:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:34:32,827:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:34:32,967:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:34:33,840:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:33,844:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:33,845:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:33,848:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:33,871:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:33,907:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:33,909:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:33,913:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:33,930:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:33,951:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:33,969:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:34,108:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:34,186:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:34,333:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:42,504:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:42,519:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:42,533:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:42,665:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:42,680:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:42,692:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:42,847:INFO:Calculating mean and std
2023-05-24 16:34:42,848:INFO:Creating metrics dataframe
2023-05-24 16:34:42,999:INFO:Uploading results into container
2023-05-24 16:34:43,000:INFO:Uploading model into container now
2023-05-24 16:34:43,000:INFO:_master_model_container: 7
2023-05-24 16:34:43,000:INFO:_display_container: 2
2023-05-24 16:34:43,000:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-24 16:34:43,000:INFO:create_model() successfully completed......................................
2023-05-24 16:34:43,077:INFO:SubProcess create_model() end ==================================
2023-05-24 16:34:43,078:INFO:Creating metrics dataframe
2023-05-24 16:34:43,088:INFO:Initializing Quadratic Discriminant Analysis
2023-05-24 16:34:43,088:INFO:Total runtime is 5.366937720775605 minutes
2023-05-24 16:34:43,094:INFO:SubProcess create_model() called ==================================
2023-05-24 16:34:43,094:INFO:Initializing create_model()
2023-05-24 16:34:43,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:34:43,094:INFO:Checking exceptions
2023-05-24 16:34:43,094:INFO:Importing libraries
2023-05-24 16:34:43,095:INFO:Copying training dataset
2023-05-24 16:34:43,184:INFO:Defining folds
2023-05-24 16:34:43,184:INFO:Declaring metric variables
2023-05-24 16:34:43,187:INFO:Importing untrained model
2023-05-24 16:34:43,193:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-24 16:34:43,201:INFO:Starting cross validation
2023-05-24 16:34:43,204:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:34:47,728:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:34:47,734:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:34:47,765:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:34:47,840:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:34:47,878:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:34:47,909:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:34:47,920:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:34:47,926:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:34:54,664:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,666:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,701:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,709:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,734:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,744:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,775:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,796:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,811:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,833:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,838:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,845:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,868:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,905:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:54,950:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:55,012:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:55,026:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:55,041:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:55,065:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:55,066:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:55,080:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:55,092:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:55,095:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:55,117:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:56,968:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:34:57,047:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:34:59,322:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:59,342:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:59,356:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:59,402:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:59,415:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:59,427:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:34:59,667:INFO:Calculating mean and std
2023-05-24 16:34:59,669:INFO:Creating metrics dataframe
2023-05-24 16:34:59,818:INFO:Uploading results into container
2023-05-24 16:34:59,819:INFO:Uploading model into container now
2023-05-24 16:34:59,819:INFO:_master_model_container: 8
2023-05-24 16:34:59,819:INFO:_display_container: 2
2023-05-24 16:34:59,820:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-24 16:34:59,820:INFO:create_model() successfully completed......................................
2023-05-24 16:34:59,900:INFO:SubProcess create_model() end ==================================
2023-05-24 16:34:59,901:INFO:Creating metrics dataframe
2023-05-24 16:34:59,912:INFO:Initializing Ada Boost Classifier
2023-05-24 16:34:59,912:INFO:Total runtime is 5.647331877549489 minutes
2023-05-24 16:34:59,916:INFO:SubProcess create_model() called ==================================
2023-05-24 16:34:59,917:INFO:Initializing create_model()
2023-05-24 16:34:59,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:34:59,917:INFO:Checking exceptions
2023-05-24 16:34:59,917:INFO:Importing libraries
2023-05-24 16:34:59,917:INFO:Copying training dataset
2023-05-24 16:35:00,010:INFO:Defining folds
2023-05-24 16:35:00,011:INFO:Declaring metric variables
2023-05-24 16:35:00,016:INFO:Importing untrained model
2023-05-24 16:35:00,020:INFO:Ada Boost Classifier Imported successfully
2023-05-24 16:35:00,030:INFO:Starting cross validation
2023-05-24 16:35:00,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:35:19,177:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:19,209:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:19,218:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:19,237:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:19,247:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:19,276:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:19,279:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:19,311:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:19,340:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:19,879:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:19,919:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:19,949:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,011:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,044:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,089:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,284:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,312:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,341:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,435:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,459:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,479:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,526:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,552:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:20,577:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:28,801:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:28,807:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:28,813:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:28,820:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:28,824:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:28,832:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:35:29,119:INFO:Calculating mean and std
2023-05-24 16:35:29,121:INFO:Creating metrics dataframe
2023-05-24 16:35:29,262:INFO:Uploading results into container
2023-05-24 16:35:29,262:INFO:Uploading model into container now
2023-05-24 16:35:29,264:INFO:_master_model_container: 9
2023-05-24 16:35:29,264:INFO:_display_container: 2
2023-05-24 16:35:29,265:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-24 16:35:29,265:INFO:create_model() successfully completed......................................
2023-05-24 16:35:29,343:INFO:SubProcess create_model() end ==================================
2023-05-24 16:35:29,343:INFO:Creating metrics dataframe
2023-05-24 16:35:29,354:INFO:Initializing Gradient Boosting Classifier
2023-05-24 16:35:29,354:INFO:Total runtime is 6.138031053543091 minutes
2023-05-24 16:35:29,357:INFO:SubProcess create_model() called ==================================
2023-05-24 16:35:29,357:INFO:Initializing create_model()
2023-05-24 16:35:29,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:35:29,357:INFO:Checking exceptions
2023-05-24 16:35:29,357:INFO:Importing libraries
2023-05-24 16:35:29,357:INFO:Copying training dataset
2023-05-24 16:35:29,446:INFO:Defining folds
2023-05-24 16:35:29,446:INFO:Declaring metric variables
2023-05-24 16:35:29,449:INFO:Importing untrained model
2023-05-24 16:35:29,453:INFO:Gradient Boosting Classifier Imported successfully
2023-05-24 16:35:29,461:INFO:Starting cross validation
2023-05-24 16:35:29,464:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:38:15,157:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:38:16,011:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:38:16,279:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:38:16,665:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:38:16,705:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:38:16,982:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:17,009:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:17,037:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:17,216:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:38:17,805:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:38:17,859:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:38:17,989:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:38:17,993:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:18,024:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:18,052:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:18,184:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:38:18,388:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:38:18,563:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:18,593:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:18,621:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:18,680:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:18,722:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:18,753:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:19,239:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:38:19,555:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:38:19,632:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:38:19,718:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:38:19,902:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:19,940:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:19,977:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:20,280:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:20,305:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:20,330:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:20,374:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:20,400:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:20,438:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:21,207:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:21,221:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:38:21,233:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:42,020:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:42,034:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:42,045:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:42,694:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:42,707:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:42,719:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:43,066:INFO:Calculating mean and std
2023-05-24 16:39:43,069:INFO:Creating metrics dataframe
2023-05-24 16:39:43,202:INFO:Uploading results into container
2023-05-24 16:39:43,203:INFO:Uploading model into container now
2023-05-24 16:39:43,203:INFO:_master_model_container: 10
2023-05-24 16:39:43,204:INFO:_display_container: 2
2023-05-24 16:39:43,204:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-24 16:39:43,204:INFO:create_model() successfully completed......................................
2023-05-24 16:39:43,286:INFO:SubProcess create_model() end ==================================
2023-05-24 16:39:43,286:INFO:Creating metrics dataframe
2023-05-24 16:39:43,299:INFO:Initializing Linear Discriminant Analysis
2023-05-24 16:39:43,299:INFO:Total runtime is 10.370441393057504 minutes
2023-05-24 16:39:43,303:INFO:SubProcess create_model() called ==================================
2023-05-24 16:39:43,303:INFO:Initializing create_model()
2023-05-24 16:39:43,303:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:39:43,303:INFO:Checking exceptions
2023-05-24 16:39:43,303:INFO:Importing libraries
2023-05-24 16:39:43,303:INFO:Copying training dataset
2023-05-24 16:39:43,392:INFO:Defining folds
2023-05-24 16:39:43,392:INFO:Declaring metric variables
2023-05-24 16:39:43,395:INFO:Importing untrained model
2023-05-24 16:39:43,400:INFO:Linear Discriminant Analysis Imported successfully
2023-05-24 16:39:43,407:INFO:Starting cross validation
2023-05-24 16:39:43,410:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:39:57,941:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:57,980:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,033:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,207:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,235:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,252:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,255:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,263:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,282:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,282:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,311:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,324:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,333:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,352:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,360:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,381:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,391:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,398:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,399:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,409:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,427:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,439:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:39:58,454:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:03,771:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:03,786:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:03,798:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:03,944:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:03,969:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:03,981:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:04,229:INFO:Calculating mean and std
2023-05-24 16:40:04,231:INFO:Creating metrics dataframe
2023-05-24 16:40:04,364:INFO:Uploading results into container
2023-05-24 16:40:04,365:INFO:Uploading model into container now
2023-05-24 16:40:04,365:INFO:_master_model_container: 11
2023-05-24 16:40:04,366:INFO:_display_container: 2
2023-05-24 16:40:04,366:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-24 16:40:04,366:INFO:create_model() successfully completed......................................
2023-05-24 16:40:04,440:INFO:SubProcess create_model() end ==================================
2023-05-24 16:40:04,440:INFO:Creating metrics dataframe
2023-05-24 16:40:04,453:INFO:Initializing Extra Trees Classifier
2023-05-24 16:40:04,453:INFO:Total runtime is 10.723020259539286 minutes
2023-05-24 16:40:04,457:INFO:SubProcess create_model() called ==================================
2023-05-24 16:40:04,458:INFO:Initializing create_model()
2023-05-24 16:40:04,458:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:40:04,458:INFO:Checking exceptions
2023-05-24 16:40:04,458:INFO:Importing libraries
2023-05-24 16:40:04,458:INFO:Copying training dataset
2023-05-24 16:40:04,544:INFO:Defining folds
2023-05-24 16:40:04,544:INFO:Declaring metric variables
2023-05-24 16:40:04,548:INFO:Importing untrained model
2023-05-24 16:40:04,553:INFO:Extra Trees Classifier Imported successfully
2023-05-24 16:40:04,558:INFO:Starting cross validation
2023-05-24 16:40:04,562:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:40:54,384:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:40:57,169:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:40:57,280:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:40:57,296:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:57,367:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:57,444:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:57,607:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:40:57,630:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:40:57,810:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:57,878:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:40:57,894:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:57,927:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:57,940:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:40:58,122:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,165:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,165:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,234:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,269:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,308:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,537:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,564:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,590:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,721:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,825:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,860:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,867:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,871:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,896:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,907:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,932:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:40:58,936:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:12,991:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:13,004:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:13,025:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:13,255:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:13,267:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:13,280:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:13,517:INFO:Calculating mean and std
2023-05-24 16:41:13,520:INFO:Creating metrics dataframe
2023-05-24 16:41:13,620:INFO:Uploading results into container
2023-05-24 16:41:13,621:INFO:Uploading model into container now
2023-05-24 16:41:13,621:INFO:_master_model_container: 12
2023-05-24 16:41:13,621:INFO:_display_container: 2
2023-05-24 16:41:13,622:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-24 16:41:13,622:INFO:create_model() successfully completed......................................
2023-05-24 16:41:13,706:INFO:SubProcess create_model() end ==================================
2023-05-24 16:41:13,707:INFO:Creating metrics dataframe
2023-05-24 16:41:13,718:INFO:Initializing Light Gradient Boosting Machine
2023-05-24 16:41:13,718:INFO:Total runtime is 11.877436717351276 minutes
2023-05-24 16:41:13,722:INFO:SubProcess create_model() called ==================================
2023-05-24 16:41:13,723:INFO:Initializing create_model()
2023-05-24 16:41:13,723:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:41:13,723:INFO:Checking exceptions
2023-05-24 16:41:13,723:INFO:Importing libraries
2023-05-24 16:41:13,723:INFO:Copying training dataset
2023-05-24 16:41:13,809:INFO:Defining folds
2023-05-24 16:41:13,809:INFO:Declaring metric variables
2023-05-24 16:41:13,813:INFO:Importing untrained model
2023-05-24 16:41:13,818:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 16:41:13,826:INFO:Starting cross validation
2023-05-24 16:41:13,829:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:41:22,010:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,037:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,064:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,106:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,135:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,198:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,565:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,593:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,621:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,712:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,740:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,768:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,780:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,809:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,839:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,915:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:22,957:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:23,016:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:23,090:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:23,115:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:23,115:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:23,140:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:23,142:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:23,166:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:26,249:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:26,270:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:26,284:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:26,418:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:26,432:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:26,444:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:26,683:INFO:Calculating mean and std
2023-05-24 16:41:26,684:INFO:Creating metrics dataframe
2023-05-24 16:41:26,791:INFO:Uploading results into container
2023-05-24 16:41:26,792:INFO:Uploading model into container now
2023-05-24 16:41:26,792:INFO:_master_model_container: 13
2023-05-24 16:41:26,792:INFO:_display_container: 2
2023-05-24 16:41:26,793:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 16:41:26,793:INFO:create_model() successfully completed......................................
2023-05-24 16:41:26,878:INFO:SubProcess create_model() end ==================================
2023-05-24 16:41:26,880:INFO:Creating metrics dataframe
2023-05-24 16:41:26,893:INFO:Initializing Dummy Classifier
2023-05-24 16:41:26,893:INFO:Total runtime is 12.09701373974482 minutes
2023-05-24 16:41:26,897:INFO:SubProcess create_model() called ==================================
2023-05-24 16:41:26,897:INFO:Initializing create_model()
2023-05-24 16:41:26,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002E964592350>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:41:26,897:INFO:Checking exceptions
2023-05-24 16:41:26,898:INFO:Importing libraries
2023-05-24 16:41:26,898:INFO:Copying training dataset
2023-05-24 16:41:27,010:INFO:Defining folds
2023-05-24 16:41:27,010:INFO:Declaring metric variables
2023-05-24 16:41:27,015:INFO:Importing untrained model
2023-05-24 16:41:27,019:INFO:Dummy Classifier Imported successfully
2023-05-24 16:41:27,025:INFO:Starting cross validation
2023-05-24 16:41:27,029:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:41:28,415:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,416:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,422:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,433:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,433:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,434:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,442:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,442:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,451:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,458:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:41:28,459:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,459:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:41:28,460:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,465:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:41:28,469:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,471:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,473:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:41:28,475:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:41:28,475:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:41:28,479:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,484:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,486:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,487:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,487:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,491:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,509:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,517:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,527:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:41:28,532:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:41:28,537:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:28,542:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:29,693:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:29,698:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:29,705:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:29,710:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:29,712:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:41:29,717:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:41:29,718:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:29,726:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:41:30,152:INFO:Calculating mean and std
2023-05-24 16:41:30,153:INFO:Creating metrics dataframe
2023-05-24 16:41:30,257:INFO:Uploading results into container
2023-05-24 16:41:30,258:INFO:Uploading model into container now
2023-05-24 16:41:30,258:INFO:_master_model_container: 14
2023-05-24 16:41:30,258:INFO:_display_container: 2
2023-05-24 16:41:30,258:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-24 16:41:30,259:INFO:create_model() successfully completed......................................
2023-05-24 16:41:30,332:INFO:SubProcess create_model() end ==================================
2023-05-24 16:41:30,332:INFO:Creating metrics dataframe
2023-05-24 16:41:30,353:INFO:Initializing create_model()
2023-05-24 16:41:30,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:41:30,354:INFO:Checking exceptions
2023-05-24 16:41:30,357:INFO:Importing libraries
2023-05-24 16:41:30,357:INFO:Copying training dataset
2023-05-24 16:41:30,445:INFO:Defining folds
2023-05-24 16:41:30,446:INFO:Declaring metric variables
2023-05-24 16:41:30,446:INFO:Importing untrained model
2023-05-24 16:41:30,446:INFO:Declaring custom model
2023-05-24 16:41:30,446:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 16:41:30,450:INFO:Cross validation set to False
2023-05-24 16:41:30,450:INFO:Fitting Model
2023-05-24 16:41:32,953:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 16:41:32,953:INFO:create_model() successfully completed......................................
2023-05-24 16:41:33,056:INFO:_master_model_container: 14
2023-05-24 16:41:33,056:INFO:_display_container: 2
2023-05-24 16:41:33,057:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 16:41:33,057:INFO:compare_models() successfully completed......................................
2023-05-24 16:41:33,312:INFO:Initializing tune_model()
2023-05-24 16:41:33,312:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=50, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002E96199ECB0>)
2023-05-24 16:41:33,312:INFO:Checking exceptions
2023-05-24 16:41:33,312:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-24 16:41:33,825:INFO:Copying training dataset
2023-05-24 16:41:33,894:INFO:Checking base model
2023-05-24 16:41:33,894:INFO:Base model : Light Gradient Boosting Machine
2023-05-24 16:41:33,898:INFO:Declaring metric variables
2023-05-24 16:41:33,902:INFO:Defining Hyperparameters
2023-05-24 16:41:34,007:INFO:Tuning with n_jobs=-1
2023-05-24 16:41:34,010:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-24 16:41:34,010:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-24 16:41:34,010:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-24 16:41:34,015:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-24 16:43:18,429:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:43:20,030:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:44:05,023:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:44:06,350:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:45:18,044:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:45:19,489:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:46:58,031:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:48:28,567:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:48:30,265:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:48:30,781:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:48:54,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 16:48:54,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 16:48:54,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 16:48:54,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 16:48:54,945:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-24 16:49:07,418:INFO:PyCaret ClassificationExperiment
2023-05-24 16:49:07,419:INFO:Logging name: clf-default-name
2023-05-24 16:49:07,419:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 16:49:07,419:INFO:version 3.0.2
2023-05-24 16:49:07,419:INFO:Initializing setup()
2023-05-24 16:49:07,420:INFO:self.USI: a62d
2023-05-24 16:49:07,420:INFO:self._variable_keys: {'target_param', '_available_plots', 'logging_param', 'html_param', 'seed', 'y_test', 'USI', 'fold_groups_param', 'log_plots_param', 'exp_name_log', 'idx', 'y', '_ml_usecase', 'X_train', 'fold_shuffle_param', 'gpu_n_jobs_param', 'pipeline', 'X_test', 'is_multiclass', 'X', 'data', 'gpu_param', 'fix_imbalance', 'exp_id', 'n_jobs_param', 'fold_generator', 'y_train', 'memory'}
2023-05-24 16:49:07,420:INFO:Checking environment
2023-05-24 16:49:07,420:INFO:python_version: 3.10.11
2023-05-24 16:49:07,420:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 16:49:07,420:INFO:machine: AMD64
2023-05-24 16:49:07,420:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 16:49:07,422:INFO:Memory: svmem(total=16889774080, available=8632705024, percent=48.9, used=8257069056, free=8632705024)
2023-05-24 16:49:07,423:INFO:Physical Core: 4
2023-05-24 16:49:07,423:INFO:Logical Core: 8
2023-05-24 16:49:07,423:INFO:Checking libraries
2023-05-24 16:49:07,424:INFO:System:
2023-05-24 16:49:07,424:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 16:49:07,424:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 16:49:07,424:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 16:49:07,424:INFO:PyCaret required dependencies:
2023-05-24 16:49:07,425:INFO:                 pip: 23.0.1
2023-05-24 16:49:07,425:INFO:          setuptools: 66.0.0
2023-05-24 16:49:07,425:INFO:             pycaret: 3.0.2
2023-05-24 16:49:07,425:INFO:             IPython: 8.13.2
2023-05-24 16:49:07,425:INFO:          ipywidgets: 8.0.6
2023-05-24 16:49:07,425:INFO:                tqdm: 4.65.0
2023-05-24 16:49:07,425:INFO:               numpy: 1.23.5
2023-05-24 16:49:07,425:INFO:              pandas: 1.5.3
2023-05-24 16:49:07,425:INFO:              jinja2: 3.1.2
2023-05-24 16:49:07,425:INFO:               scipy: 1.10.1
2023-05-24 16:49:07,425:INFO:              joblib: 1.2.0
2023-05-24 16:49:07,425:INFO:             sklearn: 1.2.2
2023-05-24 16:49:07,425:INFO:                pyod: 1.0.9
2023-05-24 16:49:07,425:INFO:            imblearn: 0.10.1
2023-05-24 16:49:07,425:INFO:   category_encoders: 2.6.1
2023-05-24 16:49:07,425:INFO:            lightgbm: 3.3.5
2023-05-24 16:49:07,425:INFO:               numba: 0.57.0
2023-05-24 16:49:07,425:INFO:            requests: 2.31.0
2023-05-24 16:49:07,425:INFO:          matplotlib: 3.7.1
2023-05-24 16:49:07,425:INFO:          scikitplot: 0.3.7
2023-05-24 16:49:07,425:INFO:         yellowbrick: 1.5
2023-05-24 16:49:07,425:INFO:              plotly: 5.14.1
2023-05-24 16:49:07,425:INFO:             kaleido: 0.2.1
2023-05-24 16:49:07,425:INFO:         statsmodels: 0.14.0
2023-05-24 16:49:07,425:INFO:              sktime: 0.17.0
2023-05-24 16:49:07,427:INFO:               tbats: 1.1.3
2023-05-24 16:49:07,427:INFO:            pmdarima: 2.0.3
2023-05-24 16:49:07,427:INFO:              psutil: 5.9.5
2023-05-24 16:49:07,427:INFO:PyCaret optional dependencies:
2023-05-24 16:49:07,435:INFO:                shap: Not installed
2023-05-24 16:49:07,435:INFO:           interpret: Not installed
2023-05-24 16:49:07,435:INFO:                umap: Not installed
2023-05-24 16:49:07,435:INFO:    pandas_profiling: Not installed
2023-05-24 16:49:07,436:INFO:  explainerdashboard: Not installed
2023-05-24 16:49:07,436:INFO:             autoviz: Not installed
2023-05-24 16:49:07,436:INFO:           fairlearn: Not installed
2023-05-24 16:49:07,436:INFO:             xgboost: Not installed
2023-05-24 16:49:07,436:INFO:            catboost: Not installed
2023-05-24 16:49:07,436:INFO:              kmodes: Not installed
2023-05-24 16:49:07,436:INFO:             mlxtend: Not installed
2023-05-24 16:49:07,436:INFO:       statsforecast: Not installed
2023-05-24 16:49:07,436:INFO:        tune_sklearn: 0.4.5
2023-05-24 16:49:07,436:INFO:                 ray: 2.4.0
2023-05-24 16:49:07,436:INFO:            hyperopt: 0.2.7
2023-05-24 16:49:07,436:INFO:              optuna: 3.1.1
2023-05-24 16:49:07,436:INFO:               skopt: 0.9.0
2023-05-24 16:49:07,436:INFO:              mlflow: Not installed
2023-05-24 16:49:07,436:INFO:              gradio: Not installed
2023-05-24 16:49:07,436:INFO:             fastapi: Not installed
2023-05-24 16:49:07,436:INFO:             uvicorn: Not installed
2023-05-24 16:49:07,436:INFO:              m2cgen: Not installed
2023-05-24 16:49:07,436:INFO:           evidently: Not installed
2023-05-24 16:49:07,436:INFO:               fugue: Not installed
2023-05-24 16:49:07,436:INFO:           streamlit: Not installed
2023-05-24 16:49:07,437:INFO:             prophet: Not installed
2023-05-24 16:49:07,437:INFO:None
2023-05-24 16:49:07,437:INFO:Set up data.
2023-05-24 16:49:07,677:INFO:Set up train/test split.
2023-05-24 16:49:07,787:INFO:Set up index.
2023-05-24 16:49:07,791:INFO:Set up folding strategy.
2023-05-24 16:49:07,792:INFO:Assigning column types.
2023-05-24 16:49:07,855:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 16:49:07,908:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 16:49:07,922:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:49:07,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:07,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:08,027:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 16:49:08,028:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:49:08,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:08,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:08,053:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 16:49:08,091:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:49:08,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:08,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:08,155:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:49:08,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:08,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:08,180:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 16:49:08,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:08,243:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:08,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:08,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:08,306:INFO:Preparing preprocessing pipeline...
2023-05-24 16:49:08,315:INFO:Set up label encoding.
2023-05-24 16:49:08,315:INFO:Set up simple imputation.
2023-05-24 16:49:08,322:INFO:Set up column name cleaning.
2023-05-24 16:49:08,739:INFO:Finished creating preprocessing pipeline.
2023-05-24 16:49:08,749:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 16:49:08,749:INFO:Creating final display dataframe.
2023-05-24 16:49:09,977:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                              Review  
2                                          Multiclass  
3   Indifference: 0, Mixed: 1, Negative: 2, Positi...  
4                                        (46252, 507)  
5                                        (46252, 507)  
6                                        (32376, 507)  
7                                        (13876, 507)  
8                                                 506  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               a62d  
2023-05-24 16:49:10,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:10,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:10,155:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:10,155:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:10,156:INFO:setup() successfully completed in 2.88s...............
2023-05-24 16:49:10,455:INFO:PyCaret ClassificationExperiment
2023-05-24 16:49:10,455:INFO:Logging name: clf-default-name
2023-05-24 16:49:10,455:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 16:49:10,455:INFO:version 3.0.2
2023-05-24 16:49:10,455:INFO:Initializing setup()
2023-05-24 16:49:10,455:INFO:self.USI: 2da6
2023-05-24 16:49:10,455:INFO:self._variable_keys: {'target_param', '_available_plots', 'logging_param', 'html_param', 'seed', 'y_test', 'USI', 'fold_groups_param', 'log_plots_param', 'exp_name_log', 'idx', 'y', '_ml_usecase', 'X_train', 'fold_shuffle_param', 'gpu_n_jobs_param', 'pipeline', 'X_test', 'is_multiclass', 'X', 'data', 'gpu_param', 'fix_imbalance', 'exp_id', 'n_jobs_param', 'fold_generator', 'y_train', 'memory'}
2023-05-24 16:49:10,455:INFO:Checking environment
2023-05-24 16:49:10,456:INFO:python_version: 3.10.11
2023-05-24 16:49:10,456:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 16:49:10,456:INFO:machine: AMD64
2023-05-24 16:49:10,456:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 16:49:10,460:INFO:Memory: svmem(total=16889774080, available=8422293504, percent=50.1, used=8467480576, free=8422293504)
2023-05-24 16:49:10,460:INFO:Physical Core: 4
2023-05-24 16:49:10,460:INFO:Logical Core: 8
2023-05-24 16:49:10,460:INFO:Checking libraries
2023-05-24 16:49:10,460:INFO:System:
2023-05-24 16:49:10,460:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 16:49:10,460:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 16:49:10,460:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 16:49:10,460:INFO:PyCaret required dependencies:
2023-05-24 16:49:10,460:INFO:                 pip: 23.0.1
2023-05-24 16:49:10,460:INFO:          setuptools: 66.0.0
2023-05-24 16:49:10,460:INFO:             pycaret: 3.0.2
2023-05-24 16:49:10,460:INFO:             IPython: 8.13.2
2023-05-24 16:49:10,460:INFO:          ipywidgets: 8.0.6
2023-05-24 16:49:10,460:INFO:                tqdm: 4.65.0
2023-05-24 16:49:10,460:INFO:               numpy: 1.23.5
2023-05-24 16:49:10,460:INFO:              pandas: 1.5.3
2023-05-24 16:49:10,460:INFO:              jinja2: 3.1.2
2023-05-24 16:49:10,461:INFO:               scipy: 1.10.1
2023-05-24 16:49:10,461:INFO:              joblib: 1.2.0
2023-05-24 16:49:10,461:INFO:             sklearn: 1.2.2
2023-05-24 16:49:10,461:INFO:                pyod: 1.0.9
2023-05-24 16:49:10,461:INFO:            imblearn: 0.10.1
2023-05-24 16:49:10,461:INFO:   category_encoders: 2.6.1
2023-05-24 16:49:10,461:INFO:            lightgbm: 3.3.5
2023-05-24 16:49:10,461:INFO:               numba: 0.57.0
2023-05-24 16:49:10,461:INFO:            requests: 2.31.0
2023-05-24 16:49:10,461:INFO:          matplotlib: 3.7.1
2023-05-24 16:49:10,461:INFO:          scikitplot: 0.3.7
2023-05-24 16:49:10,462:INFO:         yellowbrick: 1.5
2023-05-24 16:49:10,462:INFO:              plotly: 5.14.1
2023-05-24 16:49:10,462:INFO:             kaleido: 0.2.1
2023-05-24 16:49:10,462:INFO:         statsmodels: 0.14.0
2023-05-24 16:49:10,462:INFO:              sktime: 0.17.0
2023-05-24 16:49:10,462:INFO:               tbats: 1.1.3
2023-05-24 16:49:10,462:INFO:            pmdarima: 2.0.3
2023-05-24 16:49:10,462:INFO:              psutil: 5.9.5
2023-05-24 16:49:10,462:INFO:PyCaret optional dependencies:
2023-05-24 16:49:10,462:INFO:                shap: Not installed
2023-05-24 16:49:10,462:INFO:           interpret: Not installed
2023-05-24 16:49:10,462:INFO:                umap: Not installed
2023-05-24 16:49:10,462:INFO:    pandas_profiling: Not installed
2023-05-24 16:49:10,462:INFO:  explainerdashboard: Not installed
2023-05-24 16:49:10,462:INFO:             autoviz: Not installed
2023-05-24 16:49:10,462:INFO:           fairlearn: Not installed
2023-05-24 16:49:10,462:INFO:             xgboost: Not installed
2023-05-24 16:49:10,462:INFO:            catboost: Not installed
2023-05-24 16:49:10,462:INFO:              kmodes: Not installed
2023-05-24 16:49:10,462:INFO:             mlxtend: Not installed
2023-05-24 16:49:10,463:INFO:       statsforecast: Not installed
2023-05-24 16:49:10,463:INFO:        tune_sklearn: 0.4.5
2023-05-24 16:49:10,463:INFO:                 ray: 2.4.0
2023-05-24 16:49:10,463:INFO:            hyperopt: 0.2.7
2023-05-24 16:49:10,463:INFO:              optuna: 3.1.1
2023-05-24 16:49:10,463:INFO:               skopt: 0.9.0
2023-05-24 16:49:10,463:INFO:              mlflow: Not installed
2023-05-24 16:49:10,463:INFO:              gradio: Not installed
2023-05-24 16:49:10,463:INFO:             fastapi: Not installed
2023-05-24 16:49:10,463:INFO:             uvicorn: Not installed
2023-05-24 16:49:10,463:INFO:              m2cgen: Not installed
2023-05-24 16:49:10,463:INFO:           evidently: Not installed
2023-05-24 16:49:10,463:INFO:               fugue: Not installed
2023-05-24 16:49:10,463:INFO:           streamlit: Not installed
2023-05-24 16:49:10,463:INFO:             prophet: Not installed
2023-05-24 16:49:10,463:INFO:None
2023-05-24 16:49:10,463:INFO:Set up data.
2023-05-24 16:49:10,700:INFO:Set up train/test split.
2023-05-24 16:49:10,824:INFO:Set up index.
2023-05-24 16:49:10,828:INFO:Set up folding strategy.
2023-05-24 16:49:10,828:INFO:Assigning column types.
2023-05-24 16:49:10,892:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 16:49:10,930:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 16:49:10,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:49:10,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:10,954:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:10,993:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 16:49:10,994:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:49:11,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:11,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:11,018:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 16:49:11,056:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:49:11,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:11,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:11,120:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 16:49:11,144:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:11,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:11,145:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 16:49:11,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:11,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:11,270:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:11,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:11,272:INFO:Preparing preprocessing pipeline...
2023-05-24 16:49:11,280:INFO:Set up label encoding.
2023-05-24 16:49:11,280:INFO:Set up simple imputation.
2023-05-24 16:49:11,287:INFO:Set up column name cleaning.
2023-05-24 16:49:11,562:INFO:Finished creating preprocessing pipeline.
2023-05-24 16:49:11,571:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 16:49:11,571:INFO:Creating final display dataframe.
2023-05-24 16:49:12,185:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                              Review  
2                                          Multiclass  
3   Indifference: 0, Mixed: 1, Negative: 2, Positi...  
4                                        (46252, 507)  
5                                        (46252, 507)  
6                                        (32376, 507)  
7                                        (13876, 507)  
8                                                 506  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               2da6  
2023-05-24 16:49:12,262:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:12,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:12,331:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:12,332:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 16:49:12,332:INFO:setup() successfully completed in 2.01s...............
2023-05-24 16:49:12,451:INFO:Initializing compare_models()
2023-05-24 16:49:12,451:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-24 16:49:12,451:INFO:Checking exceptions
2023-05-24 16:49:12,517:INFO:Preparing display monitor
2023-05-24 16:49:12,545:INFO:Initializing Logistic Regression
2023-05-24 16:49:12,546:INFO:Total runtime is 1.720587412516276e-05 minutes
2023-05-24 16:49:12,551:INFO:SubProcess create_model() called ==================================
2023-05-24 16:49:12,552:INFO:Initializing create_model()
2023-05-24 16:49:12,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:49:12,552:INFO:Checking exceptions
2023-05-24 16:49:12,552:INFO:Importing libraries
2023-05-24 16:49:12,554:INFO:Copying training dataset
2023-05-24 16:49:12,657:INFO:Defining folds
2023-05-24 16:49:12,657:INFO:Declaring metric variables
2023-05-24 16:49:12,662:INFO:Importing untrained model
2023-05-24 16:49:12,665:INFO:Logistic Regression Imported successfully
2023-05-24 16:49:12,671:INFO:Starting cross validation
2023-05-24 16:49:12,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:51:25,837:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:51:26,252:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:51:26,768:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:51:26,932:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:51:27,069:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:51:27,194:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:27,225:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:27,243:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:51:27,257:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:27,336:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:27,367:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:27,383:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:51:27,394:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:51:27,401:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:27,924:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:51:28,003:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,032:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,041:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,055:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,057:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:51:28,063:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,080:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:51:28,085:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,070:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,093:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,101:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:51:28,114:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,253:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:51:28,616:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,650:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,690:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:28,984:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:29,015:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:29,036:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:51:29,050:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:29,296:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:29,335:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:51:29,353:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:51:29,366:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:11,309:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:52:11,672:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:11,686:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:11,699:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:12,289:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 16:52:12,601:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:12,613:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:12,624:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:12,965:INFO:Calculating mean and std
2023-05-24 16:52:12,966:INFO:Creating metrics dataframe
2023-05-24 16:52:13,098:INFO:Uploading results into container
2023-05-24 16:52:13,099:INFO:Uploading model into container now
2023-05-24 16:52:13,099:INFO:_master_model_container: 1
2023-05-24 16:52:13,099:INFO:_display_container: 2
2023-05-24 16:52:13,100:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-24 16:52:13,100:INFO:create_model() successfully completed......................................
2023-05-24 16:52:13,170:INFO:SubProcess create_model() end ==================================
2023-05-24 16:52:13,170:INFO:Creating metrics dataframe
2023-05-24 16:52:13,180:INFO:Initializing K Neighbors Classifier
2023-05-24 16:52:13,180:INFO:Total runtime is 3.010578608512878 minutes
2023-05-24 16:52:13,184:INFO:SubProcess create_model() called ==================================
2023-05-24 16:52:13,184:INFO:Initializing create_model()
2023-05-24 16:52:13,184:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:52:13,184:INFO:Checking exceptions
2023-05-24 16:52:13,184:INFO:Importing libraries
2023-05-24 16:52:13,184:INFO:Copying training dataset
2023-05-24 16:52:13,270:INFO:Defining folds
2023-05-24 16:52:13,271:INFO:Declaring metric variables
2023-05-24 16:52:13,273:INFO:Importing untrained model
2023-05-24 16:52:13,278:INFO:K Neighbors Classifier Imported successfully
2023-05-24 16:52:13,285:INFO:Starting cross validation
2023-05-24 16:52:13,288:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:52:27,377:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:27,408:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:27,439:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:27,464:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:27,502:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:27,543:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:27,563:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:27,597:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:27,643:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:27,947:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:27,980:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:27,982:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,003:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,012:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,019:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,070:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,073:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,109:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,131:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,161:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,191:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,369:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,415:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:28,449:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:34,317:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:34,329:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:34,341:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:34,440:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:34,455:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:34,470:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:34,635:INFO:Calculating mean and std
2023-05-24 16:52:34,636:INFO:Creating metrics dataframe
2023-05-24 16:52:34,784:INFO:Uploading results into container
2023-05-24 16:52:34,784:INFO:Uploading model into container now
2023-05-24 16:52:34,785:INFO:_master_model_container: 2
2023-05-24 16:52:34,785:INFO:_display_container: 2
2023-05-24 16:52:34,785:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-24 16:52:34,785:INFO:create_model() successfully completed......................................
2023-05-24 16:52:34,855:INFO:SubProcess create_model() end ==================================
2023-05-24 16:52:34,855:INFO:Creating metrics dataframe
2023-05-24 16:52:34,867:INFO:Initializing Naive Bayes
2023-05-24 16:52:34,867:INFO:Total runtime is 3.3720292369524634 minutes
2023-05-24 16:52:34,871:INFO:SubProcess create_model() called ==================================
2023-05-24 16:52:34,871:INFO:Initializing create_model()
2023-05-24 16:52:34,871:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:52:34,871:INFO:Checking exceptions
2023-05-24 16:52:34,871:INFO:Importing libraries
2023-05-24 16:52:34,871:INFO:Copying training dataset
2023-05-24 16:52:34,957:INFO:Defining folds
2023-05-24 16:52:34,957:INFO:Declaring metric variables
2023-05-24 16:52:34,961:INFO:Importing untrained model
2023-05-24 16:52:34,966:INFO:Naive Bayes Imported successfully
2023-05-24 16:52:34,971:INFO:Starting cross validation
2023-05-24 16:52:34,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:52:37,745:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,783:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,813:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,821:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,850:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,879:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,887:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,888:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,888:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,892:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,915:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,915:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,921:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,925:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,930:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,947:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,947:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,950:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,951:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,956:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,971:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,984:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:37,985:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:38,019:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:39,689:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:39,702:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:39,717:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:39,778:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:39,791:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:39,807:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:40,046:INFO:Calculating mean and std
2023-05-24 16:52:40,047:INFO:Creating metrics dataframe
2023-05-24 16:52:40,191:INFO:Uploading results into container
2023-05-24 16:52:40,191:INFO:Uploading model into container now
2023-05-24 16:52:40,192:INFO:_master_model_container: 3
2023-05-24 16:52:40,192:INFO:_display_container: 2
2023-05-24 16:52:40,192:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-24 16:52:40,192:INFO:create_model() successfully completed......................................
2023-05-24 16:52:40,265:INFO:SubProcess create_model() end ==================================
2023-05-24 16:52:40,266:INFO:Creating metrics dataframe
2023-05-24 16:52:40,275:INFO:Initializing Decision Tree Classifier
2023-05-24 16:52:40,275:INFO:Total runtime is 3.462155433495839 minutes
2023-05-24 16:52:40,279:INFO:SubProcess create_model() called ==================================
2023-05-24 16:52:40,280:INFO:Initializing create_model()
2023-05-24 16:52:40,280:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:52:40,280:INFO:Checking exceptions
2023-05-24 16:52:40,281:INFO:Importing libraries
2023-05-24 16:52:40,281:INFO:Copying training dataset
2023-05-24 16:52:40,367:INFO:Defining folds
2023-05-24 16:52:40,367:INFO:Declaring metric variables
2023-05-24 16:52:40,370:INFO:Importing untrained model
2023-05-24 16:52:40,374:INFO:Decision Tree Classifier Imported successfully
2023-05-24 16:52:40,382:INFO:Starting cross validation
2023-05-24 16:52:40,385:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:52:47,773:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,774:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,814:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,816:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,841:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,843:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,864:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,897:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,900:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,930:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,953:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,955:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,959:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,986:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:47,996:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:48,016:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:48,025:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:48,035:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:48,051:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:48,077:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:48,105:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:48,110:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:48,131:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:48,170:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:51,583:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:51,595:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:51,607:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:51,684:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:51,699:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:51,715:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:52:51,929:INFO:Calculating mean and std
2023-05-24 16:52:51,931:INFO:Creating metrics dataframe
2023-05-24 16:52:52,087:INFO:Uploading results into container
2023-05-24 16:52:52,088:INFO:Uploading model into container now
2023-05-24 16:52:52,088:INFO:_master_model_container: 4
2023-05-24 16:52:52,088:INFO:_display_container: 2
2023-05-24 16:52:52,089:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-24 16:52:52,089:INFO:create_model() successfully completed......................................
2023-05-24 16:52:52,163:INFO:SubProcess create_model() end ==================================
2023-05-24 16:52:52,163:INFO:Creating metrics dataframe
2023-05-24 16:52:52,172:INFO:Initializing SVM - Linear Kernel
2023-05-24 16:52:52,172:INFO:Total runtime is 3.660449369748433 minutes
2023-05-24 16:52:52,174:INFO:SubProcess create_model() called ==================================
2023-05-24 16:52:52,175:INFO:Initializing create_model()
2023-05-24 16:52:52,175:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:52:52,175:INFO:Checking exceptions
2023-05-24 16:52:52,175:INFO:Importing libraries
2023-05-24 16:52:52,175:INFO:Copying training dataset
2023-05-24 16:52:52,266:INFO:Defining folds
2023-05-24 16:52:52,266:INFO:Declaring metric variables
2023-05-24 16:52:52,269:INFO:Importing untrained model
2023-05-24 16:52:52,274:INFO:SVM - Linear Kernel Imported successfully
2023-05-24 16:52:52,282:INFO:Starting cross validation
2023-05-24 16:52:52,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:53:02,247:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:53:02,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:02,286:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:02,301:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:02,314:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:02,731:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:53:02,742:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:02,773:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:02,805:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:03,471:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:53:03,482:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:03,508:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:03,523:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:03,536:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:04,851:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:53:04,897:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:04,942:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:04,960:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:04,972:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:05,309:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:53:05,321:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:05,352:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:05,371:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:05,390:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:05,410:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:53:05,436:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:05,470:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:05,504:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:06,272:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:53:06,279:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:06,304:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:06,315:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:06,326:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:07,243:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:53:07,252:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:07,269:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:07,276:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:07,283:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:08,859:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:53:08,864:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:08,875:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:08,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:08,890:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:12,103:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 16:53:12,107:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:12,119:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:12,124:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:12,130:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:12,373:INFO:Calculating mean and std
2023-05-24 16:53:12,375:INFO:Creating metrics dataframe
2023-05-24 16:53:12,507:INFO:Uploading results into container
2023-05-24 16:53:12,508:INFO:Uploading model into container now
2023-05-24 16:53:12,508:INFO:_master_model_container: 5
2023-05-24 16:53:12,509:INFO:_display_container: 2
2023-05-24 16:53:12,509:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-24 16:53:12,509:INFO:create_model() successfully completed......................................
2023-05-24 16:53:12,582:INFO:SubProcess create_model() end ==================================
2023-05-24 16:53:12,583:INFO:Creating metrics dataframe
2023-05-24 16:53:12,591:INFO:Initializing Ridge Classifier
2023-05-24 16:53:12,591:INFO:Total runtime is 4.000771637757619 minutes
2023-05-24 16:53:12,596:INFO:SubProcess create_model() called ==================================
2023-05-24 16:53:12,597:INFO:Initializing create_model()
2023-05-24 16:53:12,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:53:12,597:INFO:Checking exceptions
2023-05-24 16:53:12,597:INFO:Importing libraries
2023-05-24 16:53:12,598:INFO:Copying training dataset
2023-05-24 16:53:12,684:INFO:Defining folds
2023-05-24 16:53:12,684:INFO:Declaring metric variables
2023-05-24 16:53:12,687:INFO:Importing untrained model
2023-05-24 16:53:12,691:INFO:Ridge Classifier Imported successfully
2023-05-24 16:53:12,698:INFO:Starting cross validation
2023-05-24 16:53:12,702:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:53:15,264:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:53:15,275:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,300:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,314:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:15,325:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,354:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:53:15,364:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,392:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,405:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:15,416:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,540:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:53:15,551:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,576:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,590:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:15,603:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,634:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:53:15,645:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,648:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:53:15,672:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,689:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,701:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:53:15,706:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,713:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,718:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:15,724:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:15,731:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,737:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:53:15,738:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,739:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,752:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:15,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:53:15,764:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,770:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,777:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,806:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,820:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:15,821:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,833:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:15,838:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:15,852:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:17,226:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:53:17,232:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:17,246:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:17,252:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 16:53:17,258:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:17,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:17,271:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:17,273:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:17,281:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 16:53:17,288:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:17,590:INFO:Calculating mean and std
2023-05-24 16:53:17,591:INFO:Creating metrics dataframe
2023-05-24 16:53:17,743:INFO:Uploading results into container
2023-05-24 16:53:17,744:INFO:Uploading model into container now
2023-05-24 16:53:17,744:INFO:_master_model_container: 6
2023-05-24 16:53:17,744:INFO:_display_container: 2
2023-05-24 16:53:17,746:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-24 16:53:17,746:INFO:create_model() successfully completed......................................
2023-05-24 16:53:17,820:INFO:SubProcess create_model() end ==================================
2023-05-24 16:53:17,820:INFO:Creating metrics dataframe
2023-05-24 16:53:17,831:INFO:Initializing Random Forest Classifier
2023-05-24 16:53:17,832:INFO:Total runtime is 4.088120174407958 minutes
2023-05-24 16:53:17,834:INFO:SubProcess create_model() called ==================================
2023-05-24 16:53:17,836:INFO:Initializing create_model()
2023-05-24 16:53:17,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:53:17,836:INFO:Checking exceptions
2023-05-24 16:53:17,836:INFO:Importing libraries
2023-05-24 16:53:17,836:INFO:Copying training dataset
2023-05-24 16:53:17,923:INFO:Defining folds
2023-05-24 16:53:17,923:INFO:Declaring metric variables
2023-05-24 16:53:17,927:INFO:Importing untrained model
2023-05-24 16:53:17,932:INFO:Random Forest Classifier Imported successfully
2023-05-24 16:53:17,939:INFO:Starting cross validation
2023-05-24 16:53:17,941:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:53:47,398:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:53:47,499:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:53:49,098:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:49,106:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:49,116:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:53:49,135:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:49,156:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:49,166:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:49,184:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:49,279:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:53:49,355:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:53:49,384:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:53:49,427:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:53:49,457:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:53:50,085:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:50,116:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:50,144:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:50,517:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:53:52,809:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:52,885:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,027:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,059:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,081:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,237:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,240:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,340:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,350:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,356:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,437:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,451:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,553:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:53:53,562:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:00,263:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:00,272:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:00,275:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:00,284:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:00,288:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:00,296:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:00,607:INFO:Calculating mean and std
2023-05-24 16:54:00,608:INFO:Creating metrics dataframe
2023-05-24 16:54:00,771:INFO:Uploading results into container
2023-05-24 16:54:00,771:INFO:Uploading model into container now
2023-05-24 16:54:00,772:INFO:_master_model_container: 7
2023-05-24 16:54:00,772:INFO:_display_container: 2
2023-05-24 16:54:00,772:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-24 16:54:00,772:INFO:create_model() successfully completed......................................
2023-05-24 16:54:00,844:INFO:SubProcess create_model() end ==================================
2023-05-24 16:54:00,844:INFO:Creating metrics dataframe
2023-05-24 16:54:00,857:INFO:Initializing Quadratic Discriminant Analysis
2023-05-24 16:54:00,857:INFO:Total runtime is 4.805195959409077 minutes
2023-05-24 16:54:00,861:INFO:SubProcess create_model() called ==================================
2023-05-24 16:54:00,861:INFO:Initializing create_model()
2023-05-24 16:54:00,861:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:54:00,861:INFO:Checking exceptions
2023-05-24 16:54:00,861:INFO:Importing libraries
2023-05-24 16:54:00,861:INFO:Copying training dataset
2023-05-24 16:54:00,952:INFO:Defining folds
2023-05-24 16:54:00,952:INFO:Declaring metric variables
2023-05-24 16:54:00,955:INFO:Importing untrained model
2023-05-24 16:54:00,959:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-24 16:54:00,969:INFO:Starting cross validation
2023-05-24 16:54:00,972:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:54:05,450:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:54:05,500:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:54:05,521:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:54:05,521:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:54:05,594:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:54:05,602:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:54:05,606:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:54:05,620:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:54:12,299:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,345:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,379:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,456:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,495:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,533:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,539:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,567:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,572:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,593:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,599:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,600:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,609:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,639:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,650:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,655:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,681:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,691:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,770:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,800:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,818:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,829:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,849:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:12,880:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:14,571:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:54:14,775:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 16:54:16,967:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:16,981:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:16,993:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:17,087:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:17,101:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:17,113:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:17,314:INFO:Calculating mean and std
2023-05-24 16:54:17,316:INFO:Creating metrics dataframe
2023-05-24 16:54:17,520:INFO:Uploading results into container
2023-05-24 16:54:17,521:INFO:Uploading model into container now
2023-05-24 16:54:17,521:INFO:_master_model_container: 8
2023-05-24 16:54:17,521:INFO:_display_container: 2
2023-05-24 16:54:17,522:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-24 16:54:17,522:INFO:create_model() successfully completed......................................
2023-05-24 16:54:17,602:INFO:SubProcess create_model() end ==================================
2023-05-24 16:54:17,602:INFO:Creating metrics dataframe
2023-05-24 16:54:17,612:INFO:Initializing Ada Boost Classifier
2023-05-24 16:54:17,612:INFO:Total runtime is 5.084443505605061 minutes
2023-05-24 16:54:17,618:INFO:SubProcess create_model() called ==================================
2023-05-24 16:54:17,618:INFO:Initializing create_model()
2023-05-24 16:54:17,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:54:17,619:INFO:Checking exceptions
2023-05-24 16:54:17,619:INFO:Importing libraries
2023-05-24 16:54:17,619:INFO:Copying training dataset
2023-05-24 16:54:17,717:INFO:Defining folds
2023-05-24 16:54:17,717:INFO:Declaring metric variables
2023-05-24 16:54:17,721:INFO:Importing untrained model
2023-05-24 16:54:17,725:INFO:Ada Boost Classifier Imported successfully
2023-05-24 16:54:17,734:INFO:Starting cross validation
2023-05-24 16:54:17,737:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:54:36,753:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:36,784:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:36,817:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:37,061:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:37,104:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:37,164:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:37,188:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:37,216:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:37,245:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,515:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,544:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,571:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,666:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,693:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,719:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,818:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,850:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,878:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,927:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:38,954:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:39,062:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:39,090:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:39,117:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:46,801:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:46,812:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:46,825:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:46,939:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:46,952:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:46,964:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:54:47,148:INFO:Calculating mean and std
2023-05-24 16:54:47,149:INFO:Creating metrics dataframe
2023-05-24 16:54:47,319:INFO:Uploading results into container
2023-05-24 16:54:47,320:INFO:Uploading model into container now
2023-05-24 16:54:47,320:INFO:_master_model_container: 9
2023-05-24 16:54:47,320:INFO:_display_container: 2
2023-05-24 16:54:47,320:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-24 16:54:47,320:INFO:create_model() successfully completed......................................
2023-05-24 16:54:47,391:INFO:SubProcess create_model() end ==================================
2023-05-24 16:54:47,392:INFO:Creating metrics dataframe
2023-05-24 16:54:47,403:INFO:Initializing Gradient Boosting Classifier
2023-05-24 16:54:47,403:INFO:Total runtime is 5.580962765216826 minutes
2023-05-24 16:54:47,408:INFO:SubProcess create_model() called ==================================
2023-05-24 16:54:47,408:INFO:Initializing create_model()
2023-05-24 16:54:47,408:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:54:47,408:INFO:Checking exceptions
2023-05-24 16:54:47,409:INFO:Importing libraries
2023-05-24 16:54:47,409:INFO:Copying training dataset
2023-05-24 16:54:47,497:INFO:Defining folds
2023-05-24 16:54:47,498:INFO:Declaring metric variables
2023-05-24 16:54:47,503:INFO:Importing untrained model
2023-05-24 16:54:47,506:INFO:Gradient Boosting Classifier Imported successfully
2023-05-24 16:54:47,514:INFO:Starting cross validation
2023-05-24 16:54:47,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:57:34,957:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:57:35,105:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:57:35,187:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:57:35,379:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:57:35,442:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:57:35,610:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:57:35,935:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:57:36,212:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:57:36,442:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:57:36,537:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:57:36,636:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:57:36,739:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:57:36,877:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 16:57:36,913:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:57:36,999:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,026:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,052:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,157:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,184:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,215:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,281:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:57:37,317:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,362:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,408:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,445:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,506:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,555:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,572:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,611:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,656:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,825:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,856:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:37,887:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:38,169:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:38,202:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:38,254:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:38,302:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 16:57:38,858:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:38,880:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:57:38,906:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:58:58,418:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:58:58,430:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:58:58,443:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:58:58,660:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:58:58,672:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:58:58,685:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:58:58,926:INFO:Calculating mean and std
2023-05-24 16:58:58,927:INFO:Creating metrics dataframe
2023-05-24 16:58:59,067:INFO:Uploading results into container
2023-05-24 16:58:59,068:INFO:Uploading model into container now
2023-05-24 16:58:59,068:INFO:_master_model_container: 10
2023-05-24 16:58:59,068:INFO:_display_container: 2
2023-05-24 16:58:59,069:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-24 16:58:59,069:INFO:create_model() successfully completed......................................
2023-05-24 16:58:59,145:INFO:SubProcess create_model() end ==================================
2023-05-24 16:58:59,145:INFO:Creating metrics dataframe
2023-05-24 16:58:59,160:INFO:Initializing Linear Discriminant Analysis
2023-05-24 16:58:59,160:INFO:Total runtime is 9.776914223035176 minutes
2023-05-24 16:58:59,164:INFO:SubProcess create_model() called ==================================
2023-05-24 16:58:59,164:INFO:Initializing create_model()
2023-05-24 16:58:59,165:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:58:59,165:INFO:Checking exceptions
2023-05-24 16:58:59,165:INFO:Importing libraries
2023-05-24 16:58:59,165:INFO:Copying training dataset
2023-05-24 16:58:59,250:INFO:Defining folds
2023-05-24 16:58:59,250:INFO:Declaring metric variables
2023-05-24 16:58:59,254:INFO:Importing untrained model
2023-05-24 16:58:59,258:INFO:Linear Discriminant Analysis Imported successfully
2023-05-24 16:58:59,265:INFO:Starting cross validation
2023-05-24 16:58:59,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 16:59:13,061:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,087:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,114:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,294:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,318:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,332:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,334:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,339:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,347:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,365:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,373:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,376:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,380:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,382:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,410:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,410:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,415:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,425:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,434:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,458:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,475:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,478:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,524:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:13,549:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:18,585:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:18,597:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:18,611:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:18,835:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:18,846:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:18,858:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 16:59:19,100:INFO:Calculating mean and std
2023-05-24 16:59:19,102:INFO:Creating metrics dataframe
2023-05-24 16:59:19,246:INFO:Uploading results into container
2023-05-24 16:59:19,246:INFO:Uploading model into container now
2023-05-24 16:59:19,247:INFO:_master_model_container: 11
2023-05-24 16:59:19,247:INFO:_display_container: 2
2023-05-24 16:59:19,247:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-24 16:59:19,248:INFO:create_model() successfully completed......................................
2023-05-24 16:59:19,315:INFO:SubProcess create_model() end ==================================
2023-05-24 16:59:19,315:INFO:Creating metrics dataframe
2023-05-24 16:59:19,329:INFO:Initializing Extra Trees Classifier
2023-05-24 16:59:19,330:INFO:Total runtime is 10.113087419668833 minutes
2023-05-24 16:59:19,333:INFO:SubProcess create_model() called ==================================
2023-05-24 16:59:19,333:INFO:Initializing create_model()
2023-05-24 16:59:19,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 16:59:19,333:INFO:Checking exceptions
2023-05-24 16:59:19,333:INFO:Importing libraries
2023-05-24 16:59:19,334:INFO:Copying training dataset
2023-05-24 16:59:19,420:INFO:Defining folds
2023-05-24 16:59:19,420:INFO:Declaring metric variables
2023-05-24 16:59:19,426:INFO:Importing untrained model
2023-05-24 16:59:19,430:INFO:Extra Trees Classifier Imported successfully
2023-05-24 16:59:19,438:INFO:Starting cross validation
2023-05-24 16:59:19,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:00:09,025:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:00:09,182:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:00:10,886:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:00:11,390:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:00:11,752:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:11,760:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:11,785:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:11,792:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:11,822:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:11,823:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:11,910:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:00:12,094:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:00:12,209:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:00:12,233:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:12,339:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:12,432:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:00:12,437:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:12,693:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:00:12,925:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,024:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,060:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,070:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,071:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,105:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,105:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,196:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,212:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,234:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,262:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,289:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,542:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,573:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:13,602:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:27,752:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:27,764:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:27,777:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:27,928:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:27,945:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:27,965:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:28,212:INFO:Calculating mean and std
2023-05-24 17:00:28,215:INFO:Creating metrics dataframe
2023-05-24 17:00:28,353:INFO:Uploading results into container
2023-05-24 17:00:28,354:INFO:Uploading model into container now
2023-05-24 17:00:28,355:INFO:_master_model_container: 12
2023-05-24 17:00:28,355:INFO:_display_container: 2
2023-05-24 17:00:28,355:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-24 17:00:28,356:INFO:create_model() successfully completed......................................
2023-05-24 17:00:28,427:INFO:SubProcess create_model() end ==================================
2023-05-24 17:00:28,428:INFO:Creating metrics dataframe
2023-05-24 17:00:28,441:INFO:Initializing Light Gradient Boosting Machine
2023-05-24 17:00:28,441:INFO:Total runtime is 11.264932791392008 minutes
2023-05-24 17:00:28,445:INFO:SubProcess create_model() called ==================================
2023-05-24 17:00:28,445:INFO:Initializing create_model()
2023-05-24 17:00:28,445:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:00:28,445:INFO:Checking exceptions
2023-05-24 17:00:28,445:INFO:Importing libraries
2023-05-24 17:00:28,445:INFO:Copying training dataset
2023-05-24 17:00:28,531:INFO:Defining folds
2023-05-24 17:00:28,531:INFO:Declaring metric variables
2023-05-24 17:00:28,535:INFO:Importing untrained model
2023-05-24 17:00:28,540:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 17:00:28,547:INFO:Starting cross validation
2023-05-24 17:00:28,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:00:36,595:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:36,645:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:36,650:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:36,671:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:36,680:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:36,706:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:36,833:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:36,866:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:36,893:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,335:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,362:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,392:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,398:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,429:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,457:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,469:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,486:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,512:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,516:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,553:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,582:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,615:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,655:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:37,685:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:40,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:40,912:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:40,924:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:40,960:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:40,974:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:40,985:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:41,231:INFO:Calculating mean and std
2023-05-24 17:00:41,232:INFO:Creating metrics dataframe
2023-05-24 17:00:41,352:INFO:Uploading results into container
2023-05-24 17:00:41,353:INFO:Uploading model into container now
2023-05-24 17:00:41,354:INFO:_master_model_container: 13
2023-05-24 17:00:41,354:INFO:_display_container: 2
2023-05-24 17:00:41,355:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:00:41,355:INFO:create_model() successfully completed......................................
2023-05-24 17:00:41,425:INFO:SubProcess create_model() end ==================================
2023-05-24 17:00:41,426:INFO:Creating metrics dataframe
2023-05-24 17:00:41,439:INFO:Initializing Dummy Classifier
2023-05-24 17:00:41,439:INFO:Total runtime is 11.481568348407745 minutes
2023-05-24 17:00:41,442:INFO:SubProcess create_model() called ==================================
2023-05-24 17:00:41,442:INFO:Initializing create_model()
2023-05-24 17:00:41,442:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A4428BD60>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:00:41,443:INFO:Checking exceptions
2023-05-24 17:00:41,443:INFO:Importing libraries
2023-05-24 17:00:41,443:INFO:Copying training dataset
2023-05-24 17:00:41,529:INFO:Defining folds
2023-05-24 17:00:41,529:INFO:Declaring metric variables
2023-05-24 17:00:41,532:INFO:Importing untrained model
2023-05-24 17:00:41,535:INFO:Dummy Classifier Imported successfully
2023-05-24 17:00:41,544:INFO:Starting cross validation
2023-05-24 17:00:41,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:00:42,808:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,838:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,844:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,856:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:00:42,868:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,873:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,874:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,885:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,887:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:00:42,900:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,900:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,909:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,912:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,914:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:00:42,915:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,920:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,920:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,928:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,930:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:00:42,934:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,942:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,948:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,951:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:00:42,953:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,955:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,957:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:00:42,969:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:00:42,969:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,972:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:00:42,990:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,994:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:42,999:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:44,113:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:44,125:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:44,132:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:00:44,138:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:44,189:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:44,204:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:44,211:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:00:44,216:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:00:44,706:INFO:Calculating mean and std
2023-05-24 17:00:44,707:INFO:Creating metrics dataframe
2023-05-24 17:00:44,844:INFO:Uploading results into container
2023-05-24 17:00:44,845:INFO:Uploading model into container now
2023-05-24 17:00:44,845:INFO:_master_model_container: 14
2023-05-24 17:00:44,845:INFO:_display_container: 2
2023-05-24 17:00:44,845:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-24 17:00:44,847:INFO:create_model() successfully completed......................................
2023-05-24 17:00:44,919:INFO:SubProcess create_model() end ==================================
2023-05-24 17:00:44,919:INFO:Creating metrics dataframe
2023-05-24 17:00:44,940:INFO:Initializing create_model()
2023-05-24 17:00:44,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:00:44,940:INFO:Checking exceptions
2023-05-24 17:00:44,942:INFO:Importing libraries
2023-05-24 17:00:44,942:INFO:Copying training dataset
2023-05-24 17:00:45,027:INFO:Defining folds
2023-05-24 17:00:45,027:INFO:Declaring metric variables
2023-05-24 17:00:45,027:INFO:Importing untrained model
2023-05-24 17:00:45,027:INFO:Declaring custom model
2023-05-24 17:00:45,028:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 17:00:45,030:INFO:Cross validation set to False
2023-05-24 17:00:45,030:INFO:Fitting Model
2023-05-24 17:00:47,500:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:00:47,500:INFO:create_model() successfully completed......................................
2023-05-24 17:00:47,606:INFO:_master_model_container: 14
2023-05-24 17:00:47,606:INFO:_display_container: 2
2023-05-24 17:00:47,606:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:00:47,606:INFO:compare_models() successfully completed......................................
2023-05-24 17:01:55,985:INFO:Initializing tune_model()
2023-05-24 17:01:55,985:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=20, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>)
2023-05-24 17:01:55,986:INFO:Checking exceptions
2023-05-24 17:01:55,986:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-24 17:01:56,520:INFO:Copying training dataset
2023-05-24 17:01:56,638:INFO:Checking base model
2023-05-24 17:01:56,639:INFO:Base model : Light Gradient Boosting Machine
2023-05-24 17:01:56,649:INFO:Declaring metric variables
2023-05-24 17:01:56,653:INFO:Defining Hyperparameters
2023-05-24 17:01:56,758:INFO:Tuning with n_jobs=-1
2023-05-24 17:01:56,761:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-24 17:01:56,761:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-24 17:01:56,761:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-24 17:01:56,766:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-24 17:04:26,204:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:09:30,966:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:09:46,389:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:10:31,774:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:10:57,661:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:10:58,834:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:11:44,843:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:11:46,083:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:12:09,292:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:12:09,292:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:12:10,719:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:12:30,668:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:12:31,081:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:12:32,384:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:13:07,218:INFO:best_params: {'actual_estimator__num_leaves': 134, 'actual_estimator__learning_rate': 0.022000116228351185, 'actual_estimator__n_estimators': 198, 'actual_estimator__min_split_gain': 0.1051159633031119, 'actual_estimator__reg_alpha': 0.0008451604408774724, 'actual_estimator__reg_lambda': 1.5924359564068034e-06, 'actual_estimator__feature_fraction': 0.613127884231387, 'actual_estimator__bagging_fraction': 0.42646351258900694, 'actual_estimator__bagging_freq': 3, 'actual_estimator__min_child_samples': 2}
2023-05-24 17:13:07,218:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-05-24 17:13:07,218:WARNING:Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2666, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-05-24 17:13:07,220:INFO:Hyperparameter search completed
2023-05-24 17:13:07,220:INFO:SubProcess create_model() called ==================================
2023-05-24 17:13:07,221:INFO:Initializing create_model()
2023-05-24 17:13:07,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019A47E33970>, model_only=True, return_train_score=False, kwargs={'num_leaves': 134, 'learning_rate': 0.022000116228351185, 'n_estimators': 198, 'min_split_gain': 0.1051159633031119, 'reg_alpha': 0.0008451604408774724, 'reg_lambda': 1.5924359564068034e-06, 'feature_fraction': 0.613127884231387, 'bagging_fraction': 0.42646351258900694, 'bagging_freq': 3, 'min_child_samples': 2})
2023-05-24 17:13:07,221:INFO:Checking exceptions
2023-05-24 17:13:07,221:INFO:Importing libraries
2023-05-24 17:13:07,221:INFO:Copying training dataset
2023-05-24 17:13:07,330:INFO:Defining folds
2023-05-24 17:13:07,330:INFO:Declaring metric variables
2023-05-24 17:13:07,334:INFO:Importing untrained model
2023-05-24 17:13:07,334:INFO:Declaring custom model
2023-05-24 17:13:07,339:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 17:13:07,346:INFO:Starting cross validation
2023-05-24 17:13:07,348:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:13:18,195:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:13:18,199:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:13:18,332:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:13:18,424:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:13:18,961:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.18s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:13:19,017:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.27s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:13:19,136:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:13:19,245:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:13:22,577:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:22,605:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:22,658:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:22,662:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:22,695:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:22,736:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:22,780:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:22,821:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:22,869:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:23,820:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:23,853:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:23,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:23,892:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:23,944:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:23,974:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:24,147:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:24,178:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:24,230:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:24,236:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:24,273:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:24,285:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:24,313:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:24,320:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:24,374:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:27,390:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:27,403:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:27,424:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:27,424:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:27,437:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:27,449:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:27,796:INFO:Calculating mean and std
2023-05-24 17:13:27,797:INFO:Creating metrics dataframe
2023-05-24 17:13:27,804:INFO:Finalizing model
2023-05-24 17:13:35,948:INFO:Uploading results into container
2023-05-24 17:13:35,950:INFO:Uploading model into container now
2023-05-24 17:13:35,950:INFO:_master_model_container: 15
2023-05-24 17:13:35,950:INFO:_display_container: 3
2023-05-24 17:13:35,951:INFO:LGBMClassifier(bagging_fraction=0.42646351258900694, bagging_freq=3,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.613127884231387, importance_type='split',
               learning_rate=0.022000116228351185, max_depth=-1,
               min_child_samples=2, min_child_weight=0.001,
               min_split_gain=0.1051159633031119, n_estimators=198, n_jobs=-1,
               num_leaves=134, objective=None, random_state=123,
               reg_alpha=0.0008451604408774724,
               reg_lambda=1.5924359564068034e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:13:35,951:INFO:create_model() successfully completed......................................
2023-05-24 17:13:36,076:INFO:SubProcess create_model() end ==================================
2023-05-24 17:13:36,076:INFO:choose_better activated
2023-05-24 17:13:36,081:INFO:SubProcess create_model() called ==================================
2023-05-24 17:13:36,082:INFO:Initializing create_model()
2023-05-24 17:13:36,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019A4428BEB0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:13:36,082:INFO:Checking exceptions
2023-05-24 17:13:36,084:INFO:Importing libraries
2023-05-24 17:13:36,084:INFO:Copying training dataset
2023-05-24 17:13:36,176:INFO:Defining folds
2023-05-24 17:13:36,176:INFO:Declaring metric variables
2023-05-24 17:13:36,176:INFO:Importing untrained model
2023-05-24 17:13:36,176:INFO:Declaring custom model
2023-05-24 17:13:36,177:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 17:13:36,177:INFO:Starting cross validation
2023-05-24 17:13:36,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:13:37,776:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,789:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,803:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,817:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,831:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,837:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,843:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,845:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,853:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,857:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,864:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,867:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,867:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,879:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,889:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,891:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,893:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,903:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,907:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,916:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,924:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,935:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:37,942:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:39,508:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:39,520:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:39,533:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:39,707:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:39,723:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:39,737:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:13:40,379:INFO:Calculating mean and std
2023-05-24 17:13:40,380:INFO:Creating metrics dataframe
2023-05-24 17:13:40,382:INFO:Finalizing model
2023-05-24 17:13:40,942:INFO:Uploading results into container
2023-05-24 17:13:40,942:INFO:Uploading model into container now
2023-05-24 17:13:40,943:INFO:_master_model_container: 16
2023-05-24 17:13:40,943:INFO:_display_container: 4
2023-05-24 17:13:40,943:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:13:40,943:INFO:create_model() successfully completed......................................
2023-05-24 17:13:41,035:INFO:SubProcess create_model() end ==================================
2023-05-24 17:13:41,036:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.67
2023-05-24 17:13:41,037:INFO:LGBMClassifier(bagging_fraction=0.42646351258900694, bagging_freq=3,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.613127884231387, importance_type='split',
               learning_rate=0.022000116228351185, max_depth=-1,
               min_child_samples=2, min_child_weight=0.001,
               min_split_gain=0.1051159633031119, n_estimators=198, n_jobs=-1,
               num_leaves=134, objective=None, random_state=123,
               reg_alpha=0.0008451604408774724,
               reg_lambda=1.5924359564068034e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6724
2023-05-24 17:13:41,037:INFO:LGBMClassifier(bagging_fraction=0.42646351258900694, bagging_freq=3,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.613127884231387, importance_type='split',
               learning_rate=0.022000116228351185, max_depth=-1,
               min_child_samples=2, min_child_weight=0.001,
               min_split_gain=0.1051159633031119, n_estimators=198, n_jobs=-1,
               num_leaves=134, objective=None, random_state=123,
               reg_alpha=0.0008451604408774724,
               reg_lambda=1.5924359564068034e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-05-24 17:13:41,037:INFO:choose_better completed
2023-05-24 17:13:41,049:INFO:_master_model_container: 16
2023-05-24 17:13:41,049:INFO:_display_container: 3
2023-05-24 17:13:41,050:INFO:LGBMClassifier(bagging_fraction=0.42646351258900694, bagging_freq=3,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.613127884231387, importance_type='split',
               learning_rate=0.022000116228351185, max_depth=-1,
               min_child_samples=2, min_child_weight=0.001,
               min_split_gain=0.1051159633031119, n_estimators=198, n_jobs=-1,
               num_leaves=134, objective=None, random_state=123,
               reg_alpha=0.0008451604408774724,
               reg_lambda=1.5924359564068034e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:13:41,050:INFO:tune_model() successfully completed......................................
2023-05-24 17:35:08,335:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 17:35:08,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 17:35:08,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 17:35:08,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 17:35:09,089:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-24 17:36:50,664:INFO:PyCaret ClassificationExperiment
2023-05-24 17:36:50,664:INFO:Logging name: clf-default-name
2023-05-24 17:36:50,664:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 17:36:50,664:INFO:version 3.0.2
2023-05-24 17:36:50,665:INFO:Initializing setup()
2023-05-24 17:36:50,665:INFO:self.USI: 5f54
2023-05-24 17:36:50,665:INFO:self._variable_keys: {'X_train', 'logging_param', 'y_train', 'fold_groups_param', '_available_plots', 'X', 'X_test', 'pipeline', 'seed', 'y', 'n_jobs_param', 'idx', 'gpu_param', 'html_param', 'memory', 'gpu_n_jobs_param', 'fold_generator', 'y_test', 'data', 'exp_name_log', '_ml_usecase', 'exp_id', 'fix_imbalance', 'target_param', 'log_plots_param', 'fold_shuffle_param', 'is_multiclass', 'USI'}
2023-05-24 17:36:50,665:INFO:Checking environment
2023-05-24 17:36:50,665:INFO:python_version: 3.10.11
2023-05-24 17:36:50,665:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 17:36:50,665:INFO:machine: AMD64
2023-05-24 17:36:50,665:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 17:36:50,668:INFO:Memory: svmem(total=16889774080, available=7673495552, percent=54.6, used=9216278528, free=7673495552)
2023-05-24 17:36:50,668:INFO:Physical Core: 4
2023-05-24 17:36:50,668:INFO:Logical Core: 8
2023-05-24 17:36:50,668:INFO:Checking libraries
2023-05-24 17:36:50,668:INFO:System:
2023-05-24 17:36:50,668:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 17:36:50,670:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 17:36:50,670:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 17:36:50,670:INFO:PyCaret required dependencies:
2023-05-24 17:36:50,670:INFO:                 pip: 23.0.1
2023-05-24 17:36:50,670:INFO:          setuptools: 66.0.0
2023-05-24 17:36:50,670:INFO:             pycaret: 3.0.2
2023-05-24 17:36:50,670:INFO:             IPython: 8.13.2
2023-05-24 17:36:50,670:INFO:          ipywidgets: 8.0.6
2023-05-24 17:36:50,670:INFO:                tqdm: 4.65.0
2023-05-24 17:36:50,670:INFO:               numpy: 1.23.5
2023-05-24 17:36:50,670:INFO:              pandas: 1.5.3
2023-05-24 17:36:50,670:INFO:              jinja2: 3.1.2
2023-05-24 17:36:50,670:INFO:               scipy: 1.10.1
2023-05-24 17:36:50,670:INFO:              joblib: 1.2.0
2023-05-24 17:36:50,670:INFO:             sklearn: 1.2.2
2023-05-24 17:36:50,670:INFO:                pyod: 1.0.9
2023-05-24 17:36:50,670:INFO:            imblearn: 0.10.1
2023-05-24 17:36:50,671:INFO:   category_encoders: 2.6.1
2023-05-24 17:36:50,671:INFO:            lightgbm: 3.3.5
2023-05-24 17:36:50,671:INFO:               numba: 0.57.0
2023-05-24 17:36:50,671:INFO:            requests: 2.31.0
2023-05-24 17:36:50,671:INFO:          matplotlib: 3.7.1
2023-05-24 17:36:50,671:INFO:          scikitplot: 0.3.7
2023-05-24 17:36:50,671:INFO:         yellowbrick: 1.5
2023-05-24 17:36:50,671:INFO:              plotly: 5.14.1
2023-05-24 17:36:50,671:INFO:             kaleido: 0.2.1
2023-05-24 17:36:50,671:INFO:         statsmodels: 0.14.0
2023-05-24 17:36:50,671:INFO:              sktime: 0.17.0
2023-05-24 17:36:50,671:INFO:               tbats: 1.1.3
2023-05-24 17:36:50,671:INFO:            pmdarima: 2.0.3
2023-05-24 17:36:50,671:INFO:              psutil: 5.9.5
2023-05-24 17:36:50,671:INFO:PyCaret optional dependencies:
2023-05-24 17:36:50,679:INFO:                shap: Not installed
2023-05-24 17:36:50,679:INFO:           interpret: Not installed
2023-05-24 17:36:50,679:INFO:                umap: Not installed
2023-05-24 17:36:50,679:INFO:    pandas_profiling: Not installed
2023-05-24 17:36:50,679:INFO:  explainerdashboard: Not installed
2023-05-24 17:36:50,679:INFO:             autoviz: Not installed
2023-05-24 17:36:50,679:INFO:           fairlearn: Not installed
2023-05-24 17:36:50,679:INFO:             xgboost: Not installed
2023-05-24 17:36:50,679:INFO:            catboost: Not installed
2023-05-24 17:36:50,679:INFO:              kmodes: Not installed
2023-05-24 17:36:50,679:INFO:             mlxtend: Not installed
2023-05-24 17:36:50,680:INFO:       statsforecast: Not installed
2023-05-24 17:36:50,680:INFO:        tune_sklearn: 0.4.5
2023-05-24 17:36:50,680:INFO:                 ray: 2.4.0
2023-05-24 17:36:50,680:INFO:            hyperopt: 0.2.7
2023-05-24 17:36:50,680:INFO:              optuna: 3.1.1
2023-05-24 17:36:50,680:INFO:               skopt: 0.9.0
2023-05-24 17:36:50,680:INFO:              mlflow: Not installed
2023-05-24 17:36:50,680:INFO:              gradio: Not installed
2023-05-24 17:36:50,680:INFO:             fastapi: Not installed
2023-05-24 17:36:50,680:INFO:             uvicorn: Not installed
2023-05-24 17:36:50,680:INFO:              m2cgen: Not installed
2023-05-24 17:36:50,680:INFO:           evidently: Not installed
2023-05-24 17:36:50,680:INFO:               fugue: Not installed
2023-05-24 17:36:50,680:INFO:           streamlit: Not installed
2023-05-24 17:36:50,680:INFO:             prophet: Not installed
2023-05-24 17:36:50,680:INFO:None
2023-05-24 17:36:50,680:INFO:Set up data.
2023-05-24 17:36:50,919:INFO:Set up train/test split.
2023-05-24 17:36:51,028:INFO:Set up index.
2023-05-24 17:36:51,032:INFO:Set up folding strategy.
2023-05-24 17:36:51,032:INFO:Assigning column types.
2023-05-24 17:36:51,093:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 17:36:51,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 17:36:51,143:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 17:36:51,176:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,194:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,232:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 17:36:51,233:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 17:36:51,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,256:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 17:36:51,294:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 17:36:51,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,317:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,354:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 17:36:51,377:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,377:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,378:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 17:36:51,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,499:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:51,502:INFO:Preparing preprocessing pipeline...
2023-05-24 17:36:51,509:INFO:Set up label encoding.
2023-05-24 17:36:51,509:INFO:Set up simple imputation.
2023-05-24 17:36:51,517:INFO:Set up column name cleaning.
2023-05-24 17:36:52,177:INFO:Finished creating preprocessing pipeline.
2023-05-24 17:36:52,185:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 17:36:52,185:INFO:Creating final display dataframe.
2023-05-24 17:36:53,340:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                              Review  
2                                          Multiclass  
3   Indifference: 0, Mixed: 1, Negative: 2, Positi...  
4                                        (46252, 507)  
5                                        (46252, 507)  
6                                        (32376, 507)  
7                                        (13876, 507)  
8                                                 506  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               5f54  
2023-05-24 17:36:53,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:53,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:53,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:53,520:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:36:53,520:INFO:setup() successfully completed in 3.09s...............
2023-05-24 17:37:00,019:INFO:PyCaret ClassificationExperiment
2023-05-24 17:37:00,019:INFO:Logging name: clf-default-name
2023-05-24 17:37:00,019:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 17:37:00,019:INFO:version 3.0.2
2023-05-24 17:37:00,019:INFO:Initializing setup()
2023-05-24 17:37:00,019:INFO:self.USI: ff81
2023-05-24 17:37:00,019:INFO:self._variable_keys: {'X_train', 'logging_param', 'y_train', 'fold_groups_param', '_available_plots', 'X', 'X_test', 'pipeline', 'seed', 'y', 'n_jobs_param', 'idx', 'gpu_param', 'html_param', 'memory', 'gpu_n_jobs_param', 'fold_generator', 'y_test', 'data', 'exp_name_log', '_ml_usecase', 'exp_id', 'fix_imbalance', 'target_param', 'log_plots_param', 'fold_shuffle_param', 'is_multiclass', 'USI'}
2023-05-24 17:37:00,019:INFO:Checking environment
2023-05-24 17:37:00,019:INFO:python_version: 3.10.11
2023-05-24 17:37:00,019:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 17:37:00,019:INFO:machine: AMD64
2023-05-24 17:37:00,019:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 17:37:00,021:INFO:Memory: svmem(total=16889774080, available=7361597440, percent=56.4, used=9528176640, free=7361597440)
2023-05-24 17:37:00,021:INFO:Physical Core: 4
2023-05-24 17:37:00,021:INFO:Logical Core: 8
2023-05-24 17:37:00,021:INFO:Checking libraries
2023-05-24 17:37:00,022:INFO:System:
2023-05-24 17:37:00,022:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 17:37:00,022:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 17:37:00,022:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 17:37:00,022:INFO:PyCaret required dependencies:
2023-05-24 17:37:00,022:INFO:                 pip: 23.0.1
2023-05-24 17:37:00,022:INFO:          setuptools: 66.0.0
2023-05-24 17:37:00,022:INFO:             pycaret: 3.0.2
2023-05-24 17:37:00,022:INFO:             IPython: 8.13.2
2023-05-24 17:37:00,022:INFO:          ipywidgets: 8.0.6
2023-05-24 17:37:00,022:INFO:                tqdm: 4.65.0
2023-05-24 17:37:00,022:INFO:               numpy: 1.23.5
2023-05-24 17:37:00,022:INFO:              pandas: 1.5.3
2023-05-24 17:37:00,022:INFO:              jinja2: 3.1.2
2023-05-24 17:37:00,022:INFO:               scipy: 1.10.1
2023-05-24 17:37:00,022:INFO:              joblib: 1.2.0
2023-05-24 17:37:00,022:INFO:             sklearn: 1.2.2
2023-05-24 17:37:00,022:INFO:                pyod: 1.0.9
2023-05-24 17:37:00,022:INFO:            imblearn: 0.10.1
2023-05-24 17:37:00,022:INFO:   category_encoders: 2.6.1
2023-05-24 17:37:00,022:INFO:            lightgbm: 3.3.5
2023-05-24 17:37:00,022:INFO:               numba: 0.57.0
2023-05-24 17:37:00,022:INFO:            requests: 2.31.0
2023-05-24 17:37:00,022:INFO:          matplotlib: 3.7.1
2023-05-24 17:37:00,022:INFO:          scikitplot: 0.3.7
2023-05-24 17:37:00,022:INFO:         yellowbrick: 1.5
2023-05-24 17:37:00,022:INFO:              plotly: 5.14.1
2023-05-24 17:37:00,023:INFO:             kaleido: 0.2.1
2023-05-24 17:37:00,023:INFO:         statsmodels: 0.14.0
2023-05-24 17:37:00,023:INFO:              sktime: 0.17.0
2023-05-24 17:37:00,023:INFO:               tbats: 1.1.3
2023-05-24 17:37:00,023:INFO:            pmdarima: 2.0.3
2023-05-24 17:37:00,023:INFO:              psutil: 5.9.5
2023-05-24 17:37:00,023:INFO:PyCaret optional dependencies:
2023-05-24 17:37:00,023:INFO:                shap: Not installed
2023-05-24 17:37:00,023:INFO:           interpret: Not installed
2023-05-24 17:37:00,023:INFO:                umap: Not installed
2023-05-24 17:37:00,023:INFO:    pandas_profiling: Not installed
2023-05-24 17:37:00,023:INFO:  explainerdashboard: Not installed
2023-05-24 17:37:00,023:INFO:             autoviz: Not installed
2023-05-24 17:37:00,023:INFO:           fairlearn: Not installed
2023-05-24 17:37:00,023:INFO:             xgboost: Not installed
2023-05-24 17:37:00,023:INFO:            catboost: Not installed
2023-05-24 17:37:00,023:INFO:              kmodes: Not installed
2023-05-24 17:37:00,023:INFO:             mlxtend: Not installed
2023-05-24 17:37:00,023:INFO:       statsforecast: Not installed
2023-05-24 17:37:00,023:INFO:        tune_sklearn: 0.4.5
2023-05-24 17:37:00,023:INFO:                 ray: 2.4.0
2023-05-24 17:37:00,023:INFO:            hyperopt: 0.2.7
2023-05-24 17:37:00,023:INFO:              optuna: 3.1.1
2023-05-24 17:37:00,023:INFO:               skopt: 0.9.0
2023-05-24 17:37:00,023:INFO:              mlflow: Not installed
2023-05-24 17:37:00,023:INFO:              gradio: Not installed
2023-05-24 17:37:00,023:INFO:             fastapi: Not installed
2023-05-24 17:37:00,024:INFO:             uvicorn: Not installed
2023-05-24 17:37:00,024:INFO:              m2cgen: Not installed
2023-05-24 17:37:00,024:INFO:           evidently: Not installed
2023-05-24 17:37:00,024:INFO:               fugue: Not installed
2023-05-24 17:37:00,024:INFO:           streamlit: Not installed
2023-05-24 17:37:00,024:INFO:             prophet: Not installed
2023-05-24 17:37:00,024:INFO:None
2023-05-24 17:37:00,024:INFO:Set up data.
2023-05-24 17:37:00,259:INFO:Set up train/test split.
2023-05-24 17:37:00,370:INFO:Set up index.
2023-05-24 17:37:00,374:INFO:Set up folding strategy.
2023-05-24 17:37:00,374:INFO:Assigning column types.
2023-05-24 17:37:00,436:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 17:37:00,474:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 17:37:00,474:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 17:37:00,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,535:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 17:37:00,536:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 17:37:00,559:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,559:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,559:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 17:37:00,596:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 17:37:00,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,656:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 17:37:00,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,678:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 17:37:00,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:00,807:INFO:Preparing preprocessing pipeline...
2023-05-24 17:37:00,815:INFO:Set up label encoding.
2023-05-24 17:37:00,815:INFO:Set up simple imputation.
2023-05-24 17:37:00,823:INFO:Set up column name cleaning.
2023-05-24 17:37:01,106:INFO:Finished creating preprocessing pipeline.
2023-05-24 17:37:01,115:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 17:37:01,115:INFO:Creating final display dataframe.
2023-05-24 17:37:01,723:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                              Review  
2                                          Multiclass  
3   Indifference: 0, Mixed: 1, Negative: 2, Positi...  
4                                        (46252, 507)  
5                                        (46252, 507)  
6                                        (32376, 507)  
7                                        (13876, 507)  
8                                                 506  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               ff81  
2023-05-24 17:37:01,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:01,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:01,884:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:01,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 17:37:01,885:INFO:setup() successfully completed in 2.07s...............
2023-05-24 17:37:06,324:INFO:Initializing compare_models()
2023-05-24 17:37:06,324:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-24 17:37:06,324:INFO:Checking exceptions
2023-05-24 17:37:06,376:INFO:Preparing display monitor
2023-05-24 17:37:06,400:INFO:Initializing Logistic Regression
2023-05-24 17:37:06,400:INFO:Total runtime is 0.0 minutes
2023-05-24 17:37:06,406:INFO:SubProcess create_model() called ==================================
2023-05-24 17:37:06,406:INFO:Initializing create_model()
2023-05-24 17:37:06,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:37:06,406:INFO:Checking exceptions
2023-05-24 17:37:06,407:INFO:Importing libraries
2023-05-24 17:37:06,407:INFO:Copying training dataset
2023-05-24 17:37:06,520:INFO:Defining folds
2023-05-24 17:37:06,520:INFO:Declaring metric variables
2023-05-24 17:37:06,522:INFO:Importing untrained model
2023-05-24 17:37:06,527:INFO:Logistic Regression Imported successfully
2023-05-24 17:37:06,536:INFO:Starting cross validation
2023-05-24 17:37:06,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:39:16,363:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 17:39:17,631:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 17:39:17,678:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:17,718:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:17,734:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:39:17,748:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:19,145:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:19,181:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:19,201:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:39:19,225:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:21,644:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 17:39:21,713:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 17:39:22,380:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 17:39:22,920:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:22,949:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:22,964:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:39:22,964:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:23,127:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:23,148:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:23,172:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:39:23,179:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:23,447:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:23,475:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:23,492:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:39:23,500:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:24,115:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 17:39:24,937:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:24,948:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:24,979:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:25,265:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 17:39:25,562:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 17:39:25,978:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:26,020:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:26,031:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:39:26,031:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:26,203:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:26,230:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:39:26,245:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:39:26,257:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:08,141:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 17:40:08,571:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:08,586:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:08,593:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:40:08,599:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:09,319:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 17:40:09,665:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:09,665:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:09,681:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:40:09,681:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:10,018:INFO:Calculating mean and std
2023-05-24 17:40:10,020:INFO:Creating metrics dataframe
2023-05-24 17:40:10,245:INFO:Uploading results into container
2023-05-24 17:40:10,246:INFO:Uploading model into container now
2023-05-24 17:40:10,246:INFO:_master_model_container: 1
2023-05-24 17:40:10,248:INFO:_display_container: 2
2023-05-24 17:40:10,248:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-24 17:40:10,248:INFO:create_model() successfully completed......................................
2023-05-24 17:40:10,311:INFO:SubProcess create_model() end ==================================
2023-05-24 17:40:10,311:INFO:Creating metrics dataframe
2023-05-24 17:40:10,327:INFO:Initializing K Neighbors Classifier
2023-05-24 17:40:10,327:INFO:Total runtime is 3.065452261765798 minutes
2023-05-24 17:40:10,330:INFO:SubProcess create_model() called ==================================
2023-05-24 17:40:10,331:INFO:Initializing create_model()
2023-05-24 17:40:10,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:40:10,331:INFO:Checking exceptions
2023-05-24 17:40:10,331:INFO:Importing libraries
2023-05-24 17:40:10,331:INFO:Copying training dataset
2023-05-24 17:40:10,412:INFO:Defining folds
2023-05-24 17:40:10,412:INFO:Declaring metric variables
2023-05-24 17:40:10,412:INFO:Importing untrained model
2023-05-24 17:40:10,412:INFO:K Neighbors Classifier Imported successfully
2023-05-24 17:40:10,412:INFO:Starting cross validation
2023-05-24 17:40:10,429:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:40:25,352:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:25,384:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:25,411:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:25,682:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:25,729:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:25,771:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:25,846:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:25,880:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:25,911:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:25,933:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:25,977:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:26,025:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:26,413:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:26,497:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:26,553:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:26,673:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:26,698:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:26,725:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:27,165:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:27,198:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:27,216:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:27,264:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:27,279:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:27,316:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:32,932:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:32,952:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:32,965:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:32,975:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:32,990:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:33,007:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:33,295:INFO:Calculating mean and std
2023-05-24 17:40:33,295:INFO:Creating metrics dataframe
2023-05-24 17:40:33,492:INFO:Uploading results into container
2023-05-24 17:40:33,493:INFO:Uploading model into container now
2023-05-24 17:40:33,493:INFO:_master_model_container: 2
2023-05-24 17:40:33,493:INFO:_display_container: 2
2023-05-24 17:40:33,493:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-24 17:40:33,494:INFO:create_model() successfully completed......................................
2023-05-24 17:40:33,563:INFO:SubProcess create_model() end ==================================
2023-05-24 17:40:33,563:INFO:Creating metrics dataframe
2023-05-24 17:40:33,573:INFO:Initializing Naive Bayes
2023-05-24 17:40:33,573:INFO:Total runtime is 3.4528841733932496 minutes
2023-05-24 17:40:33,577:INFO:SubProcess create_model() called ==================================
2023-05-24 17:40:33,577:INFO:Initializing create_model()
2023-05-24 17:40:33,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:40:33,578:INFO:Checking exceptions
2023-05-24 17:40:33,578:INFO:Importing libraries
2023-05-24 17:40:33,578:INFO:Copying training dataset
2023-05-24 17:40:33,675:INFO:Defining folds
2023-05-24 17:40:33,675:INFO:Declaring metric variables
2023-05-24 17:40:33,679:INFO:Importing untrained model
2023-05-24 17:40:33,684:INFO:Naive Bayes Imported successfully
2023-05-24 17:40:33,691:INFO:Starting cross validation
2023-05-24 17:40:33,694:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:40:35,350:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-24 17:40:36,715:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:36,747:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:36,788:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:36,994:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:37,035:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:37,061:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:37,716:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:37,752:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:37,782:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:37,797:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:37,852:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:37,889:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:37,929:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:37,963:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:37,976:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:38,007:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:38,014:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:38,042:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:38,126:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:38,160:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:38,186:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:38,367:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:38,399:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:38,429:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:39,327:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:39,340:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:39,349:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:39,555:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:39,576:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:39,590:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:39,997:INFO:Calculating mean and std
2023-05-24 17:40:39,998:INFO:Creating metrics dataframe
2023-05-24 17:40:40,181:INFO:Uploading results into container
2023-05-24 17:40:40,181:INFO:Uploading model into container now
2023-05-24 17:40:40,182:INFO:_master_model_container: 3
2023-05-24 17:40:40,182:INFO:_display_container: 2
2023-05-24 17:40:40,182:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-24 17:40:40,182:INFO:create_model() successfully completed......................................
2023-05-24 17:40:40,250:INFO:SubProcess create_model() end ==================================
2023-05-24 17:40:40,250:INFO:Creating metrics dataframe
2023-05-24 17:40:40,261:INFO:Initializing Decision Tree Classifier
2023-05-24 17:40:40,261:INFO:Total runtime is 3.56433930794398 minutes
2023-05-24 17:40:40,264:INFO:SubProcess create_model() called ==================================
2023-05-24 17:40:40,265:INFO:Initializing create_model()
2023-05-24 17:40:40,265:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:40:40,265:INFO:Checking exceptions
2023-05-24 17:40:40,265:INFO:Importing libraries
2023-05-24 17:40:40,265:INFO:Copying training dataset
2023-05-24 17:40:40,350:INFO:Defining folds
2023-05-24 17:40:40,350:INFO:Declaring metric variables
2023-05-24 17:40:40,353:INFO:Importing untrained model
2023-05-24 17:40:40,357:INFO:Decision Tree Classifier Imported successfully
2023-05-24 17:40:40,365:INFO:Starting cross validation
2023-05-24 17:40:40,368:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:40:47,412:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:47,437:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:47,450:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:47,554:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:47,558:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:47,566:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:47,582:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:47,598:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:47,613:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:47,713:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:47,733:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:47,773:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,088:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,121:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,133:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,248:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,264:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,295:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,313:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,324:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,350:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,350:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,380:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:48,396:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:51,030:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:51,056:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:51,069:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:51,200:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:51,215:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:51,230:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:51,394:INFO:Calculating mean and std
2023-05-24 17:40:51,396:INFO:Creating metrics dataframe
2023-05-24 17:40:51,564:INFO:Uploading results into container
2023-05-24 17:40:51,564:INFO:Uploading model into container now
2023-05-24 17:40:51,564:INFO:_master_model_container: 4
2023-05-24 17:40:51,564:INFO:_display_container: 2
2023-05-24 17:40:51,564:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-24 17:40:51,564:INFO:create_model() successfully completed......................................
2023-05-24 17:40:51,633:INFO:SubProcess create_model() end ==================================
2023-05-24 17:40:51,633:INFO:Creating metrics dataframe
2023-05-24 17:40:51,648:INFO:Initializing SVM - Linear Kernel
2023-05-24 17:40:51,648:INFO:Total runtime is 3.754130184650421 minutes
2023-05-24 17:40:51,648:INFO:SubProcess create_model() called ==================================
2023-05-24 17:40:51,648:INFO:Initializing create_model()
2023-05-24 17:40:51,648:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:40:51,648:INFO:Checking exceptions
2023-05-24 17:40:51,648:INFO:Importing libraries
2023-05-24 17:40:51,648:INFO:Copying training dataset
2023-05-24 17:40:51,739:INFO:Defining folds
2023-05-24 17:40:51,739:INFO:Declaring metric variables
2023-05-24 17:40:51,742:INFO:Importing untrained model
2023-05-24 17:40:51,746:INFO:SVM - Linear Kernel Imported successfully
2023-05-24 17:40:51,750:INFO:Starting cross validation
2023-05-24 17:40:51,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:40:56,165:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 17:40:56,165:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,228:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,272:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,415:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 17:40:56,431:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,479:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,510:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,854:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 17:40:56,860:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 17:40:56,884:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,884:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 17:40:56,915:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,931:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,946:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:56,946:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:57,009:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:57,009:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 17:40:57,031:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:57,063:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:57,097:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:57,106:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 17:40:57,119:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:57,164:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:57,224:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:57,234:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 17:40:57,245:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:57,299:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:57,322:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:40:57,338:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:58,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 17:40:58,914:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:58,914:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:58,942:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:59,233:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 17:40:59,250:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:59,267:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:59,279:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:40:59,447:INFO:Calculating mean and std
2023-05-24 17:40:59,447:INFO:Creating metrics dataframe
2023-05-24 17:40:59,649:INFO:Uploading results into container
2023-05-24 17:40:59,650:INFO:Uploading model into container now
2023-05-24 17:40:59,650:INFO:_master_model_container: 5
2023-05-24 17:40:59,650:INFO:_display_container: 2
2023-05-24 17:40:59,651:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-24 17:40:59,651:INFO:create_model() successfully completed......................................
2023-05-24 17:40:59,720:INFO:SubProcess create_model() end ==================================
2023-05-24 17:40:59,721:INFO:Creating metrics dataframe
2023-05-24 17:40:59,731:INFO:Initializing Ridge Classifier
2023-05-24 17:40:59,731:INFO:Total runtime is 3.888840397198995 minutes
2023-05-24 17:40:59,734:INFO:SubProcess create_model() called ==================================
2023-05-24 17:40:59,734:INFO:Initializing create_model()
2023-05-24 17:40:59,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:40:59,734:INFO:Checking exceptions
2023-05-24 17:40:59,734:INFO:Importing libraries
2023-05-24 17:40:59,735:INFO:Copying training dataset
2023-05-24 17:40:59,827:INFO:Defining folds
2023-05-24 17:40:59,827:INFO:Declaring metric variables
2023-05-24 17:40:59,831:INFO:Importing untrained model
2023-05-24 17:40:59,835:INFO:Ridge Classifier Imported successfully
2023-05-24 17:40:59,844:INFO:Starting cross validation
2023-05-24 17:40:59,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:41:02,672:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 17:41:02,682:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,728:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,744:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:41:02,755:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 17:41:02,757:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,766:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,793:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,802:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 17:41:02,809:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:41:02,821:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 17:41:02,822:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,847:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,849:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,865:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,877:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,882:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:41:02,892:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:41:02,894:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,898:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 17:41:02,904:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,909:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 17:41:02,910:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,911:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 17:41:02,925:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,927:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,953:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,962:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,971:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:41:02,973:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,978:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:41:02,984:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,987:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:41:02,991:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:02,999:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:03,016:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 17:41:03,032:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:03,063:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:03,078:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:41:03,090:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:04,750:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 17:41:04,750:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:04,765:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:04,781:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:41:04,788:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:04,867:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 17:41:04,867:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:04,891:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:04,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:41:04,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:05,420:INFO:Calculating mean and std
2023-05-24 17:41:05,421:INFO:Creating metrics dataframe
2023-05-24 17:41:05,615:INFO:Uploading results into container
2023-05-24 17:41:05,615:INFO:Uploading model into container now
2023-05-24 17:41:05,615:INFO:_master_model_container: 6
2023-05-24 17:41:05,616:INFO:_display_container: 2
2023-05-24 17:41:05,616:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-24 17:41:05,616:INFO:create_model() successfully completed......................................
2023-05-24 17:41:05,684:INFO:SubProcess create_model() end ==================================
2023-05-24 17:41:05,684:INFO:Creating metrics dataframe
2023-05-24 17:41:05,693:INFO:Initializing Random Forest Classifier
2023-05-24 17:41:05,693:INFO:Total runtime is 3.988217385609945 minutes
2023-05-24 17:41:05,697:INFO:SubProcess create_model() called ==================================
2023-05-24 17:41:05,697:INFO:Initializing create_model()
2023-05-24 17:41:05,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:41:05,697:INFO:Checking exceptions
2023-05-24 17:41:05,698:INFO:Importing libraries
2023-05-24 17:41:05,698:INFO:Copying training dataset
2023-05-24 17:41:05,783:INFO:Defining folds
2023-05-24 17:41:05,783:INFO:Declaring metric variables
2023-05-24 17:41:05,787:INFO:Importing untrained model
2023-05-24 17:41:05,791:INFO:Random Forest Classifier Imported successfully
2023-05-24 17:41:05,798:INFO:Starting cross validation
2023-05-24 17:41:05,801:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:41:35,804:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:41:36,064:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:41:36,349:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:41:37,214:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:41:37,860:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:37,904:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:37,922:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:41:37,948:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:38,179:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:41:38,323:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:41:38,358:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:41:38,392:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:41:38,492:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:41:38,495:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:41:39,333:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:39,372:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:39,423:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:39,869:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:39,878:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:41:39,908:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:39,960:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:40,054:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:41:40,343:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:41:40,352:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:41:40,719:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:41:40,966:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,020:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,056:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,223:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,260:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,273:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,303:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,310:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,312:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,349:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,350:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,350:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,516:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,575:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:41,605:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:51,335:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:51,350:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:51,368:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:51,498:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:51,514:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:51,530:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:41:51,860:INFO:Calculating mean and std
2023-05-24 17:41:51,860:INFO:Creating metrics dataframe
2023-05-24 17:41:52,143:INFO:Uploading results into container
2023-05-24 17:41:52,159:INFO:Uploading model into container now
2023-05-24 17:41:52,159:INFO:_master_model_container: 7
2023-05-24 17:41:52,159:INFO:_display_container: 2
2023-05-24 17:41:52,159:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-24 17:41:52,159:INFO:create_model() successfully completed......................................
2023-05-24 17:41:52,237:INFO:SubProcess create_model() end ==================================
2023-05-24 17:41:52,237:INFO:Creating metrics dataframe
2023-05-24 17:41:52,253:INFO:Initializing Quadratic Discriminant Analysis
2023-05-24 17:41:52,253:INFO:Total runtime is 4.764204072952271 minutes
2023-05-24 17:41:52,253:INFO:SubProcess create_model() called ==================================
2023-05-24 17:41:52,268:INFO:Initializing create_model()
2023-05-24 17:41:52,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:41:52,268:INFO:Checking exceptions
2023-05-24 17:41:52,268:INFO:Importing libraries
2023-05-24 17:41:52,268:INFO:Copying training dataset
2023-05-24 17:41:52,378:INFO:Defining folds
2023-05-24 17:41:52,378:INFO:Declaring metric variables
2023-05-24 17:41:52,394:INFO:Importing untrained model
2023-05-24 17:41:52,404:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-24 17:41:52,418:INFO:Starting cross validation
2023-05-24 17:41:52,419:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:41:55,829:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 17:41:56,645:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 17:41:56,677:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 17:41:57,068:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 17:41:57,115:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 17:41:57,225:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 17:41:57,382:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 17:41:57,572:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 17:42:00,998:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:42:02,893:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:02,956:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:03,018:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:03,913:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:03,968:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,026:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,177:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,209:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,209:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,281:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,284:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,312:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,350:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,384:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,388:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,542:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,543:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,573:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,575:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,609:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:04,613:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:05,183:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:05,243:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:05,278:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:07,005:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 17:42:07,024:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 17:42:09,701:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:09,717:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:09,717:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:09,733:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:09,733:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:09,733:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:10,049:INFO:Calculating mean and std
2023-05-24 17:42:10,049:INFO:Creating metrics dataframe
2023-05-24 17:42:10,233:INFO:Uploading results into container
2023-05-24 17:42:10,234:INFO:Uploading model into container now
2023-05-24 17:42:10,234:INFO:_master_model_container: 8
2023-05-24 17:42:10,234:INFO:_display_container: 2
2023-05-24 17:42:10,234:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-24 17:42:10,234:INFO:create_model() successfully completed......................................
2023-05-24 17:42:10,301:INFO:SubProcess create_model() end ==================================
2023-05-24 17:42:10,302:INFO:Creating metrics dataframe
2023-05-24 17:42:10,311:INFO:Initializing Ada Boost Classifier
2023-05-24 17:42:10,312:INFO:Total runtime is 5.0652010718981435 minutes
2023-05-24 17:42:10,316:INFO:SubProcess create_model() called ==================================
2023-05-24 17:42:10,316:INFO:Initializing create_model()
2023-05-24 17:42:10,316:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:42:10,316:INFO:Checking exceptions
2023-05-24 17:42:10,316:INFO:Importing libraries
2023-05-24 17:42:10,316:INFO:Copying training dataset
2023-05-24 17:42:10,383:INFO:Defining folds
2023-05-24 17:42:10,383:INFO:Declaring metric variables
2023-05-24 17:42:10,399:INFO:Importing untrained model
2023-05-24 17:42:10,403:INFO:Ada Boost Classifier Imported successfully
2023-05-24 17:42:10,411:INFO:Starting cross validation
2023-05-24 17:42:10,414:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:42:29,200:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,232:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,265:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,332:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,363:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,399:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,766:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,797:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,812:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,868:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,931:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,931:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:29,975:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:30,001:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:30,052:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:30,099:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:30,132:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:30,766:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:30,783:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:30,799:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:31,099:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:31,119:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:31,167:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:38,361:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:38,377:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:38,390:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:38,467:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:38,480:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:38,491:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:42:38,717:INFO:Calculating mean and std
2023-05-24 17:42:38,717:INFO:Creating metrics dataframe
2023-05-24 17:42:38,898:INFO:Uploading results into container
2023-05-24 17:42:38,899:INFO:Uploading model into container now
2023-05-24 17:42:38,899:INFO:_master_model_container: 9
2023-05-24 17:42:38,899:INFO:_display_container: 2
2023-05-24 17:42:38,900:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-24 17:42:38,900:INFO:create_model() successfully completed......................................
2023-05-24 17:42:38,965:INFO:SubProcess create_model() end ==================================
2023-05-24 17:42:38,965:INFO:Creating metrics dataframe
2023-05-24 17:42:38,981:INFO:Initializing Gradient Boosting Classifier
2023-05-24 17:42:38,981:INFO:Total runtime is 5.543011176586152 minutes
2023-05-24 17:42:38,985:INFO:SubProcess create_model() called ==================================
2023-05-24 17:42:38,986:INFO:Initializing create_model()
2023-05-24 17:42:38,986:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:42:38,986:INFO:Checking exceptions
2023-05-24 17:42:38,986:INFO:Importing libraries
2023-05-24 17:42:38,986:INFO:Copying training dataset
2023-05-24 17:42:39,065:INFO:Defining folds
2023-05-24 17:42:39,065:INFO:Declaring metric variables
2023-05-24 17:42:39,065:INFO:Importing untrained model
2023-05-24 17:42:39,065:INFO:Gradient Boosting Classifier Imported successfully
2023-05-24 17:42:39,083:INFO:Starting cross validation
2023-05-24 17:42:39,086:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:45:19,272:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:45:19,351:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:45:19,447:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:45:19,751:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:45:19,924:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:19,950:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:20,008:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:20,480:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:45:20,646:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:45:20,948:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:45:21,106:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:21,131:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:21,155:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:21,312:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:21,352:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:21,379:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:21,719:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:21,742:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:21,770:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:24,312:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:24,340:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:24,355:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:24,834:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:24,861:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:24,884:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:25,602:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:25,635:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:25,650:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:25,651:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:25,663:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:45:25,672:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:46:46,378:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:46:46,393:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:46:46,407:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:46:46,706:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:46:46,706:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:46:46,731:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:46:46,969:INFO:Calculating mean and std
2023-05-24 17:46:46,971:INFO:Creating metrics dataframe
2023-05-24 17:46:47,122:INFO:Uploading results into container
2023-05-24 17:46:47,122:INFO:Uploading model into container now
2023-05-24 17:46:47,122:INFO:_master_model_container: 10
2023-05-24 17:46:47,122:INFO:_display_container: 2
2023-05-24 17:46:47,122:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-24 17:46:47,122:INFO:create_model() successfully completed......................................
2023-05-24 17:46:47,205:INFO:SubProcess create_model() end ==================================
2023-05-24 17:46:47,206:INFO:Creating metrics dataframe
2023-05-24 17:46:47,217:INFO:Initializing Linear Discriminant Analysis
2023-05-24 17:46:47,217:INFO:Total runtime is 9.68027884165446 minutes
2023-05-24 17:46:47,221:INFO:SubProcess create_model() called ==================================
2023-05-24 17:46:47,221:INFO:Initializing create_model()
2023-05-24 17:46:47,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:46:47,221:INFO:Checking exceptions
2023-05-24 17:46:47,221:INFO:Importing libraries
2023-05-24 17:46:47,222:INFO:Copying training dataset
2023-05-24 17:46:47,305:INFO:Defining folds
2023-05-24 17:46:47,305:INFO:Declaring metric variables
2023-05-24 17:46:47,308:INFO:Importing untrained model
2023-05-24 17:46:47,314:INFO:Linear Discriminant Analysis Imported successfully
2023-05-24 17:46:47,320:INFO:Starting cross validation
2023-05-24 17:46:47,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:47:02,527:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,538:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,577:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,590:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,590:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,613:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,624:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,626:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,659:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,687:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,705:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,762:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,766:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,794:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,796:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,963:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:02,966:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:03,000:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:03,009:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:03,028:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:03,040:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:03,051:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:03,073:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:03,111:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:09,272:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:09,288:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:09,304:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:09,346:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:09,358:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:09,370:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:47:09,636:INFO:Calculating mean and std
2023-05-24 17:47:09,637:INFO:Creating metrics dataframe
2023-05-24 17:47:09,853:INFO:Uploading results into container
2023-05-24 17:47:09,853:INFO:Uploading model into container now
2023-05-24 17:47:09,853:INFO:_master_model_container: 11
2023-05-24 17:47:09,856:INFO:_display_container: 2
2023-05-24 17:47:09,856:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-24 17:47:09,856:INFO:create_model() successfully completed......................................
2023-05-24 17:47:09,923:INFO:SubProcess create_model() end ==================================
2023-05-24 17:47:09,923:INFO:Creating metrics dataframe
2023-05-24 17:47:09,938:INFO:Initializing Extra Trees Classifier
2023-05-24 17:47:09,938:INFO:Total runtime is 10.058965798219045 minutes
2023-05-24 17:47:09,954:INFO:SubProcess create_model() called ==================================
2023-05-24 17:47:09,954:INFO:Initializing create_model()
2023-05-24 17:47:09,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:47:09,954:INFO:Checking exceptions
2023-05-24 17:47:09,954:INFO:Importing libraries
2023-05-24 17:47:09,954:INFO:Copying training dataset
2023-05-24 17:47:10,040:INFO:Defining folds
2023-05-24 17:47:10,040:INFO:Declaring metric variables
2023-05-24 17:47:10,040:INFO:Importing untrained model
2023-05-24 17:47:10,040:INFO:Extra Trees Classifier Imported successfully
2023-05-24 17:47:10,056:INFO:Starting cross validation
2023-05-24 17:47:10,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:47:12,444:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-24 17:47:54,090:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:47:57,113:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-24 17:47:59,299:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:47:59,591:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:48:01,414:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:48:01,419:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:48:01,901:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:48:02,065:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:02,135:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:02,234:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:02,561:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:48:02,869:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:48:02,903:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:48:02,934:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:48:03,064:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:48:03,068:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:03,070:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:48:03,111:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:03,164:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:03,587:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:03,635:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:03,668:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:03,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:03,914:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:03,946:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:03,951:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:48:04,255:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:48:04,298:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:48:04,437:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:48:04,780:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:04,810:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:04,838:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:05,006:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:05,079:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:05,098:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:05,153:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:05,156:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:05,184:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:05,186:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:05,249:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:05,304:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:19,443:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:19,456:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:19,477:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:19,783:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:19,798:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:19,811:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:20,060:INFO:Calculating mean and std
2023-05-24 17:48:20,061:INFO:Creating metrics dataframe
2023-05-24 17:48:20,253:INFO:Uploading results into container
2023-05-24 17:48:20,253:INFO:Uploading model into container now
2023-05-24 17:48:20,254:INFO:_master_model_container: 12
2023-05-24 17:48:20,254:INFO:_display_container: 2
2023-05-24 17:48:20,254:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-24 17:48:20,254:INFO:create_model() successfully completed......................................
2023-05-24 17:48:20,328:INFO:SubProcess create_model() end ==================================
2023-05-24 17:48:20,328:INFO:Creating metrics dataframe
2023-05-24 17:48:20,339:INFO:Initializing Light Gradient Boosting Machine
2023-05-24 17:48:20,339:INFO:Total runtime is 11.232310716311137 minutes
2023-05-24 17:48:20,345:INFO:SubProcess create_model() called ==================================
2023-05-24 17:48:20,345:INFO:Initializing create_model()
2023-05-24 17:48:20,345:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:48:20,345:INFO:Checking exceptions
2023-05-24 17:48:20,345:INFO:Importing libraries
2023-05-24 17:48:20,345:INFO:Copying training dataset
2023-05-24 17:48:20,432:INFO:Defining folds
2023-05-24 17:48:20,432:INFO:Declaring metric variables
2023-05-24 17:48:20,435:INFO:Importing untrained model
2023-05-24 17:48:20,439:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 17:48:20,448:INFO:Starting cross validation
2023-05-24 17:48:20,451:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:48:29,844:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:29,871:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:29,914:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,004:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,061:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,103:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,229:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,270:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,272:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,303:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,304:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,347:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,398:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,432:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,441:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,484:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,512:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,514:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,851:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,886:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,919:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,929:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:30,970:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:31,001:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:34,555:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:34,567:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:34,583:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:34,584:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:34,598:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:34,612:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:34,919:INFO:Calculating mean and std
2023-05-24 17:48:34,920:INFO:Creating metrics dataframe
2023-05-24 17:48:35,114:INFO:Uploading results into container
2023-05-24 17:48:35,115:INFO:Uploading model into container now
2023-05-24 17:48:35,116:INFO:_master_model_container: 13
2023-05-24 17:48:35,116:INFO:_display_container: 2
2023-05-24 17:48:35,117:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:48:35,117:INFO:create_model() successfully completed......................................
2023-05-24 17:48:35,186:INFO:SubProcess create_model() end ==================================
2023-05-24 17:48:35,186:INFO:Creating metrics dataframe
2023-05-24 17:48:35,197:INFO:Initializing Dummy Classifier
2023-05-24 17:48:35,198:INFO:Total runtime is 11.47994419336319 minutes
2023-05-24 17:48:35,201:INFO:SubProcess create_model() called ==================================
2023-05-24 17:48:35,201:INFO:Initializing create_model()
2023-05-24 17:48:35,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8ECABEB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:48:35,201:INFO:Checking exceptions
2023-05-24 17:48:35,201:INFO:Importing libraries
2023-05-24 17:48:35,201:INFO:Copying training dataset
2023-05-24 17:48:35,290:INFO:Defining folds
2023-05-24 17:48:35,290:INFO:Declaring metric variables
2023-05-24 17:48:35,294:INFO:Importing untrained model
2023-05-24 17:48:35,298:INFO:Dummy Classifier Imported successfully
2023-05-24 17:48:35,304:INFO:Starting cross validation
2023-05-24 17:48:35,307:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:48:36,606:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,629:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,632:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,633:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,641:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,643:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,649:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:48:36,655:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,664:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,665:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,666:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,668:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,670:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,670:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,671:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:48:36,678:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:48:36,683:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,684:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:48:36,685:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:48:36,690:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,691:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,694:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,696:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,700:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,702:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,705:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:48:36,710:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:48:36,717:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,719:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:48:36,722:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:36,743:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:37,937:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:37,950:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:37,957:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:48:37,963:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:37,986:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:38,000:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:38,006:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 17:48:38,024:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:48:38,968:INFO:Calculating mean and std
2023-05-24 17:48:38,969:INFO:Creating metrics dataframe
2023-05-24 17:48:39,161:INFO:Uploading results into container
2023-05-24 17:48:39,162:INFO:Uploading model into container now
2023-05-24 17:48:39,162:INFO:_master_model_container: 14
2023-05-24 17:48:39,163:INFO:_display_container: 2
2023-05-24 17:48:39,163:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-24 17:48:39,163:INFO:create_model() successfully completed......................................
2023-05-24 17:48:39,234:INFO:SubProcess create_model() end ==================================
2023-05-24 17:48:39,234:INFO:Creating metrics dataframe
2023-05-24 17:48:39,257:INFO:Initializing create_model()
2023-05-24 17:48:39,257:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:48:39,257:INFO:Checking exceptions
2023-05-24 17:48:39,260:INFO:Importing libraries
2023-05-24 17:48:39,260:INFO:Copying training dataset
2023-05-24 17:48:39,343:INFO:Defining folds
2023-05-24 17:48:39,343:INFO:Declaring metric variables
2023-05-24 17:48:39,343:INFO:Importing untrained model
2023-05-24 17:48:39,343:INFO:Declaring custom model
2023-05-24 17:48:39,344:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 17:48:39,347:INFO:Cross validation set to False
2023-05-24 17:48:39,347:INFO:Fitting Model
2023-05-24 17:48:41,860:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:48:41,860:INFO:create_model() successfully completed......................................
2023-05-24 17:48:41,974:INFO:_master_model_container: 14
2023-05-24 17:48:41,974:INFO:_display_container: 2
2023-05-24 17:48:41,975:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:48:41,975:INFO:compare_models() successfully completed......................................
2023-05-24 17:49:07,599:INFO:Initializing tune_model()
2023-05-24 17:49:07,600:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=20, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>)
2023-05-24 17:49:07,600:INFO:Checking exceptions
2023-05-24 17:49:07,600:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-24 17:49:08,121:INFO:Copying training dataset
2023-05-24 17:49:08,191:INFO:Checking base model
2023-05-24 17:49:08,191:INFO:Base model : Light Gradient Boosting Machine
2023-05-24 17:49:08,198:INFO:Declaring metric variables
2023-05-24 17:49:08,204:INFO:Defining Hyperparameters
2023-05-24 17:49:08,315:INFO:Tuning with n_jobs=-1
2023-05-24 17:49:08,317:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-24 17:49:08,317:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-24 17:49:08,317:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-24 17:49:08,323:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-24 17:52:00,052:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 17:53:51,772:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:56:04,581:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:57:24,698:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 17:57:44,389:INFO:best_params: {'actual_estimator__num_leaves': 47, 'actual_estimator__learning_rate': 0.08730628786863978, 'actual_estimator__n_estimators': 254, 'actual_estimator__min_split_gain': 0.9716995697840961, 'actual_estimator__reg_alpha': 0.00032018660206183726, 'actual_estimator__reg_lambda': 1.0431406253138912e-09, 'actual_estimator__feature_fraction': 0.742053349876433, 'actual_estimator__bagging_fraction': 0.7015198135105641, 'actual_estimator__bagging_freq': 0, 'actual_estimator__min_child_samples': 88}
2023-05-24 17:57:44,390:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-05-24 17:57:44,390:WARNING:Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2666, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-05-24 17:57:44,391:INFO:Hyperparameter search completed
2023-05-24 17:57:44,391:INFO:SubProcess create_model() called ==================================
2023-05-24 17:57:44,392:INFO:Initializing create_model()
2023-05-24 17:57:44,392:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A8EC85060>, model_only=True, return_train_score=False, kwargs={'num_leaves': 47, 'learning_rate': 0.08730628786863978, 'n_estimators': 254, 'min_split_gain': 0.9716995697840961, 'reg_alpha': 0.00032018660206183726, 'reg_lambda': 1.0431406253138912e-09, 'feature_fraction': 0.742053349876433, 'bagging_fraction': 0.7015198135105641, 'bagging_freq': 0, 'min_child_samples': 88})
2023-05-24 17:57:44,393:INFO:Checking exceptions
2023-05-24 17:57:44,393:INFO:Importing libraries
2023-05-24 17:57:44,393:INFO:Copying training dataset
2023-05-24 17:57:44,518:INFO:Defining folds
2023-05-24 17:57:44,518:INFO:Declaring metric variables
2023-05-24 17:57:44,525:INFO:Importing untrained model
2023-05-24 17:57:44,525:INFO:Declaring custom model
2023-05-24 17:57:44,531:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 17:57:44,539:INFO:Starting cross validation
2023-05-24 17:57:44,542:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:57:52,189:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,215:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,230:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,230:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,242:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,244:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,255:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,258:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,258:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,277:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,280:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,282:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,289:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,294:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,294:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,299:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,300:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,305:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,305:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,326:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,329:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,333:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,346:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:52,357:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:54,172:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:54,184:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:54,196:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:54,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:54,271:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:54,283:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:55,471:INFO:Calculating mean and std
2023-05-24 17:57:55,472:INFO:Creating metrics dataframe
2023-05-24 17:57:55,478:INFO:Finalizing model
2023-05-24 17:57:57,891:INFO:Uploading results into container
2023-05-24 17:57:57,892:INFO:Uploading model into container now
2023-05-24 17:57:57,894:INFO:_master_model_container: 15
2023-05-24 17:57:57,894:INFO:_display_container: 3
2023-05-24 17:57:57,895:INFO:LGBMClassifier(bagging_fraction=0.7015198135105641, bagging_freq=0,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.742053349876433, importance_type='split',
               learning_rate=0.08730628786863978, max_depth=-1,
               min_child_samples=88, min_child_weight=0.001,
               min_split_gain=0.9716995697840961, n_estimators=254, n_jobs=-1,
               num_leaves=47, objective=None, random_state=123,
               reg_alpha=0.00032018660206183726,
               reg_lambda=1.0431406253138912e-09, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:57:57,895:INFO:create_model() successfully completed......................................
2023-05-24 17:57:58,005:INFO:SubProcess create_model() end ==================================
2023-05-24 17:57:58,005:INFO:choose_better activated
2023-05-24 17:57:58,008:INFO:SubProcess create_model() called ==================================
2023-05-24 17:57:58,009:INFO:Initializing create_model()
2023-05-24 17:57:58,009:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014A8D112DD0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-24 17:57:58,009:INFO:Checking exceptions
2023-05-24 17:57:58,011:INFO:Importing libraries
2023-05-24 17:57:58,012:INFO:Copying training dataset
2023-05-24 17:57:58,106:INFO:Defining folds
2023-05-24 17:57:58,106:INFO:Declaring metric variables
2023-05-24 17:57:58,106:INFO:Importing untrained model
2023-05-24 17:57:58,106:INFO:Declaring custom model
2023-05-24 17:57:58,107:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 17:57:58,107:INFO:Starting cross validation
2023-05-24 17:57:58,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 17:57:59,813:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,843:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,871:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,875:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,884:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,913:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,922:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,937:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,942:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,946:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,947:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,957:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,967:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,976:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:57:59,978:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:00,014:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:00,015:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:00,016:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:00,024:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:00,038:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:00,044:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:00,092:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:01,985:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:01,998:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:02,011:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:02,012:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:02,027:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:02,046:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 17:58:03,255:INFO:Calculating mean and std
2023-05-24 17:58:03,255:INFO:Creating metrics dataframe
2023-05-24 17:58:03,257:INFO:Finalizing model
2023-05-24 17:58:03,908:INFO:Uploading results into container
2023-05-24 17:58:03,909:INFO:Uploading model into container now
2023-05-24 17:58:03,909:INFO:_master_model_container: 16
2023-05-24 17:58:03,909:INFO:_display_container: 4
2023-05-24 17:58:03,909:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:58:03,909:INFO:create_model() successfully completed......................................
2023-05-24 17:58:03,988:INFO:SubProcess create_model() end ==================================
2023-05-24 17:58:03,989:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.6698
2023-05-24 17:58:03,989:INFO:LGBMClassifier(bagging_fraction=0.7015198135105641, bagging_freq=0,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.742053349876433, importance_type='split',
               learning_rate=0.08730628786863978, max_depth=-1,
               min_child_samples=88, min_child_weight=0.001,
               min_split_gain=0.9716995697840961, n_estimators=254, n_jobs=-1,
               num_leaves=47, objective=None, random_state=123,
               reg_alpha=0.00032018660206183726,
               reg_lambda=1.0431406253138912e-09, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.668
2023-05-24 17:58:03,990:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-05-24 17:58:03,990:INFO:choose_better completed
2023-05-24 17:58:03,990:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-05-24 17:58:04,000:INFO:_master_model_container: 16
2023-05-24 17:58:04,000:INFO:_display_container: 3
2023-05-24 17:58:04,001:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 17:58:04,001:INFO:tune_model() successfully completed......................................
2023-05-24 19:04:14,459:INFO:PyCaret ClassificationExperiment
2023-05-24 19:04:14,460:INFO:Logging name: clf-default-name
2023-05-24 19:04:14,460:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 19:04:14,460:INFO:version 3.0.2
2023-05-24 19:04:14,460:INFO:Initializing setup()
2023-05-24 19:04:14,460:INFO:self.USI: b41f
2023-05-24 19:04:14,460:INFO:self._variable_keys: {'X_train', 'logging_param', 'y_train', 'fold_groups_param', '_available_plots', 'X', 'X_test', 'pipeline', 'seed', 'y', 'n_jobs_param', 'idx', 'gpu_param', 'html_param', 'memory', 'gpu_n_jobs_param', 'fold_generator', 'y_test', 'data', 'exp_name_log', '_ml_usecase', 'exp_id', 'fix_imbalance', 'target_param', 'log_plots_param', 'fold_shuffle_param', 'is_multiclass', 'USI'}
2023-05-24 19:04:14,461:INFO:Checking environment
2023-05-24 19:04:14,461:INFO:python_version: 3.10.11
2023-05-24 19:04:14,461:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 19:04:14,461:INFO:machine: AMD64
2023-05-24 19:04:14,461:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 19:04:14,466:INFO:Memory: svmem(total=16889774080, available=7406481408, percent=56.1, used=9483292672, free=7406481408)
2023-05-24 19:04:14,467:INFO:Physical Core: 4
2023-05-24 19:04:14,467:INFO:Logical Core: 8
2023-05-24 19:04:14,467:INFO:Checking libraries
2023-05-24 19:04:14,467:INFO:System:
2023-05-24 19:04:14,467:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 19:04:14,468:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 19:04:14,468:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 19:04:14,468:INFO:PyCaret required dependencies:
2023-05-24 19:04:14,469:INFO:                 pip: 23.0.1
2023-05-24 19:04:14,469:INFO:          setuptools: 66.0.0
2023-05-24 19:04:14,469:INFO:             pycaret: 3.0.2
2023-05-24 19:04:14,469:INFO:             IPython: 8.13.2
2023-05-24 19:04:14,469:INFO:          ipywidgets: 8.0.6
2023-05-24 19:04:14,469:INFO:                tqdm: 4.65.0
2023-05-24 19:04:14,469:INFO:               numpy: 1.23.5
2023-05-24 19:04:14,469:INFO:              pandas: 1.5.3
2023-05-24 19:04:14,469:INFO:              jinja2: 3.1.2
2023-05-24 19:04:14,469:INFO:               scipy: 1.10.1
2023-05-24 19:04:14,469:INFO:              joblib: 1.2.0
2023-05-24 19:04:14,469:INFO:             sklearn: 1.2.2
2023-05-24 19:04:14,469:INFO:                pyod: 1.0.9
2023-05-24 19:04:14,469:INFO:            imblearn: 0.10.1
2023-05-24 19:04:14,469:INFO:   category_encoders: 2.6.1
2023-05-24 19:04:14,469:INFO:            lightgbm: 3.3.5
2023-05-24 19:04:14,469:INFO:               numba: 0.57.0
2023-05-24 19:04:14,469:INFO:            requests: 2.31.0
2023-05-24 19:04:14,469:INFO:          matplotlib: 3.7.1
2023-05-24 19:04:14,469:INFO:          scikitplot: 0.3.7
2023-05-24 19:04:14,469:INFO:         yellowbrick: 1.5
2023-05-24 19:04:14,469:INFO:              plotly: 5.14.1
2023-05-24 19:04:14,469:INFO:             kaleido: 0.2.1
2023-05-24 19:04:14,469:INFO:         statsmodels: 0.14.0
2023-05-24 19:04:14,469:INFO:              sktime: 0.17.0
2023-05-24 19:04:14,469:INFO:               tbats: 1.1.3
2023-05-24 19:04:14,469:INFO:            pmdarima: 2.0.3
2023-05-24 19:04:14,469:INFO:              psutil: 5.9.5
2023-05-24 19:04:14,470:INFO:PyCaret optional dependencies:
2023-05-24 19:04:14,470:INFO:                shap: Not installed
2023-05-24 19:04:14,470:INFO:           interpret: Not installed
2023-05-24 19:04:14,470:INFO:                umap: Not installed
2023-05-24 19:04:14,470:INFO:    pandas_profiling: Not installed
2023-05-24 19:04:14,470:INFO:  explainerdashboard: Not installed
2023-05-24 19:04:14,470:INFO:             autoviz: Not installed
2023-05-24 19:04:14,470:INFO:           fairlearn: Not installed
2023-05-24 19:04:14,470:INFO:             xgboost: Not installed
2023-05-24 19:04:14,470:INFO:            catboost: Not installed
2023-05-24 19:04:14,470:INFO:              kmodes: Not installed
2023-05-24 19:04:14,470:INFO:             mlxtend: Not installed
2023-05-24 19:04:14,470:INFO:       statsforecast: Not installed
2023-05-24 19:04:14,470:INFO:        tune_sklearn: 0.4.5
2023-05-24 19:04:14,470:INFO:                 ray: 2.4.0
2023-05-24 19:04:14,470:INFO:            hyperopt: 0.2.7
2023-05-24 19:04:14,470:INFO:              optuna: 3.1.1
2023-05-24 19:04:14,470:INFO:               skopt: 0.9.0
2023-05-24 19:04:14,470:INFO:              mlflow: Not installed
2023-05-24 19:04:14,470:INFO:              gradio: Not installed
2023-05-24 19:04:14,470:INFO:             fastapi: Not installed
2023-05-24 19:04:14,470:INFO:             uvicorn: Not installed
2023-05-24 19:04:14,470:INFO:              m2cgen: Not installed
2023-05-24 19:04:14,470:INFO:           evidently: Not installed
2023-05-24 19:04:14,470:INFO:               fugue: Not installed
2023-05-24 19:04:14,470:INFO:           streamlit: Not installed
2023-05-24 19:04:14,470:INFO:             prophet: Not installed
2023-05-24 19:04:14,470:INFO:None
2023-05-24 19:04:14,471:INFO:Set up data.
2023-05-24 19:04:14,718:INFO:Set up train/test split.
2023-05-24 19:04:14,829:INFO:Set up index.
2023-05-24 19:04:14,834:INFO:Set up folding strategy.
2023-05-24 19:04:14,834:INFO:Assigning column types.
2023-05-24 19:04:14,893:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 19:04:14,937:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 19:04:14,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:04:14,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:14,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:15,017:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 19:04:15,018:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:04:15,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:15,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:15,043:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 19:04:15,097:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:04:15,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:15,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:15,159:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:04:15,183:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:15,183:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:15,184:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 19:04:15,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:15,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:15,317:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:15,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:15,322:INFO:Preparing preprocessing pipeline...
2023-05-24 19:04:15,331:INFO:Set up label encoding.
2023-05-24 19:04:15,331:INFO:Set up simple imputation.
2023-05-24 19:04:15,332:INFO:Set up imbalanced handling.
2023-05-24 19:04:15,340:INFO:Set up column name cleaning.
2023-05-24 19:04:19,283:INFO:Finished creating preprocessing pipeline.
2023-05-24 19:04:19,292:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 19:04:19,293:INFO:Creating final display dataframe.
2023-05-24 19:04:24,235:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13                Fix imbalance   
14         Fix imbalance method   
15               Fold Generator   
16                  Fold Number   
17                     CPU Jobs   
18                      Use GPU   
19               Log Experiment   
20              Experiment Name   
21                          USI   

                                                Value  
0                                                 123  
1                                              Review  
2                                          Multiclass  
3   Indifference: 0, Mixed: 1, Negative: 2, Positi...  
4                                        (46252, 508)  
5                                        (68248, 508)  
6                                        (54372, 508)  
7                                        (13876, 508)  
8                                                 507  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                               True  
14                                              SMOTE  
15                                    StratifiedKFold  
16                                                 10  
17                                                 -1  
18                                              False  
19                                              False  
20                                   clf-default-name  
21                                               b41f  
2023-05-24 19:04:24,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:24,327:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:24,400:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:24,401:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:24,403:INFO:setup() successfully completed in 10.23s...............
2023-05-24 19:04:47,253:INFO:PyCaret ClassificationExperiment
2023-05-24 19:04:47,253:INFO:Logging name: clf-default-name
2023-05-24 19:04:47,253:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 19:04:47,253:INFO:version 3.0.2
2023-05-24 19:04:47,253:INFO:Initializing setup()
2023-05-24 19:04:47,253:INFO:self.USI: b125
2023-05-24 19:04:47,253:INFO:self._variable_keys: {'X_train', 'logging_param', 'y_train', 'fold_groups_param', '_available_plots', 'X', 'X_test', 'pipeline', 'seed', 'y', 'n_jobs_param', 'idx', 'gpu_param', 'html_param', 'memory', 'gpu_n_jobs_param', 'fold_generator', 'y_test', 'data', 'exp_name_log', '_ml_usecase', 'exp_id', 'fix_imbalance', 'target_param', 'log_plots_param', 'fold_shuffle_param', 'is_multiclass', 'USI'}
2023-05-24 19:04:47,253:INFO:Checking environment
2023-05-24 19:04:47,253:INFO:python_version: 3.10.11
2023-05-24 19:04:47,253:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 19:04:47,253:INFO:machine: AMD64
2023-05-24 19:04:47,253:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 19:04:47,256:INFO:Memory: svmem(total=16889774080, available=7246057472, percent=57.1, used=9643716608, free=7246057472)
2023-05-24 19:04:47,256:INFO:Physical Core: 4
2023-05-24 19:04:47,256:INFO:Logical Core: 8
2023-05-24 19:04:47,256:INFO:Checking libraries
2023-05-24 19:04:47,256:INFO:System:
2023-05-24 19:04:47,256:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 19:04:47,256:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 19:04:47,256:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 19:04:47,256:INFO:PyCaret required dependencies:
2023-05-24 19:04:47,256:INFO:                 pip: 23.0.1
2023-05-24 19:04:47,256:INFO:          setuptools: 66.0.0
2023-05-24 19:04:47,256:INFO:             pycaret: 3.0.2
2023-05-24 19:04:47,257:INFO:             IPython: 8.13.2
2023-05-24 19:04:47,257:INFO:          ipywidgets: 8.0.6
2023-05-24 19:04:47,257:INFO:                tqdm: 4.65.0
2023-05-24 19:04:47,257:INFO:               numpy: 1.23.5
2023-05-24 19:04:47,257:INFO:              pandas: 1.5.3
2023-05-24 19:04:47,257:INFO:              jinja2: 3.1.2
2023-05-24 19:04:47,257:INFO:               scipy: 1.10.1
2023-05-24 19:04:47,257:INFO:              joblib: 1.2.0
2023-05-24 19:04:47,257:INFO:             sklearn: 1.2.2
2023-05-24 19:04:47,257:INFO:                pyod: 1.0.9
2023-05-24 19:04:47,257:INFO:            imblearn: 0.10.1
2023-05-24 19:04:47,257:INFO:   category_encoders: 2.6.1
2023-05-24 19:04:47,257:INFO:            lightgbm: 3.3.5
2023-05-24 19:04:47,257:INFO:               numba: 0.57.0
2023-05-24 19:04:47,257:INFO:            requests: 2.31.0
2023-05-24 19:04:47,257:INFO:          matplotlib: 3.7.1
2023-05-24 19:04:47,257:INFO:          scikitplot: 0.3.7
2023-05-24 19:04:47,257:INFO:         yellowbrick: 1.5
2023-05-24 19:04:47,257:INFO:              plotly: 5.14.1
2023-05-24 19:04:47,257:INFO:             kaleido: 0.2.1
2023-05-24 19:04:47,257:INFO:         statsmodels: 0.14.0
2023-05-24 19:04:47,257:INFO:              sktime: 0.17.0
2023-05-24 19:04:47,257:INFO:               tbats: 1.1.3
2023-05-24 19:04:47,257:INFO:            pmdarima: 2.0.3
2023-05-24 19:04:47,257:INFO:              psutil: 5.9.5
2023-05-24 19:04:47,257:INFO:PyCaret optional dependencies:
2023-05-24 19:04:47,257:INFO:                shap: Not installed
2023-05-24 19:04:47,258:INFO:           interpret: Not installed
2023-05-24 19:04:47,258:INFO:                umap: Not installed
2023-05-24 19:04:47,258:INFO:    pandas_profiling: Not installed
2023-05-24 19:04:47,258:INFO:  explainerdashboard: Not installed
2023-05-24 19:04:47,258:INFO:             autoviz: Not installed
2023-05-24 19:04:47,258:INFO:           fairlearn: Not installed
2023-05-24 19:04:47,258:INFO:             xgboost: Not installed
2023-05-24 19:04:47,258:INFO:            catboost: Not installed
2023-05-24 19:04:47,258:INFO:              kmodes: Not installed
2023-05-24 19:04:47,258:INFO:             mlxtend: Not installed
2023-05-24 19:04:47,258:INFO:       statsforecast: Not installed
2023-05-24 19:04:47,258:INFO:        tune_sklearn: 0.4.5
2023-05-24 19:04:47,258:INFO:                 ray: 2.4.0
2023-05-24 19:04:47,258:INFO:            hyperopt: 0.2.7
2023-05-24 19:04:47,258:INFO:              optuna: 3.1.1
2023-05-24 19:04:47,258:INFO:               skopt: 0.9.0
2023-05-24 19:04:47,258:INFO:              mlflow: Not installed
2023-05-24 19:04:47,258:INFO:              gradio: Not installed
2023-05-24 19:04:47,258:INFO:             fastapi: Not installed
2023-05-24 19:04:47,258:INFO:             uvicorn: Not installed
2023-05-24 19:04:47,258:INFO:              m2cgen: Not installed
2023-05-24 19:04:47,258:INFO:           evidently: Not installed
2023-05-24 19:04:47,258:INFO:               fugue: Not installed
2023-05-24 19:04:47,258:INFO:           streamlit: Not installed
2023-05-24 19:04:47,258:INFO:             prophet: Not installed
2023-05-24 19:04:47,258:INFO:None
2023-05-24 19:04:47,258:INFO:Set up data.
2023-05-24 19:04:47,723:INFO:Set up train/test split.
2023-05-24 19:04:47,834:INFO:Set up index.
2023-05-24 19:04:47,837:INFO:Set up folding strategy.
2023-05-24 19:04:47,838:INFO:Assigning column types.
2023-05-24 19:04:47,902:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 19:04:47,941:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 19:04:47,942:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:04:47,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:47,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:48,011:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 19:04:48,012:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:04:48,037:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:48,037:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:48,038:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 19:04:48,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:04:48,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:48,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:48,139:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:04:48,162:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:48,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:48,162:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 19:04:48,225:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:48,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:48,288:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:48,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:48,289:INFO:Preparing preprocessing pipeline...
2023-05-24 19:04:48,298:INFO:Set up label encoding.
2023-05-24 19:04:48,298:INFO:Set up simple imputation.
2023-05-24 19:04:48,305:INFO:Set up column name cleaning.
2023-05-24 19:04:48,589:INFO:Finished creating preprocessing pipeline.
2023-05-24 19:04:48,598:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 19:04:48,598:INFO:Creating final display dataframe.
2023-05-24 19:04:49,877:INFO:Setup _display_container:                     Description  \
0                    Session id   
1                        Target   
2                   Target type   
3                Target mapping   
4           Original data shape   
5        Transformed data shape   
6   Transformed train set shape   
7    Transformed test set shape   
8              Numeric features   
9                    Preprocess   
10              Imputation type   
11           Numeric imputation   
12       Categorical imputation   
13               Fold Generator   
14                  Fold Number   
15                     CPU Jobs   
16                      Use GPU   
17               Log Experiment   
18              Experiment Name   
19                          USI   

                                                Value  
0                                                 123  
1                                              Review  
2                                          Multiclass  
3   Indifference: 0, Mixed: 1, Negative: 2, Positi...  
4                                        (46252, 508)  
5                                        (46252, 508)  
6                                        (32376, 508)  
7                                        (13876, 508)  
8                                                 507  
9                                                True  
10                                             simple  
11                                               mean  
12                                               mode  
13                                    StratifiedKFold  
14                                                 10  
15                                                 -1  
16                                              False  
17                                              False  
18                                   clf-default-name  
19                                               b125  
2023-05-24 19:04:49,956:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:49,957:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:50,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:50,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:04:50,023:INFO:setup() successfully completed in 3.05s...............
2023-05-24 19:04:52,341:INFO:Initializing compare_models()
2023-05-24 19:04:52,341:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-24 19:04:52,341:INFO:Checking exceptions
2023-05-24 19:04:52,414:INFO:Preparing display monitor
2023-05-24 19:04:52,446:INFO:Initializing Logistic Regression
2023-05-24 19:04:52,446:INFO:Total runtime is 0.0 minutes
2023-05-24 19:04:52,451:INFO:SubProcess create_model() called ==================================
2023-05-24 19:04:52,452:INFO:Initializing create_model()
2023-05-24 19:04:52,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:04:52,452:INFO:Checking exceptions
2023-05-24 19:04:52,454:INFO:Importing libraries
2023-05-24 19:04:52,454:INFO:Copying training dataset
2023-05-24 19:04:52,583:INFO:Defining folds
2023-05-24 19:04:52,583:INFO:Declaring metric variables
2023-05-24 19:04:52,587:INFO:Importing untrained model
2023-05-24 19:04:52,590:INFO:Logistic Regression Imported successfully
2023-05-24 19:04:52,596:INFO:Starting cross validation
2023-05-24 19:04:52,602:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:08:29,056:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:08:30,494:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:30,529:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:30,563:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:34,410:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:08:35,797:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:35,838:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:35,876:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:37,381:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:08:38,692:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:38,752:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:38,790:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:39,188:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:08:39,817:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:08:40,495:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:40,531:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:40,565:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:41,113:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:41,158:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:41,196:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:43,140:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:08:44,049:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:44,066:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:44,096:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:45,611:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:08:46,460:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:46,479:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:46,498:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:54,075:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:08:54,808:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:54,826:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:08:54,843:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:04,260:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:10:04,712:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:04,726:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:04,743:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:05,377:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:10:05,767:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:05,779:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:05,799:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:06,046:INFO:Calculating mean and std
2023-05-24 19:10:06,048:INFO:Creating metrics dataframe
2023-05-24 19:10:06,316:INFO:Uploading results into container
2023-05-24 19:10:06,317:INFO:Uploading model into container now
2023-05-24 19:10:06,317:INFO:_master_model_container: 1
2023-05-24 19:10:06,317:INFO:_display_container: 2
2023-05-24 19:10:06,317:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-24 19:10:06,317:INFO:create_model() successfully completed......................................
2023-05-24 19:10:06,414:INFO:SubProcess create_model() end ==================================
2023-05-24 19:10:06,414:INFO:Creating metrics dataframe
2023-05-24 19:10:06,426:INFO:Initializing K Neighbors Classifier
2023-05-24 19:10:06,426:INFO:Total runtime is 5.232995820045471 minutes
2023-05-24 19:10:06,437:INFO:SubProcess create_model() called ==================================
2023-05-24 19:10:06,438:INFO:Initializing create_model()
2023-05-24 19:10:06,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:10:06,439:INFO:Checking exceptions
2023-05-24 19:10:06,439:INFO:Importing libraries
2023-05-24 19:10:06,440:INFO:Copying training dataset
2023-05-24 19:10:06,546:INFO:Defining folds
2023-05-24 19:10:06,546:INFO:Declaring metric variables
2023-05-24 19:10:06,552:INFO:Importing untrained model
2023-05-24 19:10:06,560:INFO:K Neighbors Classifier Imported successfully
2023-05-24 19:10:06,567:INFO:Starting cross validation
2023-05-24 19:10:06,571:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:10:33,226:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:33,260:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:33,294:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:33,312:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:33,343:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:33,380:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:33,416:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:33,451:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:33,488:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:33,643:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:33,681:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:33,729:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,687:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,717:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,765:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,770:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,794:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,796:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,821:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,832:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,855:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,893:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:34,924:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:48,685:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:48,696:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:48,708:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:48,742:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:48,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:48,783:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:49,146:INFO:Calculating mean and std
2023-05-24 19:10:49,148:INFO:Creating metrics dataframe
2023-05-24 19:10:49,490:INFO:Uploading results into container
2023-05-24 19:10:49,491:INFO:Uploading model into container now
2023-05-24 19:10:49,491:INFO:_master_model_container: 2
2023-05-24 19:10:49,492:INFO:_display_container: 2
2023-05-24 19:10:49,492:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-24 19:10:49,492:INFO:create_model() successfully completed......................................
2023-05-24 19:10:49,590:INFO:SubProcess create_model() end ==================================
2023-05-24 19:10:49,591:INFO:Creating metrics dataframe
2023-05-24 19:10:49,609:INFO:Initializing Naive Bayes
2023-05-24 19:10:49,609:INFO:Total runtime is 5.952722386519114 minutes
2023-05-24 19:10:49,613:INFO:SubProcess create_model() called ==================================
2023-05-24 19:10:49,613:INFO:Initializing create_model()
2023-05-24 19:10:49,613:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:10:49,613:INFO:Checking exceptions
2023-05-24 19:10:49,614:INFO:Importing libraries
2023-05-24 19:10:49,614:INFO:Copying training dataset
2023-05-24 19:10:49,729:INFO:Defining folds
2023-05-24 19:10:49,729:INFO:Declaring metric variables
2023-05-24 19:10:49,735:INFO:Importing untrained model
2023-05-24 19:10:49,742:INFO:Naive Bayes Imported successfully
2023-05-24 19:10:49,749:INFO:Starting cross validation
2023-05-24 19:10:49,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:10:54,884:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:54,910:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:54,937:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:55,009:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:55,053:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:55,079:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:55,916:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:55,961:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:55,989:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:55,992:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:55,993:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,020:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,025:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,026:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,032:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,059:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,064:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,064:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,082:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,105:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,109:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,291:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,320:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:56,356:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:58,625:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:58,641:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:58,658:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:58,694:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:58,718:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:58,735:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:10:59,106:INFO:Calculating mean and std
2023-05-24 19:10:59,108:INFO:Creating metrics dataframe
2023-05-24 19:10:59,429:INFO:Uploading results into container
2023-05-24 19:10:59,430:INFO:Uploading model into container now
2023-05-24 19:10:59,431:INFO:_master_model_container: 3
2023-05-24 19:10:59,432:INFO:_display_container: 2
2023-05-24 19:10:59,432:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-24 19:10:59,432:INFO:create_model() successfully completed......................................
2023-05-24 19:10:59,530:INFO:SubProcess create_model() end ==================================
2023-05-24 19:10:59,530:INFO:Creating metrics dataframe
2023-05-24 19:10:59,540:INFO:Initializing Decision Tree Classifier
2023-05-24 19:10:59,540:INFO:Total runtime is 6.118243857224782 minutes
2023-05-24 19:10:59,549:INFO:SubProcess create_model() called ==================================
2023-05-24 19:10:59,549:INFO:Initializing create_model()
2023-05-24 19:10:59,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:10:59,550:INFO:Checking exceptions
2023-05-24 19:10:59,550:INFO:Importing libraries
2023-05-24 19:10:59,550:INFO:Copying training dataset
2023-05-24 19:10:59,665:INFO:Defining folds
2023-05-24 19:10:59,665:INFO:Declaring metric variables
2023-05-24 19:10:59,673:INFO:Importing untrained model
2023-05-24 19:10:59,678:INFO:Decision Tree Classifier Imported successfully
2023-05-24 19:10:59,685:INFO:Starting cross validation
2023-05-24 19:10:59,689:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:11:13,167:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,215:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,250:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,492:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,521:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,551:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,589:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,627:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,665:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,767:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,805:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,805:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,842:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,846:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:13,875:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:14,092:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:14,130:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:14,162:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:14,247:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:14,281:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:14,313:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:14,394:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:14,419:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:14,449:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:21,687:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:21,707:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:21,719:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:21,722:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:21,736:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:21,748:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:22,151:INFO:Calculating mean and std
2023-05-24 19:11:22,154:INFO:Creating metrics dataframe
2023-05-24 19:11:22,492:INFO:Uploading results into container
2023-05-24 19:11:22,493:INFO:Uploading model into container now
2023-05-24 19:11:22,493:INFO:_master_model_container: 4
2023-05-24 19:11:22,493:INFO:_display_container: 2
2023-05-24 19:11:22,493:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-24 19:11:22,493:INFO:create_model() successfully completed......................................
2023-05-24 19:11:22,583:INFO:SubProcess create_model() end ==================================
2023-05-24 19:11:22,583:INFO:Creating metrics dataframe
2023-05-24 19:11:22,595:INFO:Initializing SVM - Linear Kernel
2023-05-24 19:11:22,595:INFO:Total runtime is 6.502479660511017 minutes
2023-05-24 19:11:22,601:INFO:SubProcess create_model() called ==================================
2023-05-24 19:11:22,602:INFO:Initializing create_model()
2023-05-24 19:11:22,602:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:11:22,602:INFO:Checking exceptions
2023-05-24 19:11:22,602:INFO:Importing libraries
2023-05-24 19:11:22,602:INFO:Copying training dataset
2023-05-24 19:11:22,708:INFO:Defining folds
2023-05-24 19:11:22,709:INFO:Declaring metric variables
2023-05-24 19:11:22,713:INFO:Importing untrained model
2023-05-24 19:11:22,716:INFO:SVM - Linear Kernel Imported successfully
2023-05-24 19:11:22,725:INFO:Starting cross validation
2023-05-24 19:11:22,731:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:11:43,342:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:11:43,353:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:43,383:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:43,414:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:43,630:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:11:43,644:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:43,678:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:43,703:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:45,667:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:11:45,681:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:45,710:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:45,739:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:46,425:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:11:46,440:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:46,470:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:46,498:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:47,411:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:11:47,425:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:47,468:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:47,496:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:52,008:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:11:52,017:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:52,038:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:52,053:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:53,362:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:11:53,371:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:53,393:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:53,414:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:54,015:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:11:54,024:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:54,042:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:11:54,068:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:01,953:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:12:01,961:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:01,977:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:01,991:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:02,388:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:12:02,393:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:02,405:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:02,417:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:02,763:INFO:Calculating mean and std
2023-05-24 19:12:02,765:INFO:Creating metrics dataframe
2023-05-24 19:12:03,029:INFO:Uploading results into container
2023-05-24 19:12:03,030:INFO:Uploading model into container now
2023-05-24 19:12:03,030:INFO:_master_model_container: 5
2023-05-24 19:12:03,030:INFO:_display_container: 2
2023-05-24 19:12:03,032:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-24 19:12:03,032:INFO:create_model() successfully completed......................................
2023-05-24 19:12:03,128:INFO:SubProcess create_model() end ==================================
2023-05-24 19:12:03,129:INFO:Creating metrics dataframe
2023-05-24 19:12:03,149:INFO:Initializing Ridge Classifier
2023-05-24 19:12:03,160:INFO:Total runtime is 7.178573294480642 minutes
2023-05-24 19:12:03,164:INFO:SubProcess create_model() called ==================================
2023-05-24 19:12:03,164:INFO:Initializing create_model()
2023-05-24 19:12:03,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:12:03,164:INFO:Checking exceptions
2023-05-24 19:12:03,164:INFO:Importing libraries
2023-05-24 19:12:03,164:INFO:Copying training dataset
2023-05-24 19:12:03,276:INFO:Defining folds
2023-05-24 19:12:03,277:INFO:Declaring metric variables
2023-05-24 19:12:03,282:INFO:Importing untrained model
2023-05-24 19:12:03,288:INFO:Ridge Classifier Imported successfully
2023-05-24 19:12:03,295:INFO:Starting cross validation
2023-05-24 19:12:03,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:12:07,554:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:12:07,571:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,595:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,620:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,629:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:12:07,644:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,681:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,700:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:12:07,713:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,722:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,737:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,766:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,793:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:12:07,803:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,832:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,859:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,865:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:12:07,887:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:12:07,897:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,900:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,932:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,940:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,969:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:07,980:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:08,033:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:12:08,045:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:08,070:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:08,089:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:12:08,095:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:08,098:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:08,122:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:08,145:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:10,933:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:12:10,941:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:10,963:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:10,987:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:11,268:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:12:11,279:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:11,306:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:11,328:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:12:11,534:INFO:Calculating mean and std
2023-05-24 19:12:11,537:INFO:Creating metrics dataframe
2023-05-24 19:12:11,961:INFO:Uploading results into container
2023-05-24 19:12:11,961:INFO:Uploading model into container now
2023-05-24 19:12:11,962:INFO:_master_model_container: 6
2023-05-24 19:12:11,962:INFO:_display_container: 2
2023-05-24 19:12:11,963:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-24 19:12:11,963:INFO:create_model() successfully completed......................................
2023-05-24 19:12:12,063:INFO:SubProcess create_model() end ==================================
2023-05-24 19:12:12,063:INFO:Creating metrics dataframe
2023-05-24 19:12:12,073:INFO:Initializing Random Forest Classifier
2023-05-24 19:12:12,073:INFO:Total runtime is 7.327112797896067 minutes
2023-05-24 19:12:12,077:INFO:SubProcess create_model() called ==================================
2023-05-24 19:12:12,078:INFO:Initializing create_model()
2023-05-24 19:12:12,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:12:12,078:INFO:Checking exceptions
2023-05-24 19:12:12,079:INFO:Importing libraries
2023-05-24 19:12:12,079:INFO:Copying training dataset
2023-05-24 19:12:12,195:INFO:Defining folds
2023-05-24 19:12:12,195:INFO:Declaring metric variables
2023-05-24 19:12:12,199:INFO:Importing untrained model
2023-05-24 19:12:12,204:INFO:Random Forest Classifier Imported successfully
2023-05-24 19:12:12,213:INFO:Starting cross validation
2023-05-24 19:12:12,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:13:04,474:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:13:05,805:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:13:06,854:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:06,892:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:06,914:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:07,462:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:13:07,593:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:07,631:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:07,661:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:07,663:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:13:08,801:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:13:08,823:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:13:08,829:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:13:08,848:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:13:09,247:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,293:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,301:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,321:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,333:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,389:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,562:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,655:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,665:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,668:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,673:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,687:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,703:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,709:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,710:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,715:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,739:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:09,739:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:24,352:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:24,378:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:24,403:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:25,279:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:25,291:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:25,303:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:25,644:INFO:Calculating mean and std
2023-05-24 19:13:25,646:INFO:Creating metrics dataframe
2023-05-24 19:13:25,916:INFO:Uploading results into container
2023-05-24 19:13:25,917:INFO:Uploading model into container now
2023-05-24 19:13:25,917:INFO:_master_model_container: 7
2023-05-24 19:13:25,917:INFO:_display_container: 2
2023-05-24 19:13:25,918:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-24 19:13:25,918:INFO:create_model() successfully completed......................................
2023-05-24 19:13:26,029:INFO:SubProcess create_model() end ==================================
2023-05-24 19:13:26,029:INFO:Creating metrics dataframe
2023-05-24 19:13:26,039:INFO:Initializing Quadratic Discriminant Analysis
2023-05-24 19:13:26,040:INFO:Total runtime is 8.559910817941029 minutes
2023-05-24 19:13:26,052:INFO:SubProcess create_model() called ==================================
2023-05-24 19:13:26,052:INFO:Initializing create_model()
2023-05-24 19:13:26,052:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:13:26,052:INFO:Checking exceptions
2023-05-24 19:13:26,053:INFO:Importing libraries
2023-05-24 19:13:26,053:INFO:Copying training dataset
2023-05-24 19:13:26,161:INFO:Defining folds
2023-05-24 19:13:26,161:INFO:Declaring metric variables
2023-05-24 19:13:26,164:INFO:Importing untrained model
2023-05-24 19:13:26,168:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-24 19:13:26,177:INFO:Starting cross validation
2023-05-24 19:13:26,182:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:13:29,950:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:13:32,153:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:13:33,449:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:13:33,944:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:13:33,953:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:13:34,152:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:13:34,272:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:13:34,634:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:13:39,801:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:13:42,115:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:42,154:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:42,175:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:13:42,196:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:44,007:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:44,041:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:44,077:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,020:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,065:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,106:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,519:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,560:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,565:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,572:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,595:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,602:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,607:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,631:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,638:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,681:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,724:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,771:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,879:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,916:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:45,980:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:47,483:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:13:48,483:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:13:51,992:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:52,005:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:52,025:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:52,909:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:52,920:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:52,939:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:13:53,282:INFO:Calculating mean and std
2023-05-24 19:13:53,283:INFO:Creating metrics dataframe
2023-05-24 19:13:53,500:INFO:Uploading results into container
2023-05-24 19:13:53,501:INFO:Uploading model into container now
2023-05-24 19:13:53,501:INFO:_master_model_container: 8
2023-05-24 19:13:53,501:INFO:_display_container: 2
2023-05-24 19:13:53,501:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-24 19:13:53,501:INFO:create_model() successfully completed......................................
2023-05-24 19:13:53,604:INFO:SubProcess create_model() end ==================================
2023-05-24 19:13:53,604:INFO:Creating metrics dataframe
2023-05-24 19:13:53,622:INFO:Initializing Ada Boost Classifier
2023-05-24 19:13:53,622:INFO:Total runtime is 9.019596926371255 minutes
2023-05-24 19:13:53,628:INFO:SubProcess create_model() called ==================================
2023-05-24 19:13:53,628:INFO:Initializing create_model()
2023-05-24 19:13:53,628:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:13:53,628:INFO:Checking exceptions
2023-05-24 19:13:53,628:INFO:Importing libraries
2023-05-24 19:13:53,628:INFO:Copying training dataset
2023-05-24 19:13:53,728:INFO:Defining folds
2023-05-24 19:13:53,728:INFO:Declaring metric variables
2023-05-24 19:13:53,732:INFO:Importing untrained model
2023-05-24 19:13:53,736:INFO:Ada Boost Classifier Imported successfully
2023-05-24 19:13:53,750:INFO:Starting cross validation
2023-05-24 19:13:53,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:14:32,171:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:32,216:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:32,246:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:32,414:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:32,475:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:32,509:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:32,705:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:32,734:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:32,765:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:32,887:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:32,916:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:32,948:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,011:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,054:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,069:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,082:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,085:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,088:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,111:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,117:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,121:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,145:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,162:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:33,163:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:54,895:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:54,917:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:54,938:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:55,065:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:55,076:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:55,091:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:14:55,403:INFO:Calculating mean and std
2023-05-24 19:14:55,404:INFO:Creating metrics dataframe
2023-05-24 19:14:55,819:INFO:Uploading results into container
2023-05-24 19:14:55,819:INFO:Uploading model into container now
2023-05-24 19:14:55,820:INFO:_master_model_container: 9
2023-05-24 19:14:55,820:INFO:_display_container: 2
2023-05-24 19:14:55,820:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-24 19:14:55,820:INFO:create_model() successfully completed......................................
2023-05-24 19:14:55,921:INFO:SubProcess create_model() end ==================================
2023-05-24 19:14:55,921:INFO:Creating metrics dataframe
2023-05-24 19:14:55,933:INFO:Initializing Gradient Boosting Classifier
2023-05-24 19:14:55,934:INFO:Total runtime is 10.05813237428665 minutes
2023-05-24 19:14:55,951:INFO:SubProcess create_model() called ==================================
2023-05-24 19:14:55,952:INFO:Initializing create_model()
2023-05-24 19:14:55,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:14:55,952:INFO:Checking exceptions
2023-05-24 19:14:55,952:INFO:Importing libraries
2023-05-24 19:14:55,952:INFO:Copying training dataset
2023-05-24 19:14:56,045:INFO:Defining folds
2023-05-24 19:14:56,045:INFO:Declaring metric variables
2023-05-24 19:14:56,051:INFO:Importing untrained model
2023-05-24 19:14:56,057:INFO:Gradient Boosting Classifier Imported successfully
2023-05-24 19:14:56,067:INFO:Starting cross validation
2023-05-24 19:14:56,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:22:31,620:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:22:31,891:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:22:32,086:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:22:32,764:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:22:32,836:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:22:33,075:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:22:33,274:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:22:33,448:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:33,476:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:33,505:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:33,840:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:33,873:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:33,905:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:34,008:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:34,040:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:34,081:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:34,243:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:22:34,300:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:22:34,959:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:35,007:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:35,035:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:35,593:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:22:36,279:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:36,306:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:36,331:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:41,093:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:41,114:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:41,139:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:42,186:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:42,207:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:42,230:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:42,839:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:42,869:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:22:42,889:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:08,301:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:08,320:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:08,331:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:09,032:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:09,043:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:09,054:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:09,291:INFO:Calculating mean and std
2023-05-24 19:27:09,293:INFO:Creating metrics dataframe
2023-05-24 19:27:09,635:INFO:Uploading results into container
2023-05-24 19:27:09,636:INFO:Uploading model into container now
2023-05-24 19:27:09,637:INFO:_master_model_container: 10
2023-05-24 19:27:09,637:INFO:_display_container: 2
2023-05-24 19:27:09,638:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-24 19:27:09,638:INFO:create_model() successfully completed......................................
2023-05-24 19:27:09,744:INFO:SubProcess create_model() end ==================================
2023-05-24 19:27:09,745:INFO:Creating metrics dataframe
2023-05-24 19:27:09,759:INFO:Initializing Linear Discriminant Analysis
2023-05-24 19:27:09,770:INFO:Total runtime is 22.288737066586812 minutes
2023-05-24 19:27:09,781:INFO:SubProcess create_model() called ==================================
2023-05-24 19:27:09,781:INFO:Initializing create_model()
2023-05-24 19:27:09,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:27:09,782:INFO:Checking exceptions
2023-05-24 19:27:09,782:INFO:Importing libraries
2023-05-24 19:27:09,782:INFO:Copying training dataset
2023-05-24 19:27:09,881:INFO:Defining folds
2023-05-24 19:27:09,881:INFO:Declaring metric variables
2023-05-24 19:27:09,887:INFO:Importing untrained model
2023-05-24 19:27:09,893:INFO:Linear Discriminant Analysis Imported successfully
2023-05-24 19:27:09,900:INFO:Starting cross validation
2023-05-24 19:27:09,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:27:34,406:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,432:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,459:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,563:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,582:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,589:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,608:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,620:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,634:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,732:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,798:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,927:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,955:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,984:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:34,995:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:35,023:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:35,049:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:35,053:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:35,079:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:35,121:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:35,267:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:35,295:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:35,331:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:45,579:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:45,591:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:45,602:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:45,656:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:45,678:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:45,700:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:27:46,103:INFO:Calculating mean and std
2023-05-24 19:27:46,104:INFO:Creating metrics dataframe
2023-05-24 19:27:46,508:INFO:Uploading results into container
2023-05-24 19:27:46,509:INFO:Uploading model into container now
2023-05-24 19:27:46,511:INFO:_master_model_container: 11
2023-05-24 19:27:46,511:INFO:_display_container: 2
2023-05-24 19:27:46,512:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-24 19:27:46,512:INFO:create_model() successfully completed......................................
2023-05-24 19:27:46,617:INFO:SubProcess create_model() end ==================================
2023-05-24 19:27:46,617:INFO:Creating metrics dataframe
2023-05-24 19:27:46,659:INFO:Initializing Extra Trees Classifier
2023-05-24 19:27:46,660:INFO:Total runtime is 22.903565557797748 minutes
2023-05-24 19:27:46,666:INFO:SubProcess create_model() called ==================================
2023-05-24 19:27:46,667:INFO:Initializing create_model()
2023-05-24 19:27:46,667:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:27:46,667:INFO:Checking exceptions
2023-05-24 19:27:46,667:INFO:Importing libraries
2023-05-24 19:27:46,667:INFO:Copying training dataset
2023-05-24 19:27:46,776:INFO:Defining folds
2023-05-24 19:27:46,776:INFO:Declaring metric variables
2023-05-24 19:27:46,781:INFO:Importing untrained model
2023-05-24 19:27:46,785:INFO:Extra Trees Classifier Imported successfully
2023-05-24 19:27:46,791:INFO:Starting cross validation
2023-05-24 19:27:46,796:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:29:09,761:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:29:12,845:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-24 19:29:14,086:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-24 19:29:14,252:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:29:14,357:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:29:15,897:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:29:16,899:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:29:16,973:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:17,011:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:17,042:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:17,503:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:29:17,512:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:29:17,813:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:29:18,241:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:18,310:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:29:18,318:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:18,334:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:18,347:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:18,361:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:29:18,362:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:18,404:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:18,431:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:29:18,680:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:29:19,116:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:29:19,555:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:19,593:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:19,634:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:19,674:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:29:19,787:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:29:20,081:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:29:20,091:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:20,121:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:20,196:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:20,620:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:20,653:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:20,655:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:20,689:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:20,697:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:20,715:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:20,858:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:20,911:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:20,964:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:40,842:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:29:42,581:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:42,601:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:42,625:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:43,944:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:43,955:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:43,973:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:29:44,213:INFO:Calculating mean and std
2023-05-24 19:29:44,215:INFO:Creating metrics dataframe
2023-05-24 19:29:44,512:INFO:Uploading results into container
2023-05-24 19:29:44,513:INFO:Uploading model into container now
2023-05-24 19:29:44,514:INFO:_master_model_container: 12
2023-05-24 19:29:44,514:INFO:_display_container: 2
2023-05-24 19:29:44,516:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-24 19:29:44,516:INFO:create_model() successfully completed......................................
2023-05-24 19:29:44,616:INFO:SubProcess create_model() end ==================================
2023-05-24 19:29:44,616:INFO:Creating metrics dataframe
2023-05-24 19:29:44,630:INFO:Initializing Light Gradient Boosting Machine
2023-05-24 19:29:44,630:INFO:Total runtime is 24.869743756453193 minutes
2023-05-24 19:29:44,635:INFO:SubProcess create_model() called ==================================
2023-05-24 19:29:44,636:INFO:Initializing create_model()
2023-05-24 19:29:44,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:29:44,636:INFO:Checking exceptions
2023-05-24 19:29:44,636:INFO:Importing libraries
2023-05-24 19:29:44,636:INFO:Copying training dataset
2023-05-24 19:29:44,750:INFO:Defining folds
2023-05-24 19:29:44,750:INFO:Declaring metric variables
2023-05-24 19:29:44,755:INFO:Importing untrained model
2023-05-24 19:29:44,760:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 19:29:44,772:INFO:Starting cross validation
2023-05-24 19:29:44,778:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:30:20,289:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:20,318:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:20,349:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,111:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,139:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,168:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,231:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,265:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,299:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,871:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,930:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,953:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,964:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,968:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,986:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:30:21,993:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:21,997:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:22,044:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:22,046:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:22,238:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:22,276:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:22,310:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:22,757:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:22,782:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:22,809:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:39,239:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:39,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:39,271:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:39,766:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:39,779:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:39,791:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:40,029:INFO:Calculating mean and std
2023-05-24 19:30:40,030:INFO:Creating metrics dataframe
2023-05-24 19:30:40,311:INFO:Uploading results into container
2023-05-24 19:30:40,313:INFO:Uploading model into container now
2023-05-24 19:30:40,313:INFO:_master_model_container: 13
2023-05-24 19:30:40,314:INFO:_display_container: 2
2023-05-24 19:30:40,315:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 19:30:40,315:INFO:create_model() successfully completed......................................
2023-05-24 19:30:40,420:INFO:SubProcess create_model() end ==================================
2023-05-24 19:30:40,420:INFO:Creating metrics dataframe
2023-05-24 19:30:40,438:INFO:Initializing Dummy Classifier
2023-05-24 19:30:40,439:INFO:Total runtime is 25.799881800015765 minutes
2023-05-24 19:30:40,445:INFO:SubProcess create_model() called ==================================
2023-05-24 19:30:40,446:INFO:Initializing create_model()
2023-05-24 19:30:40,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014AA7F4DDE0>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:30:40,446:INFO:Checking exceptions
2023-05-24 19:30:40,446:INFO:Importing libraries
2023-05-24 19:30:40,446:INFO:Copying training dataset
2023-05-24 19:30:40,557:INFO:Defining folds
2023-05-24 19:30:40,557:INFO:Declaring metric variables
2023-05-24 19:30:40,563:INFO:Importing untrained model
2023-05-24 19:30:40,567:INFO:Dummy Classifier Imported successfully
2023-05-24 19:30:40,574:INFO:Starting cross validation
2023-05-24 19:30:40,581:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:30:43,373:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,396:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,402:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,417:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:30:43,421:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,428:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,443:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:30:43,455:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,563:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,596:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,612:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:30:43,623:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,625:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,656:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,670:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,670:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:30:43,678:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,685:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,698:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,704:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,717:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:30:43,721:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,723:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,732:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,736:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:30:43,740:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,755:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,756:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:30:43,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,768:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:43,778:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:30:43,787:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:45,408:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:45,426:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:45,427:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:45,439:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:45,439:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:30:45,446:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:30:45,448:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:45,452:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1396: UserWarning: Note that pos_label (set to 'Positive') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2023-05-24 19:30:46,488:INFO:Calculating mean and std
2023-05-24 19:30:46,490:INFO:Creating metrics dataframe
2023-05-24 19:30:46,849:INFO:Uploading results into container
2023-05-24 19:30:46,849:INFO:Uploading model into container now
2023-05-24 19:30:46,850:INFO:_master_model_container: 14
2023-05-24 19:30:46,850:INFO:_display_container: 2
2023-05-24 19:30:46,850:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-24 19:30:46,850:INFO:create_model() successfully completed......................................
2023-05-24 19:30:46,943:INFO:SubProcess create_model() end ==================================
2023-05-24 19:30:46,944:INFO:Creating metrics dataframe
2023-05-24 19:30:46,992:INFO:Initializing create_model()
2023-05-24 19:30:46,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F32020>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:30:46,993:INFO:Checking exceptions
2023-05-24 19:30:46,995:INFO:Importing libraries
2023-05-24 19:30:46,996:INFO:Copying training dataset
2023-05-24 19:30:47,115:INFO:Defining folds
2023-05-24 19:30:47,115:INFO:Declaring metric variables
2023-05-24 19:30:47,115:INFO:Importing untrained model
2023-05-24 19:30:47,115:INFO:Declaring custom model
2023-05-24 19:30:47,115:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 19:30:47,119:INFO:Cross validation set to False
2023-05-24 19:30:47,119:INFO:Fitting Model
2023-05-24 19:30:59,153:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 19:30:59,153:INFO:create_model() successfully completed......................................
2023-05-24 19:30:59,297:INFO:_master_model_container: 14
2023-05-24 19:30:59,297:INFO:_display_container: 2
2023-05-24 19:30:59,299:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 19:30:59,299:INFO:compare_models() successfully completed......................................
2023-05-24 19:42:04,437:INFO:PyCaret ClassificationExperiment
2023-05-24 19:42:04,437:INFO:Logging name: clf-default-name
2023-05-24 19:42:04,437:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 19:42:04,438:INFO:version 3.0.2
2023-05-24 19:42:04,438:INFO:Initializing setup()
2023-05-24 19:42:04,438:INFO:self.USI: 090b
2023-05-24 19:42:04,439:INFO:self._variable_keys: {'X_train', 'logging_param', 'y_train', 'fold_groups_param', '_available_plots', 'X', 'X_test', 'pipeline', 'seed', 'y', 'n_jobs_param', 'idx', 'gpu_param', 'html_param', 'memory', 'gpu_n_jobs_param', 'fold_generator', 'y_test', 'data', 'exp_name_log', '_ml_usecase', 'exp_id', 'fix_imbalance', 'target_param', 'log_plots_param', 'fold_shuffle_param', 'is_multiclass', 'USI'}
2023-05-24 19:42:04,440:INFO:Checking environment
2023-05-24 19:42:04,440:INFO:python_version: 3.10.11
2023-05-24 19:42:04,440:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 19:42:04,440:INFO:machine: AMD64
2023-05-24 19:42:04,441:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 19:42:04,443:INFO:Memory: svmem(total=16889774080, available=9280208896, percent=45.1, used=7609565184, free=9280208896)
2023-05-24 19:42:04,444:INFO:Physical Core: 4
2023-05-24 19:42:04,444:INFO:Logical Core: 8
2023-05-24 19:42:04,444:INFO:Checking libraries
2023-05-24 19:42:04,445:INFO:System:
2023-05-24 19:42:04,445:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 19:42:04,445:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 19:42:04,445:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 19:42:04,445:INFO:PyCaret required dependencies:
2023-05-24 19:42:04,446:INFO:                 pip: 23.0.1
2023-05-24 19:42:04,446:INFO:          setuptools: 66.0.0
2023-05-24 19:42:04,446:INFO:             pycaret: 3.0.2
2023-05-24 19:42:04,446:INFO:             IPython: 8.13.2
2023-05-24 19:42:04,446:INFO:          ipywidgets: 8.0.6
2023-05-24 19:42:04,447:INFO:                tqdm: 4.65.0
2023-05-24 19:42:04,447:INFO:               numpy: 1.23.5
2023-05-24 19:42:04,447:INFO:              pandas: 1.5.3
2023-05-24 19:42:04,447:INFO:              jinja2: 3.1.2
2023-05-24 19:42:04,447:INFO:               scipy: 1.10.1
2023-05-24 19:42:04,448:INFO:              joblib: 1.2.0
2023-05-24 19:42:04,448:INFO:             sklearn: 1.2.2
2023-05-24 19:42:04,448:INFO:                pyod: 1.0.9
2023-05-24 19:42:04,448:INFO:            imblearn: 0.10.1
2023-05-24 19:42:04,449:INFO:   category_encoders: 2.6.1
2023-05-24 19:42:04,449:INFO:            lightgbm: 3.3.5
2023-05-24 19:42:04,449:INFO:               numba: 0.57.0
2023-05-24 19:42:04,449:INFO:            requests: 2.31.0
2023-05-24 19:42:04,449:INFO:          matplotlib: 3.7.1
2023-05-24 19:42:04,449:INFO:          scikitplot: 0.3.7
2023-05-24 19:42:04,451:INFO:         yellowbrick: 1.5
2023-05-24 19:42:04,451:INFO:              plotly: 5.14.1
2023-05-24 19:42:04,451:INFO:             kaleido: 0.2.1
2023-05-24 19:42:04,451:INFO:         statsmodels: 0.14.0
2023-05-24 19:42:04,451:INFO:              sktime: 0.17.0
2023-05-24 19:42:04,451:INFO:               tbats: 1.1.3
2023-05-24 19:42:04,451:INFO:            pmdarima: 2.0.3
2023-05-24 19:42:04,451:INFO:              psutil: 5.9.5
2023-05-24 19:42:04,451:INFO:PyCaret optional dependencies:
2023-05-24 19:42:04,451:INFO:                shap: Not installed
2023-05-24 19:42:04,451:INFO:           interpret: Not installed
2023-05-24 19:42:04,451:INFO:                umap: Not installed
2023-05-24 19:42:04,451:INFO:    pandas_profiling: Not installed
2023-05-24 19:42:04,451:INFO:  explainerdashboard: Not installed
2023-05-24 19:42:04,451:INFO:             autoviz: Not installed
2023-05-24 19:42:04,451:INFO:           fairlearn: Not installed
2023-05-24 19:42:04,451:INFO:             xgboost: Not installed
2023-05-24 19:42:04,451:INFO:            catboost: Not installed
2023-05-24 19:42:04,451:INFO:              kmodes: Not installed
2023-05-24 19:42:04,451:INFO:             mlxtend: Not installed
2023-05-24 19:42:04,451:INFO:       statsforecast: Not installed
2023-05-24 19:42:04,451:INFO:        tune_sklearn: 0.4.5
2023-05-24 19:42:04,451:INFO:                 ray: 2.4.0
2023-05-24 19:42:04,451:INFO:            hyperopt: 0.2.7
2023-05-24 19:42:04,451:INFO:              optuna: 3.1.1
2023-05-24 19:42:04,451:INFO:               skopt: 0.9.0
2023-05-24 19:42:04,451:INFO:              mlflow: Not installed
2023-05-24 19:42:04,451:INFO:              gradio: Not installed
2023-05-24 19:42:04,451:INFO:             fastapi: Not installed
2023-05-24 19:42:04,451:INFO:             uvicorn: Not installed
2023-05-24 19:42:04,451:INFO:              m2cgen: Not installed
2023-05-24 19:42:04,451:INFO:           evidently: Not installed
2023-05-24 19:42:04,451:INFO:               fugue: Not installed
2023-05-24 19:42:04,453:INFO:           streamlit: Not installed
2023-05-24 19:42:04,453:INFO:             prophet: Not installed
2023-05-24 19:42:04,453:INFO:None
2023-05-24 19:42:04,453:INFO:Set up data.
2023-05-24 19:42:04,733:INFO:Set up train/test split.
2023-05-24 19:42:04,853:INFO:Set up index.
2023-05-24 19:42:04,858:INFO:Set up folding strategy.
2023-05-24 19:42:04,859:INFO:Assigning column types.
2023-05-24 19:42:04,956:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 19:42:04,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 19:42:04,998:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:42:05,027:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,027:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,066:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 19:42:05,067:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:42:05,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,117:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 19:42:05,164:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:42:05,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,240:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:42:05,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,277:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 19:42:05,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:05,435:INFO:Preparing preprocessing pipeline...
2023-05-24 19:42:05,444:INFO:Set up label encoding.
2023-05-24 19:42:05,444:INFO:Set up simple imputation.
2023-05-24 19:42:05,444:INFO:Set up imbalanced handling.
2023-05-24 19:42:05,452:INFO:Set up column name cleaning.
2023-05-24 19:42:08,379:INFO:Finished creating preprocessing pipeline.
2023-05-24 19:42:08,388:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 19:42:08,388:INFO:Creating final display dataframe.
2023-05-24 19:42:12,277:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (46252, 508)
5        Transformed data shape              (51442, 508)
6   Transformed train set shape              (37566, 508)
7    Transformed test set shape              (13876, 508)
8              Numeric features                       507
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      090b
2023-05-24 19:42:12,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:12,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:12,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:12,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:12,472:INFO:setup() successfully completed in 8.34s...............
2023-05-24 19:42:20,753:INFO:PyCaret ClassificationExperiment
2023-05-24 19:42:20,753:INFO:Logging name: clf-default-name
2023-05-24 19:42:20,753:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 19:42:20,753:INFO:version 3.0.2
2023-05-24 19:42:20,753:INFO:Initializing setup()
2023-05-24 19:42:20,753:INFO:self.USI: f915
2023-05-24 19:42:20,753:INFO:self._variable_keys: {'X_train', 'logging_param', 'y_train', 'fold_groups_param', '_available_plots', 'X', 'X_test', 'pipeline', 'seed', 'y', 'n_jobs_param', 'idx', 'gpu_param', 'html_param', 'memory', 'gpu_n_jobs_param', 'fold_generator', 'y_test', 'data', 'exp_name_log', '_ml_usecase', 'exp_id', 'fix_imbalance', 'target_param', 'log_plots_param', 'fold_shuffle_param', 'is_multiclass', 'USI'}
2023-05-24 19:42:20,753:INFO:Checking environment
2023-05-24 19:42:20,753:INFO:python_version: 3.10.11
2023-05-24 19:42:20,753:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 19:42:20,753:INFO:machine: AMD64
2023-05-24 19:42:20,753:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 19:42:20,757:INFO:Memory: svmem(total=16889774080, available=8698916864, percent=48.5, used=8190857216, free=8698916864)
2023-05-24 19:42:20,757:INFO:Physical Core: 4
2023-05-24 19:42:20,757:INFO:Logical Core: 8
2023-05-24 19:42:20,757:INFO:Checking libraries
2023-05-24 19:42:20,757:INFO:System:
2023-05-24 19:42:20,757:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 19:42:20,757:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 19:42:20,757:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 19:42:20,758:INFO:PyCaret required dependencies:
2023-05-24 19:42:20,758:INFO:                 pip: 23.0.1
2023-05-24 19:42:20,758:INFO:          setuptools: 66.0.0
2023-05-24 19:42:20,758:INFO:             pycaret: 3.0.2
2023-05-24 19:42:20,758:INFO:             IPython: 8.13.2
2023-05-24 19:42:20,758:INFO:          ipywidgets: 8.0.6
2023-05-24 19:42:20,758:INFO:                tqdm: 4.65.0
2023-05-24 19:42:20,758:INFO:               numpy: 1.23.5
2023-05-24 19:42:20,758:INFO:              pandas: 1.5.3
2023-05-24 19:42:20,758:INFO:              jinja2: 3.1.2
2023-05-24 19:42:20,758:INFO:               scipy: 1.10.1
2023-05-24 19:42:20,758:INFO:              joblib: 1.2.0
2023-05-24 19:42:20,758:INFO:             sklearn: 1.2.2
2023-05-24 19:42:20,758:INFO:                pyod: 1.0.9
2023-05-24 19:42:20,758:INFO:            imblearn: 0.10.1
2023-05-24 19:42:20,758:INFO:   category_encoders: 2.6.1
2023-05-24 19:42:20,758:INFO:            lightgbm: 3.3.5
2023-05-24 19:42:20,758:INFO:               numba: 0.57.0
2023-05-24 19:42:20,758:INFO:            requests: 2.31.0
2023-05-24 19:42:20,758:INFO:          matplotlib: 3.7.1
2023-05-24 19:42:20,758:INFO:          scikitplot: 0.3.7
2023-05-24 19:42:20,758:INFO:         yellowbrick: 1.5
2023-05-24 19:42:20,758:INFO:              plotly: 5.14.1
2023-05-24 19:42:20,758:INFO:             kaleido: 0.2.1
2023-05-24 19:42:20,758:INFO:         statsmodels: 0.14.0
2023-05-24 19:42:20,758:INFO:              sktime: 0.17.0
2023-05-24 19:42:20,758:INFO:               tbats: 1.1.3
2023-05-24 19:42:20,758:INFO:            pmdarima: 2.0.3
2023-05-24 19:42:20,758:INFO:              psutil: 5.9.5
2023-05-24 19:42:20,758:INFO:PyCaret optional dependencies:
2023-05-24 19:42:20,759:INFO:                shap: Not installed
2023-05-24 19:42:20,759:INFO:           interpret: Not installed
2023-05-24 19:42:20,759:INFO:                umap: Not installed
2023-05-24 19:42:20,759:INFO:    pandas_profiling: Not installed
2023-05-24 19:42:20,759:INFO:  explainerdashboard: Not installed
2023-05-24 19:42:20,759:INFO:             autoviz: Not installed
2023-05-24 19:42:20,759:INFO:           fairlearn: Not installed
2023-05-24 19:42:20,759:INFO:             xgboost: Not installed
2023-05-24 19:42:20,759:INFO:            catboost: Not installed
2023-05-24 19:42:20,759:INFO:              kmodes: Not installed
2023-05-24 19:42:20,759:INFO:             mlxtend: Not installed
2023-05-24 19:42:20,759:INFO:       statsforecast: Not installed
2023-05-24 19:42:20,759:INFO:        tune_sklearn: 0.4.5
2023-05-24 19:42:20,759:INFO:                 ray: 2.4.0
2023-05-24 19:42:20,759:INFO:            hyperopt: 0.2.7
2023-05-24 19:42:20,759:INFO:              optuna: 3.1.1
2023-05-24 19:42:20,759:INFO:               skopt: 0.9.0
2023-05-24 19:42:20,759:INFO:              mlflow: Not installed
2023-05-24 19:42:20,759:INFO:              gradio: Not installed
2023-05-24 19:42:20,759:INFO:             fastapi: Not installed
2023-05-24 19:42:20,759:INFO:             uvicorn: Not installed
2023-05-24 19:42:20,759:INFO:              m2cgen: Not installed
2023-05-24 19:42:20,759:INFO:           evidently: Not installed
2023-05-24 19:42:20,759:INFO:               fugue: Not installed
2023-05-24 19:42:20,759:INFO:           streamlit: Not installed
2023-05-24 19:42:20,759:INFO:             prophet: Not installed
2023-05-24 19:42:20,759:INFO:None
2023-05-24 19:42:20,759:INFO:Set up data.
2023-05-24 19:42:21,000:INFO:Set up train/test split.
2023-05-24 19:42:21,115:INFO:Set up index.
2023-05-24 19:42:21,119:INFO:Set up folding strategy.
2023-05-24 19:42:21,119:INFO:Assigning column types.
2023-05-24 19:42:21,182:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 19:42:21,219:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 19:42:21,220:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:42:21,244:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,283:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 19:42:21,284:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:42:21,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,311:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 19:42:21,352:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:42:21,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,419:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 19:42:21,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,444:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 19:42:21,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:21,579:INFO:Preparing preprocessing pipeline...
2023-05-24 19:42:21,588:INFO:Set up label encoding.
2023-05-24 19:42:21,588:INFO:Set up simple imputation.
2023-05-24 19:42:21,588:INFO:Set up imbalanced handling.
2023-05-24 19:42:21,596:INFO:Set up column name cleaning.
2023-05-24 19:42:22,232:INFO:Finished creating preprocessing pipeline.
2023-05-24 19:42:22,242:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 19:42:22,243:INFO:Creating final display dataframe.
2023-05-24 19:42:24,547:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (46252, 508)
5        Transformed data shape              (51442, 508)
6   Transformed train set shape              (37566, 508)
7    Transformed test set shape              (13876, 508)
8              Numeric features                       507
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      f915
2023-05-24 19:42:24,629:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:24,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:24,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:24,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 19:42:24,700:INFO:setup() successfully completed in 4.16s...............
2023-05-24 19:42:26,093:INFO:Initializing compare_models()
2023-05-24 19:42:26,093:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-24 19:42:26,093:INFO:Checking exceptions
2023-05-24 19:42:26,147:INFO:Preparing display monitor
2023-05-24 19:42:26,169:INFO:Initializing Logistic Regression
2023-05-24 19:42:26,170:INFO:Total runtime is 1.6589959462483723e-05 minutes
2023-05-24 19:42:26,173:INFO:SubProcess create_model() called ==================================
2023-05-24 19:42:26,174:INFO:Initializing create_model()
2023-05-24 19:42:26,174:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:42:26,174:INFO:Checking exceptions
2023-05-24 19:42:26,174:INFO:Importing libraries
2023-05-24 19:42:26,174:INFO:Copying training dataset
2023-05-24 19:42:26,292:INFO:Defining folds
2023-05-24 19:42:26,293:INFO:Declaring metric variables
2023-05-24 19:42:26,297:INFO:Importing untrained model
2023-05-24 19:42:26,301:INFO:Logistic Regression Imported successfully
2023-05-24 19:42:26,311:INFO:Starting cross validation
2023-05-24 19:42:26,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:44:07,153:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:44:07,782:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:44:07,946:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:44:08,349:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:44:08,627:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:44:08,965:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:44:10,418:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:44:11,060:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:44:40,450:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:44:40,462:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 19:44:41,290:INFO:Calculating mean and std
2023-05-24 19:44:41,293:INFO:Creating metrics dataframe
2023-05-24 19:44:41,546:INFO:Uploading results into container
2023-05-24 19:44:41,546:INFO:Uploading model into container now
2023-05-24 19:44:41,547:INFO:_master_model_container: 1
2023-05-24 19:44:41,547:INFO:_display_container: 2
2023-05-24 19:44:41,547:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-24 19:44:41,547:INFO:create_model() successfully completed......................................
2023-05-24 19:44:41,643:INFO:SubProcess create_model() end ==================================
2023-05-24 19:44:41,644:INFO:Creating metrics dataframe
2023-05-24 19:44:41,652:INFO:Initializing K Neighbors Classifier
2023-05-24 19:44:41,652:INFO:Total runtime is 2.2580451409022015 minutes
2023-05-24 19:44:41,657:INFO:SubProcess create_model() called ==================================
2023-05-24 19:44:41,657:INFO:Initializing create_model()
2023-05-24 19:44:41,658:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:44:41,658:INFO:Checking exceptions
2023-05-24 19:44:41,658:INFO:Importing libraries
2023-05-24 19:44:41,658:INFO:Copying training dataset
2023-05-24 19:44:41,750:INFO:Defining folds
2023-05-24 19:44:41,750:INFO:Declaring metric variables
2023-05-24 19:44:41,753:INFO:Importing untrained model
2023-05-24 19:44:41,758:INFO:K Neighbors Classifier Imported successfully
2023-05-24 19:44:41,766:INFO:Starting cross validation
2023-05-24 19:44:41,783:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:44:45,349:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-24 19:44:45,370:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-24 19:44:45,553:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-24 19:45:09,988:INFO:Calculating mean and std
2023-05-24 19:45:09,989:INFO:Creating metrics dataframe
2023-05-24 19:45:10,248:INFO:Uploading results into container
2023-05-24 19:45:10,249:INFO:Uploading model into container now
2023-05-24 19:45:10,249:INFO:_master_model_container: 2
2023-05-24 19:45:10,249:INFO:_display_container: 2
2023-05-24 19:45:10,249:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-24 19:45:10,249:INFO:create_model() successfully completed......................................
2023-05-24 19:45:10,337:INFO:SubProcess create_model() end ==================================
2023-05-24 19:45:10,337:INFO:Creating metrics dataframe
2023-05-24 19:45:10,347:INFO:Initializing Naive Bayes
2023-05-24 19:45:10,348:INFO:Total runtime is 2.7363177776336673 minutes
2023-05-24 19:45:10,365:INFO:SubProcess create_model() called ==================================
2023-05-24 19:45:10,365:INFO:Initializing create_model()
2023-05-24 19:45:10,366:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:45:10,366:INFO:Checking exceptions
2023-05-24 19:45:10,366:INFO:Importing libraries
2023-05-24 19:45:10,366:INFO:Copying training dataset
2023-05-24 19:45:10,457:INFO:Defining folds
2023-05-24 19:45:10,457:INFO:Declaring metric variables
2023-05-24 19:45:10,461:INFO:Importing untrained model
2023-05-24 19:45:10,466:INFO:Naive Bayes Imported successfully
2023-05-24 19:45:10,472:INFO:Starting cross validation
2023-05-24 19:45:10,487:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:45:17,377:INFO:Calculating mean and std
2023-05-24 19:45:17,378:INFO:Creating metrics dataframe
2023-05-24 19:45:17,636:INFO:Uploading results into container
2023-05-24 19:45:17,638:INFO:Uploading model into container now
2023-05-24 19:45:17,638:INFO:_master_model_container: 3
2023-05-24 19:45:17,638:INFO:_display_container: 2
2023-05-24 19:45:17,638:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-24 19:45:17,638:INFO:create_model() successfully completed......................................
2023-05-24 19:45:17,725:INFO:SubProcess create_model() end ==================================
2023-05-24 19:45:17,725:INFO:Creating metrics dataframe
2023-05-24 19:45:17,734:INFO:Initializing Decision Tree Classifier
2023-05-24 19:45:17,734:INFO:Total runtime is 2.8594232161839805 minutes
2023-05-24 19:45:17,738:INFO:SubProcess create_model() called ==================================
2023-05-24 19:45:17,738:INFO:Initializing create_model()
2023-05-24 19:45:17,739:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:45:17,739:INFO:Checking exceptions
2023-05-24 19:45:17,739:INFO:Importing libraries
2023-05-24 19:45:17,739:INFO:Copying training dataset
2023-05-24 19:45:17,836:INFO:Defining folds
2023-05-24 19:45:17,836:INFO:Declaring metric variables
2023-05-24 19:45:17,840:INFO:Importing untrained model
2023-05-24 19:45:17,845:INFO:Decision Tree Classifier Imported successfully
2023-05-24 19:45:17,853:INFO:Starting cross validation
2023-05-24 19:45:17,869:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:45:34,179:INFO:Calculating mean and std
2023-05-24 19:45:34,180:INFO:Creating metrics dataframe
2023-05-24 19:45:34,454:INFO:Uploading results into container
2023-05-24 19:45:34,455:INFO:Uploading model into container now
2023-05-24 19:45:34,456:INFO:_master_model_container: 4
2023-05-24 19:45:34,456:INFO:_display_container: 2
2023-05-24 19:45:34,456:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-24 19:45:34,456:INFO:create_model() successfully completed......................................
2023-05-24 19:45:34,547:INFO:SubProcess create_model() end ==================================
2023-05-24 19:45:34,547:INFO:Creating metrics dataframe
2023-05-24 19:45:34,556:INFO:Initializing SVM - Linear Kernel
2023-05-24 19:45:34,557:INFO:Total runtime is 3.1397781888643905 minutes
2023-05-24 19:45:34,561:INFO:SubProcess create_model() called ==================================
2023-05-24 19:45:34,561:INFO:Initializing create_model()
2023-05-24 19:45:34,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:45:34,562:INFO:Checking exceptions
2023-05-24 19:45:34,562:INFO:Importing libraries
2023-05-24 19:45:34,562:INFO:Copying training dataset
2023-05-24 19:45:34,654:INFO:Defining folds
2023-05-24 19:45:34,654:INFO:Declaring metric variables
2023-05-24 19:45:34,657:INFO:Importing untrained model
2023-05-24 19:45:34,664:INFO:SVM - Linear Kernel Imported successfully
2023-05-24 19:45:34,670:INFO:Starting cross validation
2023-05-24 19:45:34,685:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:45:37,917:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:45:37,990:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:45:38,327:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:45:38,733:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:45:38,781:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:45:38,832:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:45:38,861:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:45:39,382:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:45:41,298:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:45:41,555:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 19:45:41,802:INFO:Calculating mean and std
2023-05-24 19:45:41,803:INFO:Creating metrics dataframe
2023-05-24 19:45:42,100:INFO:Uploading results into container
2023-05-24 19:45:42,101:INFO:Uploading model into container now
2023-05-24 19:45:42,102:INFO:_master_model_container: 5
2023-05-24 19:45:42,102:INFO:_display_container: 2
2023-05-24 19:45:42,102:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-24 19:45:42,102:INFO:create_model() successfully completed......................................
2023-05-24 19:45:42,188:INFO:SubProcess create_model() end ==================================
2023-05-24 19:45:42,188:INFO:Creating metrics dataframe
2023-05-24 19:45:42,198:INFO:Initializing Ridge Classifier
2023-05-24 19:45:42,198:INFO:Total runtime is 3.267150441805522 minutes
2023-05-24 19:45:42,202:INFO:SubProcess create_model() called ==================================
2023-05-24 19:45:42,203:INFO:Initializing create_model()
2023-05-24 19:45:42,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:45:42,203:INFO:Checking exceptions
2023-05-24 19:45:42,203:INFO:Importing libraries
2023-05-24 19:45:42,203:INFO:Copying training dataset
2023-05-24 19:45:42,293:INFO:Defining folds
2023-05-24 19:45:42,294:INFO:Declaring metric variables
2023-05-24 19:45:42,298:INFO:Importing untrained model
2023-05-24 19:45:42,303:INFO:Ridge Classifier Imported successfully
2023-05-24 19:45:42,312:INFO:Starting cross validation
2023-05-24 19:45:42,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:45:46,188:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:45:46,213:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:45:46,299:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:45:46,330:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:45:46,539:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:45:46,548:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:45:46,588:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:45:49,005:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:45:49,112:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 19:45:49,838:INFO:Calculating mean and std
2023-05-24 19:45:49,839:INFO:Creating metrics dataframe
2023-05-24 19:45:50,122:INFO:Uploading results into container
2023-05-24 19:45:50,123:INFO:Uploading model into container now
2023-05-24 19:45:50,123:INFO:_master_model_container: 6
2023-05-24 19:45:50,123:INFO:_display_container: 2
2023-05-24 19:45:50,124:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-24 19:45:50,124:INFO:create_model() successfully completed......................................
2023-05-24 19:45:50,208:INFO:SubProcess create_model() end ==================================
2023-05-24 19:45:50,208:INFO:Creating metrics dataframe
2023-05-24 19:45:50,220:INFO:Initializing Random Forest Classifier
2023-05-24 19:45:50,220:INFO:Total runtime is 3.400850943724315 minutes
2023-05-24 19:45:50,223:INFO:SubProcess create_model() called ==================================
2023-05-24 19:45:50,223:INFO:Initializing create_model()
2023-05-24 19:45:50,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:45:50,224:INFO:Checking exceptions
2023-05-24 19:45:50,224:INFO:Importing libraries
2023-05-24 19:45:50,224:INFO:Copying training dataset
2023-05-24 19:45:50,314:INFO:Defining folds
2023-05-24 19:45:50,314:INFO:Declaring metric variables
2023-05-24 19:45:50,319:INFO:Importing untrained model
2023-05-24 19:45:50,323:INFO:Random Forest Classifier Imported successfully
2023-05-24 19:45:50,330:INFO:Starting cross validation
2023-05-24 19:45:50,344:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:46:22,904:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:46:23,189:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.41s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:46:24,459:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:46:24,522:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:46:25,225:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:46:25,584:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:46:25,646:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:46:25,669:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:46:37,315:INFO:Calculating mean and std
2023-05-24 19:46:37,317:INFO:Creating metrics dataframe
2023-05-24 19:46:37,750:INFO:Uploading results into container
2023-05-24 19:46:37,750:INFO:Uploading model into container now
2023-05-24 19:46:37,751:INFO:_master_model_container: 7
2023-05-24 19:46:37,751:INFO:_display_container: 2
2023-05-24 19:46:37,751:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-24 19:46:37,751:INFO:create_model() successfully completed......................................
2023-05-24 19:46:37,868:INFO:SubProcess create_model() end ==================================
2023-05-24 19:46:37,868:INFO:Creating metrics dataframe
2023-05-24 19:46:37,887:INFO:Initializing Quadratic Discriminant Analysis
2023-05-24 19:46:37,888:INFO:Total runtime is 4.195317963759105 minutes
2023-05-24 19:46:37,895:INFO:SubProcess create_model() called ==================================
2023-05-24 19:46:37,895:INFO:Initializing create_model()
2023-05-24 19:46:37,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:46:37,895:INFO:Checking exceptions
2023-05-24 19:46:37,895:INFO:Importing libraries
2023-05-24 19:46:37,895:INFO:Copying training dataset
2023-05-24 19:46:37,999:INFO:Defining folds
2023-05-24 19:46:37,999:INFO:Declaring metric variables
2023-05-24 19:46:38,004:INFO:Importing untrained model
2023-05-24 19:46:38,011:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-24 19:46:38,018:INFO:Starting cross validation
2023-05-24 19:46:38,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:46:44,958:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:46:45,000:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:46:45,063:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:46:45,065:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:46:45,065:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:46:45,089:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:46:45,095:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:46:45,099:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:46:56,281:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:46:56,304:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 19:46:59,232:INFO:Calculating mean and std
2023-05-24 19:46:59,234:INFO:Creating metrics dataframe
2023-05-24 19:46:59,675:INFO:Uploading results into container
2023-05-24 19:46:59,676:INFO:Uploading model into container now
2023-05-24 19:46:59,677:INFO:_master_model_container: 8
2023-05-24 19:46:59,677:INFO:_display_container: 2
2023-05-24 19:46:59,679:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-24 19:46:59,679:INFO:create_model() successfully completed......................................
2023-05-24 19:46:59,776:INFO:SubProcess create_model() end ==================================
2023-05-24 19:46:59,776:INFO:Creating metrics dataframe
2023-05-24 19:46:59,800:INFO:Initializing Ada Boost Classifier
2023-05-24 19:46:59,800:INFO:Total runtime is 4.560521046320598 minutes
2023-05-24 19:46:59,805:INFO:SubProcess create_model() called ==================================
2023-05-24 19:46:59,806:INFO:Initializing create_model()
2023-05-24 19:46:59,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:46:59,806:INFO:Checking exceptions
2023-05-24 19:46:59,806:INFO:Importing libraries
2023-05-24 19:46:59,806:INFO:Copying training dataset
2023-05-24 19:46:59,902:INFO:Defining folds
2023-05-24 19:46:59,902:INFO:Declaring metric variables
2023-05-24 19:46:59,906:INFO:Importing untrained model
2023-05-24 19:46:59,911:INFO:Ada Boost Classifier Imported successfully
2023-05-24 19:46:59,918:INFO:Starting cross validation
2023-05-24 19:46:59,939:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:47:37,743:INFO:Calculating mean and std
2023-05-24 19:47:37,744:INFO:Creating metrics dataframe
2023-05-24 19:47:38,193:INFO:Uploading results into container
2023-05-24 19:47:38,193:INFO:Uploading model into container now
2023-05-24 19:47:38,194:INFO:_master_model_container: 9
2023-05-24 19:47:38,194:INFO:_display_container: 2
2023-05-24 19:47:38,194:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-24 19:47:38,195:INFO:create_model() successfully completed......................................
2023-05-24 19:47:38,299:INFO:SubProcess create_model() end ==================================
2023-05-24 19:47:38,299:INFO:Creating metrics dataframe
2023-05-24 19:47:38,314:INFO:Initializing Gradient Boosting Classifier
2023-05-24 19:47:38,314:INFO:Total runtime is 5.202415891488394 minutes
2023-05-24 19:47:38,318:INFO:SubProcess create_model() called ==================================
2023-05-24 19:47:38,318:INFO:Initializing create_model()
2023-05-24 19:47:38,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:47:38,319:INFO:Checking exceptions
2023-05-24 19:47:38,319:INFO:Importing libraries
2023-05-24 19:47:38,319:INFO:Copying training dataset
2023-05-24 19:47:38,412:INFO:Defining folds
2023-05-24 19:47:38,412:INFO:Declaring metric variables
2023-05-24 19:47:38,417:INFO:Importing untrained model
2023-05-24 19:47:38,423:INFO:Gradient Boosting Classifier Imported successfully
2023-05-24 19:47:38,436:INFO:Starting cross validation
2023-05-24 19:47:38,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:48:45,167:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:48:45,401:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:48:45,894:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:48:46,352:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:48:47,352:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:48:49,158:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:49:21,576:INFO:Calculating mean and std
2023-05-24 19:49:21,576:INFO:Creating metrics dataframe
2023-05-24 19:49:21,874:INFO:Uploading results into container
2023-05-24 19:49:21,874:INFO:Uploading model into container now
2023-05-24 19:49:21,874:INFO:_master_model_container: 10
2023-05-24 19:49:21,874:INFO:_display_container: 2
2023-05-24 19:49:21,874:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-24 19:49:21,874:INFO:create_model() successfully completed......................................
2023-05-24 19:49:21,952:INFO:SubProcess create_model() end ==================================
2023-05-24 19:49:21,952:INFO:Creating metrics dataframe
2023-05-24 19:49:21,952:INFO:Initializing Linear Discriminant Analysis
2023-05-24 19:49:21,952:INFO:Total runtime is 6.929712363084158 minutes
2023-05-24 19:49:21,952:INFO:SubProcess create_model() called ==================================
2023-05-24 19:49:21,952:INFO:Initializing create_model()
2023-05-24 19:49:21,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:49:21,967:INFO:Checking exceptions
2023-05-24 19:49:21,967:INFO:Importing libraries
2023-05-24 19:49:21,967:INFO:Copying training dataset
2023-05-24 19:49:22,036:INFO:Defining folds
2023-05-24 19:49:22,036:INFO:Declaring metric variables
2023-05-24 19:49:22,052:INFO:Importing untrained model
2023-05-24 19:49:22,052:INFO:Linear Discriminant Analysis Imported successfully
2023-05-24 19:49:22,052:INFO:Starting cross validation
2023-05-24 19:49:22,068:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:49:39,922:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:49:39,927:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:49:50,645:INFO:Calculating mean and std
2023-05-24 19:49:50,647:INFO:Creating metrics dataframe
2023-05-24 19:49:50,987:INFO:Uploading results into container
2023-05-24 19:49:50,988:INFO:Uploading model into container now
2023-05-24 19:49:50,988:INFO:_master_model_container: 11
2023-05-24 19:49:50,988:INFO:_display_container: 2
2023-05-24 19:49:50,989:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-24 19:49:50,989:INFO:create_model() successfully completed......................................
2023-05-24 19:49:51,073:INFO:SubProcess create_model() end ==================================
2023-05-24 19:49:51,074:INFO:Creating metrics dataframe
2023-05-24 19:49:51,085:INFO:Initializing Extra Trees Classifier
2023-05-24 19:49:51,085:INFO:Total runtime is 7.415271266301473 minutes
2023-05-24 19:49:51,089:INFO:SubProcess create_model() called ==================================
2023-05-24 19:49:51,089:INFO:Initializing create_model()
2023-05-24 19:49:51,089:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:49:51,089:INFO:Checking exceptions
2023-05-24 19:49:51,089:INFO:Importing libraries
2023-05-24 19:49:51,089:INFO:Copying training dataset
2023-05-24 19:49:51,205:INFO:Defining folds
2023-05-24 19:49:51,206:INFO:Declaring metric variables
2023-05-24 19:49:51,210:INFO:Importing untrained model
2023-05-24 19:49:51,214:INFO:Extra Trees Classifier Imported successfully
2023-05-24 19:49:51,214:INFO:Starting cross validation
2023-05-24 19:49:51,230:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:50:50,340:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:50:52,226:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:50:52,255:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:50:52,277:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:50:52,701:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:50:52,860:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:50:52,908:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:51:13,870:INFO:Calculating mean and std
2023-05-24 19:51:13,872:INFO:Creating metrics dataframe
2023-05-24 19:51:14,335:INFO:Uploading results into container
2023-05-24 19:51:14,336:INFO:Uploading model into container now
2023-05-24 19:51:14,336:INFO:_master_model_container: 12
2023-05-24 19:51:14,337:INFO:_display_container: 2
2023-05-24 19:51:14,337:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-24 19:51:14,337:INFO:create_model() successfully completed......................................
2023-05-24 19:51:14,435:INFO:SubProcess create_model() end ==================================
2023-05-24 19:51:14,435:INFO:Creating metrics dataframe
2023-05-24 19:51:14,448:INFO:Initializing Light Gradient Boosting Machine
2023-05-24 19:51:14,448:INFO:Total runtime is 8.80464604695638 minutes
2023-05-24 19:51:14,454:INFO:SubProcess create_model() called ==================================
2023-05-24 19:51:14,454:INFO:Initializing create_model()
2023-05-24 19:51:14,454:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:51:14,454:INFO:Checking exceptions
2023-05-24 19:51:14,454:INFO:Importing libraries
2023-05-24 19:51:14,455:INFO:Copying training dataset
2023-05-24 19:51:14,557:INFO:Defining folds
2023-05-24 19:51:14,557:INFO:Declaring metric variables
2023-05-24 19:51:14,562:INFO:Importing untrained model
2023-05-24 19:51:14,567:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 19:51:14,575:INFO:Starting cross validation
2023-05-24 19:51:14,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:51:26,994:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:51:27,042:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:51:27,044:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:51:34,164:INFO:Calculating mean and std
2023-05-24 19:51:34,165:INFO:Creating metrics dataframe
2023-05-24 19:51:34,478:INFO:Uploading results into container
2023-05-24 19:51:34,478:INFO:Uploading model into container now
2023-05-24 19:51:34,478:INFO:_master_model_container: 13
2023-05-24 19:51:34,478:INFO:_display_container: 2
2023-05-24 19:51:34,478:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 19:51:34,478:INFO:create_model() successfully completed......................................
2023-05-24 19:51:34,557:INFO:SubProcess create_model() end ==================================
2023-05-24 19:51:34,557:INFO:Creating metrics dataframe
2023-05-24 19:51:34,572:INFO:Initializing Dummy Classifier
2023-05-24 19:51:34,572:INFO:Total runtime is 9.140050065517425 minutes
2023-05-24 19:51:34,572:INFO:SubProcess create_model() called ==================================
2023-05-24 19:51:34,572:INFO:Initializing create_model()
2023-05-24 19:51:34,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000014A933EE620>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:51:34,572:INFO:Checking exceptions
2023-05-24 19:51:34,572:INFO:Importing libraries
2023-05-24 19:51:34,572:INFO:Copying training dataset
2023-05-24 19:51:34,650:INFO:Defining folds
2023-05-24 19:51:34,650:INFO:Declaring metric variables
2023-05-24 19:51:34,666:INFO:Importing untrained model
2023-05-24 19:51:34,666:INFO:Dummy Classifier Imported successfully
2023-05-24 19:51:34,666:INFO:Starting cross validation
2023-05-24 19:51:34,681:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 19:51:36,813:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:51:36,876:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:51:36,923:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:51:37,034:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:51:37,081:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:51:37,128:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:51:37,128:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:51:37,192:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:51:38,776:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:51:38,870:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 19:51:40,099:INFO:Calculating mean and std
2023-05-24 19:51:40,100:INFO:Creating metrics dataframe
2023-05-24 19:51:40,435:INFO:Uploading results into container
2023-05-24 19:51:40,436:INFO:Uploading model into container now
2023-05-24 19:51:40,436:INFO:_master_model_container: 14
2023-05-24 19:51:40,436:INFO:_display_container: 2
2023-05-24 19:51:40,437:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-24 19:51:40,437:INFO:create_model() successfully completed......................................
2023-05-24 19:51:40,521:INFO:SubProcess create_model() end ==================================
2023-05-24 19:51:40,521:INFO:Creating metrics dataframe
2023-05-24 19:51:40,544:INFO:Initializing create_model()
2023-05-24 19:51:40,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-24 19:51:40,545:INFO:Checking exceptions
2023-05-24 19:51:40,547:INFO:Importing libraries
2023-05-24 19:51:40,547:INFO:Copying training dataset
2023-05-24 19:51:40,635:INFO:Defining folds
2023-05-24 19:51:40,635:INFO:Declaring metric variables
2023-05-24 19:51:40,635:INFO:Importing untrained model
2023-05-24 19:51:40,635:INFO:Declaring custom model
2023-05-24 19:51:40,636:INFO:Random Forest Classifier Imported successfully
2023-05-24 19:51:40,649:INFO:Cross validation set to False
2023-05-24 19:51:40,649:INFO:Fitting Model
2023-05-24 19:51:48,671:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-24 19:51:48,671:INFO:create_model() successfully completed......................................
2023-05-24 19:51:48,767:INFO:_master_model_container: 14
2023-05-24 19:51:48,767:INFO:_display_container: 2
2023-05-24 19:51:48,767:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-24 19:51:48,767:INFO:compare_models() successfully completed......................................
2023-05-24 19:56:04,610:INFO:Initializing tune_model()
2023-05-24 19:56:04,610:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000014AA7F36F20>)
2023-05-24 19:56:04,610:INFO:Checking exceptions
2023-05-24 19:56:04,610:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-24 19:56:04,670:INFO:Copying training dataset
2023-05-24 19:56:04,762:INFO:Checking base model
2023-05-24 19:56:04,762:INFO:Base model : Random Forest Classifier
2023-05-24 19:56:04,766:INFO:Declaring metric variables
2023-05-24 19:56:04,773:INFO:Defining Hyperparameters
2023-05-24 19:56:04,992:INFO:Tuning with n_jobs=-1
2023-05-24 19:56:04,999:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-24 19:56:04,999:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-24 19:56:05,004:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-05-24 19:56:05,005:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-24 19:56:05,005:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-24 19:57:56,418:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:57:58,239:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:58:00,459:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 19:58:02,014:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:58:07,611:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 19:59:51,535:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:00:08,301:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:00:09,911:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:00:20,205:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:00:28,779:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:00:58,290:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:01:42,185:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:02:21,206:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:02:36,425:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:04:19,680:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:04:35,619:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:05:36,712:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:06:17,232:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:06:34,831:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:06:36,747:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:10:55,800:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:11:08,335:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:11:14,075:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:11:15,150:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:11:43,949:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:12:27,830:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:13:25,360:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:13:26,782:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:13:56,511:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:13:58,030:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:14:54,785:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:14:56,160:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:15:00,040:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:18:13,811:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:18:27,682:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:18:56,750:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:18:58,087:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:19:35,982:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:19:36,493:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:19:37,923:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:19:38,226:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:19:40,768:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:19:40,827:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:19:41,897:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:19:48,623:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:19:49,987:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:20:33,231:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:20:34,472:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:21:33,826:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:26:21,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 20:26:21,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 20:26:21,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 20:26:21,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-24 20:26:22,447:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-24 20:27:13,622:WARNING:C:\Users\NT550-052\AppData\Local\Temp\ipykernel_12848\1336287416.py:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.
  X_train = pd.concat(X_train,y_train)

2023-05-24 20:29:24,911:INFO:PyCaret ClassificationExperiment
2023-05-24 20:29:24,911:INFO:Logging name: clf-default-name
2023-05-24 20:29:24,911:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 20:29:24,911:INFO:version 3.0.2
2023-05-24 20:29:24,911:INFO:Initializing setup()
2023-05-24 20:29:24,911:INFO:self.USI: 2ce5
2023-05-24 20:29:24,911:INFO:self._variable_keys: {'X_train', 'memory', 'fold_groups_param', 'y_train', '_available_plots', 'fix_imbalance', 'exp_id', '_ml_usecase', 'idx', 'seed', 'gpu_param', 'logging_param', 'USI', 'data', 'html_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_generator', 'X', 'X_test', 'y', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'pipeline', 'y_test', 'target_param'}
2023-05-24 20:29:24,911:INFO:Checking environment
2023-05-24 20:29:24,911:INFO:python_version: 3.10.11
2023-05-24 20:29:24,911:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 20:29:24,911:INFO:machine: AMD64
2023-05-24 20:29:24,911:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 20:29:24,911:INFO:Memory: svmem(total=16889774080, available=7703695360, percent=54.4, used=9186078720, free=7703695360)
2023-05-24 20:29:24,911:INFO:Physical Core: 4
2023-05-24 20:29:24,911:INFO:Logical Core: 8
2023-05-24 20:29:24,911:INFO:Checking libraries
2023-05-24 20:29:24,911:INFO:System:
2023-05-24 20:29:24,911:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 20:29:24,911:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 20:29:24,911:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 20:29:24,911:INFO:PyCaret required dependencies:
2023-05-24 20:29:24,911:INFO:                 pip: 23.0.1
2023-05-24 20:29:24,911:INFO:          setuptools: 66.0.0
2023-05-24 20:29:24,911:INFO:             pycaret: 3.0.2
2023-05-24 20:29:24,911:INFO:             IPython: 8.13.2
2023-05-24 20:29:24,911:INFO:          ipywidgets: 8.0.6
2023-05-24 20:29:24,911:INFO:                tqdm: 4.65.0
2023-05-24 20:29:24,911:INFO:               numpy: 1.23.5
2023-05-24 20:29:24,911:INFO:              pandas: 1.5.3
2023-05-24 20:29:24,911:INFO:              jinja2: 3.1.2
2023-05-24 20:29:24,911:INFO:               scipy: 1.10.1
2023-05-24 20:29:24,911:INFO:              joblib: 1.2.0
2023-05-24 20:29:24,911:INFO:             sklearn: 1.2.2
2023-05-24 20:29:24,911:INFO:                pyod: 1.0.9
2023-05-24 20:29:24,911:INFO:            imblearn: 0.10.1
2023-05-24 20:29:24,911:INFO:   category_encoders: 2.6.1
2023-05-24 20:29:24,911:INFO:            lightgbm: 3.3.5
2023-05-24 20:29:24,911:INFO:               numba: 0.57.0
2023-05-24 20:29:24,911:INFO:            requests: 2.31.0
2023-05-24 20:29:24,911:INFO:          matplotlib: 3.7.1
2023-05-24 20:29:24,911:INFO:          scikitplot: 0.3.7
2023-05-24 20:29:24,911:INFO:         yellowbrick: 1.5
2023-05-24 20:29:24,911:INFO:              plotly: 5.14.1
2023-05-24 20:29:24,911:INFO:             kaleido: 0.2.1
2023-05-24 20:29:24,911:INFO:         statsmodels: 0.14.0
2023-05-24 20:29:24,911:INFO:              sktime: 0.17.0
2023-05-24 20:29:24,911:INFO:               tbats: 1.1.3
2023-05-24 20:29:24,911:INFO:            pmdarima: 2.0.3
2023-05-24 20:29:24,911:INFO:              psutil: 5.9.5
2023-05-24 20:29:24,911:INFO:PyCaret optional dependencies:
2023-05-24 20:29:24,929:INFO:                shap: Not installed
2023-05-24 20:29:24,929:INFO:           interpret: Not installed
2023-05-24 20:29:24,929:INFO:                umap: Not installed
2023-05-24 20:29:24,929:INFO:    pandas_profiling: Not installed
2023-05-24 20:29:24,929:INFO:  explainerdashboard: Not installed
2023-05-24 20:29:24,929:INFO:             autoviz: Not installed
2023-05-24 20:29:24,929:INFO:           fairlearn: Not installed
2023-05-24 20:29:24,929:INFO:             xgboost: Not installed
2023-05-24 20:29:24,929:INFO:            catboost: Not installed
2023-05-24 20:29:24,929:INFO:              kmodes: Not installed
2023-05-24 20:29:24,930:INFO:             mlxtend: Not installed
2023-05-24 20:29:24,930:INFO:       statsforecast: Not installed
2023-05-24 20:29:24,930:INFO:        tune_sklearn: 0.4.5
2023-05-24 20:29:24,930:INFO:                 ray: 2.4.0
2023-05-24 20:29:24,930:INFO:            hyperopt: 0.2.7
2023-05-24 20:29:24,930:INFO:              optuna: 3.1.1
2023-05-24 20:29:24,930:INFO:               skopt: 0.9.0
2023-05-24 20:29:24,930:INFO:              mlflow: Not installed
2023-05-24 20:29:24,930:INFO:              gradio: Not installed
2023-05-24 20:29:24,930:INFO:             fastapi: Not installed
2023-05-24 20:29:24,930:INFO:             uvicorn: Not installed
2023-05-24 20:29:24,930:INFO:              m2cgen: Not installed
2023-05-24 20:29:24,930:INFO:           evidently: Not installed
2023-05-24 20:29:24,930:INFO:               fugue: Not installed
2023-05-24 20:29:24,930:INFO:           streamlit: Not installed
2023-05-24 20:29:24,930:INFO:             prophet: Not installed
2023-05-24 20:29:24,930:INFO:None
2023-05-24 20:29:24,930:INFO:Set up data.
2023-05-24 20:29:25,216:INFO:Set up train/test split.
2023-05-24 20:29:25,319:INFO:Set up index.
2023-05-24 20:29:25,327:INFO:Set up folding strategy.
2023-05-24 20:29:25,327:INFO:Assigning column types.
2023-05-24 20:29:25,377:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 20:29:25,415:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:29:25,419:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:29:25,452:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,515:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:29:25,516:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:29:25,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,539:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,539:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 20:29:25,585:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:29:25,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,717:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:29:25,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,753:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 20:29:25,826:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,892:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,893:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:25,895:INFO:Preparing preprocessing pipeline...
2023-05-24 20:29:25,902:INFO:Set up label encoding.
2023-05-24 20:29:25,902:INFO:Set up simple imputation.
2023-05-24 20:29:25,902:INFO:Set up imbalanced handling.
2023-05-24 20:29:25,908:INFO:Set up column name cleaning.
2023-05-24 20:29:28,492:INFO:Finished creating preprocessing pipeline.
2023-05-24 20:29:28,506:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 20:29:28,506:INFO:Creating final display dataframe.
2023-05-24 20:29:31,574:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 508)
5        Transformed data shape              (41153, 508)
6   Transformed train set shape              (30052, 508)
7    Transformed test set shape              (11101, 508)
8              Numeric features                       507
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      2ce5
2023-05-24 20:29:31,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:31,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:31,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:31,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:29:31,741:INFO:setup() successfully completed in 7.16s...............
2023-05-24 20:30:32,501:INFO:PyCaret ClassificationExperiment
2023-05-24 20:30:32,501:INFO:Logging name: clf-default-name
2023-05-24 20:30:32,501:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 20:30:32,501:INFO:version 3.0.2
2023-05-24 20:30:32,501:INFO:Initializing setup()
2023-05-24 20:30:32,501:INFO:self.USI: bb8c
2023-05-24 20:30:32,501:INFO:self._variable_keys: {'X_train', 'memory', 'fold_groups_param', 'y_train', '_available_plots', 'fix_imbalance', 'exp_id', '_ml_usecase', 'idx', 'seed', 'gpu_param', 'logging_param', 'USI', 'data', 'html_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_generator', 'X', 'X_test', 'y', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'pipeline', 'y_test', 'target_param'}
2023-05-24 20:30:32,501:INFO:Checking environment
2023-05-24 20:30:32,501:INFO:python_version: 3.10.11
2023-05-24 20:30:32,501:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 20:30:32,501:INFO:machine: AMD64
2023-05-24 20:30:32,501:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 20:30:32,504:INFO:Memory: svmem(total=16889774080, available=7257059328, percent=57.0, used=9632714752, free=7257059328)
2023-05-24 20:30:32,504:INFO:Physical Core: 4
2023-05-24 20:30:32,504:INFO:Logical Core: 8
2023-05-24 20:30:32,504:INFO:Checking libraries
2023-05-24 20:30:32,504:INFO:System:
2023-05-24 20:30:32,504:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 20:30:32,504:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 20:30:32,504:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 20:30:32,504:INFO:PyCaret required dependencies:
2023-05-24 20:30:32,504:INFO:                 pip: 23.0.1
2023-05-24 20:30:32,504:INFO:          setuptools: 66.0.0
2023-05-24 20:30:32,504:INFO:             pycaret: 3.0.2
2023-05-24 20:30:32,504:INFO:             IPython: 8.13.2
2023-05-24 20:30:32,504:INFO:          ipywidgets: 8.0.6
2023-05-24 20:30:32,504:INFO:                tqdm: 4.65.0
2023-05-24 20:30:32,504:INFO:               numpy: 1.23.5
2023-05-24 20:30:32,504:INFO:              pandas: 1.5.3
2023-05-24 20:30:32,504:INFO:              jinja2: 3.1.2
2023-05-24 20:30:32,504:INFO:               scipy: 1.10.1
2023-05-24 20:30:32,505:INFO:              joblib: 1.2.0
2023-05-24 20:30:32,505:INFO:             sklearn: 1.2.2
2023-05-24 20:30:32,505:INFO:                pyod: 1.0.9
2023-05-24 20:30:32,505:INFO:            imblearn: 0.10.1
2023-05-24 20:30:32,505:INFO:   category_encoders: 2.6.1
2023-05-24 20:30:32,505:INFO:            lightgbm: 3.3.5
2023-05-24 20:30:32,505:INFO:               numba: 0.57.0
2023-05-24 20:30:32,505:INFO:            requests: 2.31.0
2023-05-24 20:30:32,505:INFO:          matplotlib: 3.7.1
2023-05-24 20:30:32,505:INFO:          scikitplot: 0.3.7
2023-05-24 20:30:32,505:INFO:         yellowbrick: 1.5
2023-05-24 20:30:32,505:INFO:              plotly: 5.14.1
2023-05-24 20:30:32,505:INFO:             kaleido: 0.2.1
2023-05-24 20:30:32,505:INFO:         statsmodels: 0.14.0
2023-05-24 20:30:32,505:INFO:              sktime: 0.17.0
2023-05-24 20:30:32,505:INFO:               tbats: 1.1.3
2023-05-24 20:30:32,505:INFO:            pmdarima: 2.0.3
2023-05-24 20:30:32,505:INFO:              psutil: 5.9.5
2023-05-24 20:30:32,505:INFO:PyCaret optional dependencies:
2023-05-24 20:30:32,505:INFO:                shap: Not installed
2023-05-24 20:30:32,505:INFO:           interpret: Not installed
2023-05-24 20:30:32,505:INFO:                umap: Not installed
2023-05-24 20:30:32,505:INFO:    pandas_profiling: Not installed
2023-05-24 20:30:32,505:INFO:  explainerdashboard: Not installed
2023-05-24 20:30:32,505:INFO:             autoviz: Not installed
2023-05-24 20:30:32,505:INFO:           fairlearn: Not installed
2023-05-24 20:30:32,505:INFO:             xgboost: Not installed
2023-05-24 20:30:32,505:INFO:            catboost: Not installed
2023-05-24 20:30:32,506:INFO:              kmodes: Not installed
2023-05-24 20:30:32,506:INFO:             mlxtend: Not installed
2023-05-24 20:30:32,506:INFO:       statsforecast: Not installed
2023-05-24 20:30:32,506:INFO:        tune_sklearn: 0.4.5
2023-05-24 20:30:32,506:INFO:                 ray: 2.4.0
2023-05-24 20:30:32,506:INFO:            hyperopt: 0.2.7
2023-05-24 20:30:32,506:INFO:              optuna: 3.1.1
2023-05-24 20:30:32,506:INFO:               skopt: 0.9.0
2023-05-24 20:30:32,506:INFO:              mlflow: Not installed
2023-05-24 20:30:32,506:INFO:              gradio: Not installed
2023-05-24 20:30:32,506:INFO:             fastapi: Not installed
2023-05-24 20:30:32,506:INFO:             uvicorn: Not installed
2023-05-24 20:30:32,506:INFO:              m2cgen: Not installed
2023-05-24 20:30:32,506:INFO:           evidently: Not installed
2023-05-24 20:30:32,506:INFO:               fugue: Not installed
2023-05-24 20:30:32,506:INFO:           streamlit: Not installed
2023-05-24 20:30:32,506:INFO:             prophet: Not installed
2023-05-24 20:30:32,506:INFO:None
2023-05-24 20:30:32,506:INFO:Set up data.
2023-05-24 20:31:17,784:INFO:PyCaret ClassificationExperiment
2023-05-24 20:31:17,785:INFO:Logging name: clf-default-name
2023-05-24 20:31:17,785:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 20:31:17,785:INFO:version 3.0.2
2023-05-24 20:31:17,785:INFO:Initializing setup()
2023-05-24 20:31:17,785:INFO:self.USI: e99a
2023-05-24 20:31:17,785:INFO:self._variable_keys: {'X_train', 'memory', 'fold_groups_param', 'y_train', '_available_plots', 'fix_imbalance', 'exp_id', '_ml_usecase', 'idx', 'seed', 'gpu_param', 'logging_param', 'USI', 'data', 'html_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_generator', 'X', 'X_test', 'y', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'pipeline', 'y_test', 'target_param'}
2023-05-24 20:31:17,785:INFO:Checking environment
2023-05-24 20:31:17,785:INFO:python_version: 3.10.11
2023-05-24 20:31:17,785:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 20:31:17,785:INFO:machine: AMD64
2023-05-24 20:31:17,785:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 20:31:17,788:INFO:Memory: svmem(total=16889774080, available=7132545024, percent=57.8, used=9757229056, free=7132545024)
2023-05-24 20:31:17,788:INFO:Physical Core: 4
2023-05-24 20:31:17,788:INFO:Logical Core: 8
2023-05-24 20:31:17,788:INFO:Checking libraries
2023-05-24 20:31:17,788:INFO:System:
2023-05-24 20:31:17,788:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 20:31:17,788:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 20:31:17,788:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 20:31:17,788:INFO:PyCaret required dependencies:
2023-05-24 20:31:17,788:INFO:                 pip: 23.0.1
2023-05-24 20:31:17,788:INFO:          setuptools: 66.0.0
2023-05-24 20:31:17,788:INFO:             pycaret: 3.0.2
2023-05-24 20:31:17,788:INFO:             IPython: 8.13.2
2023-05-24 20:31:17,788:INFO:          ipywidgets: 8.0.6
2023-05-24 20:31:17,788:INFO:                tqdm: 4.65.0
2023-05-24 20:31:17,788:INFO:               numpy: 1.23.5
2023-05-24 20:31:17,788:INFO:              pandas: 1.5.3
2023-05-24 20:31:17,789:INFO:              jinja2: 3.1.2
2023-05-24 20:31:17,789:INFO:               scipy: 1.10.1
2023-05-24 20:31:17,789:INFO:              joblib: 1.2.0
2023-05-24 20:31:17,789:INFO:             sklearn: 1.2.2
2023-05-24 20:31:17,789:INFO:                pyod: 1.0.9
2023-05-24 20:31:17,789:INFO:            imblearn: 0.10.1
2023-05-24 20:31:17,789:INFO:   category_encoders: 2.6.1
2023-05-24 20:31:17,789:INFO:            lightgbm: 3.3.5
2023-05-24 20:31:17,789:INFO:               numba: 0.57.0
2023-05-24 20:31:17,789:INFO:            requests: 2.31.0
2023-05-24 20:31:17,789:INFO:          matplotlib: 3.7.1
2023-05-24 20:31:17,789:INFO:          scikitplot: 0.3.7
2023-05-24 20:31:17,789:INFO:         yellowbrick: 1.5
2023-05-24 20:31:17,789:INFO:              plotly: 5.14.1
2023-05-24 20:31:17,789:INFO:             kaleido: 0.2.1
2023-05-24 20:31:17,789:INFO:         statsmodels: 0.14.0
2023-05-24 20:31:17,789:INFO:              sktime: 0.17.0
2023-05-24 20:31:17,789:INFO:               tbats: 1.1.3
2023-05-24 20:31:17,789:INFO:            pmdarima: 2.0.3
2023-05-24 20:31:17,789:INFO:              psutil: 5.9.5
2023-05-24 20:31:17,789:INFO:PyCaret optional dependencies:
2023-05-24 20:31:17,789:INFO:                shap: Not installed
2023-05-24 20:31:17,789:INFO:           interpret: Not installed
2023-05-24 20:31:17,789:INFO:                umap: Not installed
2023-05-24 20:31:17,789:INFO:    pandas_profiling: Not installed
2023-05-24 20:31:17,789:INFO:  explainerdashboard: Not installed
2023-05-24 20:31:17,789:INFO:             autoviz: Not installed
2023-05-24 20:31:17,789:INFO:           fairlearn: Not installed
2023-05-24 20:31:17,790:INFO:             xgboost: Not installed
2023-05-24 20:31:17,790:INFO:            catboost: Not installed
2023-05-24 20:31:17,790:INFO:              kmodes: Not installed
2023-05-24 20:31:17,790:INFO:             mlxtend: Not installed
2023-05-24 20:31:17,790:INFO:       statsforecast: Not installed
2023-05-24 20:31:17,790:INFO:        tune_sklearn: 0.4.5
2023-05-24 20:31:17,790:INFO:                 ray: 2.4.0
2023-05-24 20:31:17,790:INFO:            hyperopt: 0.2.7
2023-05-24 20:31:17,790:INFO:              optuna: 3.1.1
2023-05-24 20:31:17,790:INFO:               skopt: 0.9.0
2023-05-24 20:31:17,790:INFO:              mlflow: Not installed
2023-05-24 20:31:17,790:INFO:              gradio: Not installed
2023-05-24 20:31:17,790:INFO:             fastapi: Not installed
2023-05-24 20:31:17,790:INFO:             uvicorn: Not installed
2023-05-24 20:31:17,790:INFO:              m2cgen: Not installed
2023-05-24 20:31:17,790:INFO:           evidently: Not installed
2023-05-24 20:31:17,790:INFO:               fugue: Not installed
2023-05-24 20:31:17,790:INFO:           streamlit: Not installed
2023-05-24 20:31:17,790:INFO:             prophet: Not installed
2023-05-24 20:31:17,790:INFO:None
2023-05-24 20:31:17,790:INFO:Set up data.
2023-05-24 20:31:17,981:INFO:Set up train/test split.
2023-05-24 20:31:18,075:INFO:Set up index.
2023-05-24 20:31:18,078:INFO:Set up folding strategy.
2023-05-24 20:31:18,079:INFO:Assigning column types.
2023-05-24 20:31:18,131:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 20:31:18,168:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:31:18,168:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:31:18,190:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,191:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,227:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:31:18,228:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:31:18,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,252:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 20:31:18,289:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:31:18,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,350:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:31:18,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,375:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 20:31:18,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,508:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:18,509:INFO:Preparing preprocessing pipeline...
2023-05-24 20:31:18,517:INFO:Set up label encoding.
2023-05-24 20:31:18,517:INFO:Set up simple imputation.
2023-05-24 20:31:18,517:INFO:Set up imbalanced handling.
2023-05-24 20:31:18,524:INFO:Set up column name cleaning.
2023-05-24 20:31:19,057:INFO:Finished creating preprocessing pipeline.
2023-05-24 20:31:19,067:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 20:31:19,067:INFO:Creating final display dataframe.
2023-05-24 20:31:20,593:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 508)
5        Transformed data shape              (41153, 508)
6   Transformed train set shape              (30052, 508)
7    Transformed test set shape              (11101, 508)
8              Numeric features                       507
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      e99a
2023-05-24 20:31:20,697:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:20,698:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:20,774:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:20,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:20,774:INFO:setup() successfully completed in 3.28s...............
2023-05-24 20:31:59,551:INFO:PyCaret ClassificationExperiment
2023-05-24 20:31:59,551:INFO:Logging name: clf-default-name
2023-05-24 20:31:59,551:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 20:31:59,551:INFO:version 3.0.2
2023-05-24 20:31:59,551:INFO:Initializing setup()
2023-05-24 20:31:59,551:INFO:self.USI: a8e3
2023-05-24 20:31:59,551:INFO:self._variable_keys: {'X_train', 'memory', 'fold_groups_param', 'y_train', '_available_plots', 'fix_imbalance', 'exp_id', '_ml_usecase', 'idx', 'seed', 'gpu_param', 'logging_param', 'USI', 'data', 'html_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_generator', 'X', 'X_test', 'y', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'pipeline', 'y_test', 'target_param'}
2023-05-24 20:31:59,551:INFO:Checking environment
2023-05-24 20:31:59,551:INFO:python_version: 3.10.11
2023-05-24 20:31:59,551:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 20:31:59,551:INFO:machine: AMD64
2023-05-24 20:31:59,551:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 20:31:59,554:INFO:Memory: svmem(total=16889774080, available=7018450944, percent=58.4, used=9871323136, free=7018450944)
2023-05-24 20:31:59,554:INFO:Physical Core: 4
2023-05-24 20:31:59,554:INFO:Logical Core: 8
2023-05-24 20:31:59,554:INFO:Checking libraries
2023-05-24 20:31:59,554:INFO:System:
2023-05-24 20:31:59,554:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 20:31:59,554:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 20:31:59,554:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 20:31:59,555:INFO:PyCaret required dependencies:
2023-05-24 20:31:59,555:INFO:                 pip: 23.0.1
2023-05-24 20:31:59,555:INFO:          setuptools: 66.0.0
2023-05-24 20:31:59,555:INFO:             pycaret: 3.0.2
2023-05-24 20:31:59,555:INFO:             IPython: 8.13.2
2023-05-24 20:31:59,555:INFO:          ipywidgets: 8.0.6
2023-05-24 20:31:59,555:INFO:                tqdm: 4.65.0
2023-05-24 20:31:59,555:INFO:               numpy: 1.23.5
2023-05-24 20:31:59,555:INFO:              pandas: 1.5.3
2023-05-24 20:31:59,555:INFO:              jinja2: 3.1.2
2023-05-24 20:31:59,555:INFO:               scipy: 1.10.1
2023-05-24 20:31:59,555:INFO:              joblib: 1.2.0
2023-05-24 20:31:59,555:INFO:             sklearn: 1.2.2
2023-05-24 20:31:59,555:INFO:                pyod: 1.0.9
2023-05-24 20:31:59,555:INFO:            imblearn: 0.10.1
2023-05-24 20:31:59,555:INFO:   category_encoders: 2.6.1
2023-05-24 20:31:59,555:INFO:            lightgbm: 3.3.5
2023-05-24 20:31:59,555:INFO:               numba: 0.57.0
2023-05-24 20:31:59,555:INFO:            requests: 2.31.0
2023-05-24 20:31:59,555:INFO:          matplotlib: 3.7.1
2023-05-24 20:31:59,555:INFO:          scikitplot: 0.3.7
2023-05-24 20:31:59,555:INFO:         yellowbrick: 1.5
2023-05-24 20:31:59,555:INFO:              plotly: 5.14.1
2023-05-24 20:31:59,555:INFO:             kaleido: 0.2.1
2023-05-24 20:31:59,555:INFO:         statsmodels: 0.14.0
2023-05-24 20:31:59,555:INFO:              sktime: 0.17.0
2023-05-24 20:31:59,556:INFO:               tbats: 1.1.3
2023-05-24 20:31:59,556:INFO:            pmdarima: 2.0.3
2023-05-24 20:31:59,556:INFO:              psutil: 5.9.5
2023-05-24 20:31:59,556:INFO:PyCaret optional dependencies:
2023-05-24 20:31:59,556:INFO:                shap: Not installed
2023-05-24 20:31:59,556:INFO:           interpret: Not installed
2023-05-24 20:31:59,556:INFO:                umap: Not installed
2023-05-24 20:31:59,556:INFO:    pandas_profiling: Not installed
2023-05-24 20:31:59,556:INFO:  explainerdashboard: Not installed
2023-05-24 20:31:59,556:INFO:             autoviz: Not installed
2023-05-24 20:31:59,556:INFO:           fairlearn: Not installed
2023-05-24 20:31:59,556:INFO:             xgboost: Not installed
2023-05-24 20:31:59,556:INFO:            catboost: Not installed
2023-05-24 20:31:59,556:INFO:              kmodes: Not installed
2023-05-24 20:31:59,556:INFO:             mlxtend: Not installed
2023-05-24 20:31:59,556:INFO:       statsforecast: Not installed
2023-05-24 20:31:59,556:INFO:        tune_sklearn: 0.4.5
2023-05-24 20:31:59,556:INFO:                 ray: 2.4.0
2023-05-24 20:31:59,556:INFO:            hyperopt: 0.2.7
2023-05-24 20:31:59,556:INFO:              optuna: 3.1.1
2023-05-24 20:31:59,556:INFO:               skopt: 0.9.0
2023-05-24 20:31:59,556:INFO:              mlflow: Not installed
2023-05-24 20:31:59,556:INFO:              gradio: Not installed
2023-05-24 20:31:59,556:INFO:             fastapi: Not installed
2023-05-24 20:31:59,556:INFO:             uvicorn: Not installed
2023-05-24 20:31:59,556:INFO:              m2cgen: Not installed
2023-05-24 20:31:59,556:INFO:           evidently: Not installed
2023-05-24 20:31:59,556:INFO:               fugue: Not installed
2023-05-24 20:31:59,556:INFO:           streamlit: Not installed
2023-05-24 20:31:59,557:INFO:             prophet: Not installed
2023-05-24 20:31:59,557:INFO:None
2023-05-24 20:31:59,557:INFO:Set up data.
2023-05-24 20:31:59,757:INFO:Set up train/test split.
2023-05-24 20:31:59,845:INFO:Set up index.
2023-05-24 20:31:59,848:INFO:Set up folding strategy.
2023-05-24 20:31:59,848:INFO:Assigning column types.
2023-05-24 20:31:59,901:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 20:31:59,939:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:31:59,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:31:59,964:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:31:59,964:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:00,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:32:00,002:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:32:00,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:00,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:00,027:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 20:32:00,066:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:32:00,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:00,089:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:00,127:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:32:00,150:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:00,150:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:00,150:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 20:32:00,210:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:00,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:00,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:00,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:00,278:INFO:Preparing preprocessing pipeline...
2023-05-24 20:32:00,288:INFO:Set up label encoding.
2023-05-24 20:32:00,289:INFO:Set up simple imputation.
2023-05-24 20:32:00,289:INFO:Set up imbalanced handling.
2023-05-24 20:32:00,295:INFO:Set up column name cleaning.
2023-05-24 20:32:00,724:INFO:Finished creating preprocessing pipeline.
2023-05-24 20:32:00,734:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 20:32:00,734:INFO:Creating final display dataframe.
2023-05-24 20:32:01,289:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 508)
5        Transformed data shape              (41153, 508)
6   Transformed train set shape              (30052, 508)
7    Transformed test set shape              (11101, 508)
8              Numeric features                       507
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      a8e3
2023-05-24 20:32:01,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:01,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:01,431:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:01,431:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:01,432:INFO:setup() successfully completed in 2.16s...............
2023-05-24 20:32:12,391:INFO:PyCaret ClassificationExperiment
2023-05-24 20:32:12,391:INFO:Logging name: clf-default-name
2023-05-24 20:32:12,391:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 20:32:12,391:INFO:version 3.0.2
2023-05-24 20:32:12,391:INFO:Initializing setup()
2023-05-24 20:32:12,391:INFO:self.USI: 32ec
2023-05-24 20:32:12,391:INFO:self._variable_keys: {'X_train', 'memory', 'fold_groups_param', 'y_train', '_available_plots', 'fix_imbalance', 'exp_id', '_ml_usecase', 'idx', 'seed', 'gpu_param', 'logging_param', 'USI', 'data', 'html_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_generator', 'X', 'X_test', 'y', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'pipeline', 'y_test', 'target_param'}
2023-05-24 20:32:12,391:INFO:Checking environment
2023-05-24 20:32:12,391:INFO:python_version: 3.10.11
2023-05-24 20:32:12,391:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 20:32:12,391:INFO:machine: AMD64
2023-05-24 20:32:12,392:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 20:32:12,394:INFO:Memory: svmem(total=16889774080, available=7000035328, percent=58.6, used=9889738752, free=7000035328)
2023-05-24 20:32:12,394:INFO:Physical Core: 4
2023-05-24 20:32:12,394:INFO:Logical Core: 8
2023-05-24 20:32:12,394:INFO:Checking libraries
2023-05-24 20:32:12,394:INFO:System:
2023-05-24 20:32:12,394:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 20:32:12,394:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 20:32:12,394:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 20:32:12,394:INFO:PyCaret required dependencies:
2023-05-24 20:32:12,394:INFO:                 pip: 23.0.1
2023-05-24 20:32:12,394:INFO:          setuptools: 66.0.0
2023-05-24 20:32:12,394:INFO:             pycaret: 3.0.2
2023-05-24 20:32:12,394:INFO:             IPython: 8.13.2
2023-05-24 20:32:12,395:INFO:          ipywidgets: 8.0.6
2023-05-24 20:32:12,395:INFO:                tqdm: 4.65.0
2023-05-24 20:32:12,395:INFO:               numpy: 1.23.5
2023-05-24 20:32:12,395:INFO:              pandas: 1.5.3
2023-05-24 20:32:12,395:INFO:              jinja2: 3.1.2
2023-05-24 20:32:12,395:INFO:               scipy: 1.10.1
2023-05-24 20:32:12,395:INFO:              joblib: 1.2.0
2023-05-24 20:32:12,395:INFO:             sklearn: 1.2.2
2023-05-24 20:32:12,395:INFO:                pyod: 1.0.9
2023-05-24 20:32:12,395:INFO:            imblearn: 0.10.1
2023-05-24 20:32:12,395:INFO:   category_encoders: 2.6.1
2023-05-24 20:32:12,395:INFO:            lightgbm: 3.3.5
2023-05-24 20:32:12,395:INFO:               numba: 0.57.0
2023-05-24 20:32:12,395:INFO:            requests: 2.31.0
2023-05-24 20:32:12,395:INFO:          matplotlib: 3.7.1
2023-05-24 20:32:12,395:INFO:          scikitplot: 0.3.7
2023-05-24 20:32:12,395:INFO:         yellowbrick: 1.5
2023-05-24 20:32:12,395:INFO:              plotly: 5.14.1
2023-05-24 20:32:12,395:INFO:             kaleido: 0.2.1
2023-05-24 20:32:12,395:INFO:         statsmodels: 0.14.0
2023-05-24 20:32:12,395:INFO:              sktime: 0.17.0
2023-05-24 20:32:12,395:INFO:               tbats: 1.1.3
2023-05-24 20:32:12,395:INFO:            pmdarima: 2.0.3
2023-05-24 20:32:12,395:INFO:              psutil: 5.9.5
2023-05-24 20:32:12,395:INFO:PyCaret optional dependencies:
2023-05-24 20:32:12,395:INFO:                shap: Not installed
2023-05-24 20:32:12,395:INFO:           interpret: Not installed
2023-05-24 20:32:12,395:INFO:                umap: Not installed
2023-05-24 20:32:12,396:INFO:    pandas_profiling: Not installed
2023-05-24 20:32:12,396:INFO:  explainerdashboard: Not installed
2023-05-24 20:32:12,396:INFO:             autoviz: Not installed
2023-05-24 20:32:12,396:INFO:           fairlearn: Not installed
2023-05-24 20:32:12,396:INFO:             xgboost: Not installed
2023-05-24 20:32:12,396:INFO:            catboost: Not installed
2023-05-24 20:32:12,396:INFO:              kmodes: Not installed
2023-05-24 20:32:12,396:INFO:             mlxtend: Not installed
2023-05-24 20:32:12,396:INFO:       statsforecast: Not installed
2023-05-24 20:32:12,396:INFO:        tune_sklearn: 0.4.5
2023-05-24 20:32:12,396:INFO:                 ray: 2.4.0
2023-05-24 20:32:12,396:INFO:            hyperopt: 0.2.7
2023-05-24 20:32:12,396:INFO:              optuna: 3.1.1
2023-05-24 20:32:12,396:INFO:               skopt: 0.9.0
2023-05-24 20:32:12,396:INFO:              mlflow: Not installed
2023-05-24 20:32:12,396:INFO:              gradio: Not installed
2023-05-24 20:32:12,396:INFO:             fastapi: Not installed
2023-05-24 20:32:12,396:INFO:             uvicorn: Not installed
2023-05-24 20:32:12,396:INFO:              m2cgen: Not installed
2023-05-24 20:32:12,396:INFO:           evidently: Not installed
2023-05-24 20:32:12,396:INFO:               fugue: Not installed
2023-05-24 20:32:12,396:INFO:           streamlit: Not installed
2023-05-24 20:32:12,396:INFO:             prophet: Not installed
2023-05-24 20:32:12,396:INFO:None
2023-05-24 20:32:12,396:INFO:Set up data.
2023-05-24 20:32:12,592:INFO:Set up train/test split.
2023-05-24 20:32:12,691:INFO:Set up index.
2023-05-24 20:32:12,693:INFO:Set up folding strategy.
2023-05-24 20:32:12,693:INFO:Assigning column types.
2023-05-24 20:32:12,748:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 20:32:12,790:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:32:12,790:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:32:12,814:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:12,815:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:12,855:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:32:12,855:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:32:12,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:12,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:12,880:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 20:32:12,917:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:32:12,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:12,941:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:12,983:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:32:13,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:13,007:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:13,008:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 20:32:13,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:13,071:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:13,135:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:13,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:13,136:INFO:Preparing preprocessing pipeline...
2023-05-24 20:32:13,143:INFO:Set up label encoding.
2023-05-24 20:32:13,144:INFO:Set up simple imputation.
2023-05-24 20:32:13,144:INFO:Set up imbalanced handling.
2023-05-24 20:32:13,151:INFO:Set up column name cleaning.
2023-05-24 20:32:13,600:INFO:Finished creating preprocessing pipeline.
2023-05-24 20:32:13,608:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 20:32:13,609:INFO:Creating final display dataframe.
2023-05-24 20:32:14,148:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 508)
5        Transformed data shape              (41153, 508)
6   Transformed train set shape              (30052, 508)
7    Transformed test set shape              (11101, 508)
8              Numeric features                       507
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      32ec
2023-05-24 20:32:14,238:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:14,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:14,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:14,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:14,319:INFO:setup() successfully completed in 2.22s...............
2023-05-24 20:32:34,849:INFO:PyCaret ClassificationExperiment
2023-05-24 20:32:34,849:INFO:Logging name: clf-default-name
2023-05-24 20:32:34,849:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 20:32:34,850:INFO:version 3.0.2
2023-05-24 20:32:34,850:INFO:Initializing setup()
2023-05-24 20:32:34,850:INFO:self.USI: 398a
2023-05-24 20:32:34,850:INFO:self._variable_keys: {'X_train', 'memory', 'fold_groups_param', 'y_train', '_available_plots', 'fix_imbalance', 'exp_id', '_ml_usecase', 'idx', 'seed', 'gpu_param', 'logging_param', 'USI', 'data', 'html_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_generator', 'X', 'X_test', 'y', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'pipeline', 'y_test', 'target_param'}
2023-05-24 20:32:34,850:INFO:Checking environment
2023-05-24 20:32:34,850:INFO:python_version: 3.10.11
2023-05-24 20:32:34,850:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 20:32:34,850:INFO:machine: AMD64
2023-05-24 20:32:34,850:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 20:32:34,852:INFO:Memory: svmem(total=16889774080, available=6682718208, percent=60.4, used=10207055872, free=6682718208)
2023-05-24 20:32:34,853:INFO:Physical Core: 4
2023-05-24 20:32:34,853:INFO:Logical Core: 8
2023-05-24 20:32:34,853:INFO:Checking libraries
2023-05-24 20:32:34,853:INFO:System:
2023-05-24 20:32:34,853:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 20:32:34,853:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 20:32:34,853:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 20:32:34,853:INFO:PyCaret required dependencies:
2023-05-24 20:32:34,853:INFO:                 pip: 23.0.1
2023-05-24 20:32:34,853:INFO:          setuptools: 66.0.0
2023-05-24 20:32:34,853:INFO:             pycaret: 3.0.2
2023-05-24 20:32:34,853:INFO:             IPython: 8.13.2
2023-05-24 20:32:34,853:INFO:          ipywidgets: 8.0.6
2023-05-24 20:32:34,853:INFO:                tqdm: 4.65.0
2023-05-24 20:32:34,853:INFO:               numpy: 1.23.5
2023-05-24 20:32:34,853:INFO:              pandas: 1.5.3
2023-05-24 20:32:34,853:INFO:              jinja2: 3.1.2
2023-05-24 20:32:34,853:INFO:               scipy: 1.10.1
2023-05-24 20:32:34,853:INFO:              joblib: 1.2.0
2023-05-24 20:32:34,853:INFO:             sklearn: 1.2.2
2023-05-24 20:32:34,853:INFO:                pyod: 1.0.9
2023-05-24 20:32:34,853:INFO:            imblearn: 0.10.1
2023-05-24 20:32:34,853:INFO:   category_encoders: 2.6.1
2023-05-24 20:32:34,853:INFO:            lightgbm: 3.3.5
2023-05-24 20:32:34,853:INFO:               numba: 0.57.0
2023-05-24 20:32:34,853:INFO:            requests: 2.31.0
2023-05-24 20:32:34,854:INFO:          matplotlib: 3.7.1
2023-05-24 20:32:34,854:INFO:          scikitplot: 0.3.7
2023-05-24 20:32:34,854:INFO:         yellowbrick: 1.5
2023-05-24 20:32:34,854:INFO:              plotly: 5.14.1
2023-05-24 20:32:34,854:INFO:             kaleido: 0.2.1
2023-05-24 20:32:34,854:INFO:         statsmodels: 0.14.0
2023-05-24 20:32:34,854:INFO:              sktime: 0.17.0
2023-05-24 20:32:34,854:INFO:               tbats: 1.1.3
2023-05-24 20:32:34,854:INFO:            pmdarima: 2.0.3
2023-05-24 20:32:34,854:INFO:              psutil: 5.9.5
2023-05-24 20:32:34,854:INFO:PyCaret optional dependencies:
2023-05-24 20:32:34,854:INFO:                shap: Not installed
2023-05-24 20:32:34,854:INFO:           interpret: Not installed
2023-05-24 20:32:34,854:INFO:                umap: Not installed
2023-05-24 20:32:34,854:INFO:    pandas_profiling: Not installed
2023-05-24 20:32:34,854:INFO:  explainerdashboard: Not installed
2023-05-24 20:32:34,854:INFO:             autoviz: Not installed
2023-05-24 20:32:34,854:INFO:           fairlearn: Not installed
2023-05-24 20:32:34,854:INFO:             xgboost: Not installed
2023-05-24 20:32:34,854:INFO:            catboost: Not installed
2023-05-24 20:32:34,854:INFO:              kmodes: Not installed
2023-05-24 20:32:34,854:INFO:             mlxtend: Not installed
2023-05-24 20:32:34,854:INFO:       statsforecast: Not installed
2023-05-24 20:32:34,854:INFO:        tune_sklearn: 0.4.5
2023-05-24 20:32:34,854:INFO:                 ray: 2.4.0
2023-05-24 20:32:34,854:INFO:            hyperopt: 0.2.7
2023-05-24 20:32:34,854:INFO:              optuna: 3.1.1
2023-05-24 20:32:34,854:INFO:               skopt: 0.9.0
2023-05-24 20:32:34,854:INFO:              mlflow: Not installed
2023-05-24 20:32:34,855:INFO:              gradio: Not installed
2023-05-24 20:32:34,855:INFO:             fastapi: Not installed
2023-05-24 20:32:34,855:INFO:             uvicorn: Not installed
2023-05-24 20:32:34,855:INFO:              m2cgen: Not installed
2023-05-24 20:32:34,855:INFO:           evidently: Not installed
2023-05-24 20:32:34,855:INFO:               fugue: Not installed
2023-05-24 20:32:34,855:INFO:           streamlit: Not installed
2023-05-24 20:32:34,855:INFO:             prophet: Not installed
2023-05-24 20:32:34,855:INFO:None
2023-05-24 20:32:34,855:INFO:Set up data.
2023-05-24 20:32:35,069:INFO:Set up train/test split.
2023-05-24 20:32:35,156:INFO:Set up index.
2023-05-24 20:32:35,158:INFO:Set up folding strategy.
2023-05-24 20:32:35,158:INFO:Assigning column types.
2023-05-24 20:32:35,205:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 20:32:35,242:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:32:35,242:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:32:35,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:32:35,318:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:32:35,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,344:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 20:32:35,387:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:32:35,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,454:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:32:35,477:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,477:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,477:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 20:32:35,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:35,605:INFO:Preparing preprocessing pipeline...
2023-05-24 20:32:35,612:INFO:Set up label encoding.
2023-05-24 20:32:35,612:INFO:Set up simple imputation.
2023-05-24 20:32:35,612:INFO:Set up imbalanced handling.
2023-05-24 20:32:35,619:INFO:Set up column name cleaning.
2023-05-24 20:32:36,081:INFO:Finished creating preprocessing pipeline.
2023-05-24 20:32:36,090:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 20:32:36,090:INFO:Creating final display dataframe.
2023-05-24 20:32:36,765:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 508)
5        Transformed data shape              (41153, 508)
6   Transformed train set shape              (30052, 508)
7    Transformed test set shape              (11101, 508)
8              Numeric features                       507
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      398a
2023-05-24 20:32:36,871:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:36,871:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:36,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:36,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:32:36,959:INFO:setup() successfully completed in 2.43s...............
2023-05-24 20:34:01,132:INFO:PyCaret ClassificationExperiment
2023-05-24 20:34:01,132:INFO:Logging name: clf-default-name
2023-05-24 20:34:01,133:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-24 20:34:01,133:INFO:version 3.0.2
2023-05-24 20:34:01,133:INFO:Initializing setup()
2023-05-24 20:34:01,133:INFO:self.USI: eae1
2023-05-24 20:34:01,133:INFO:self._variable_keys: {'X_train', 'memory', 'fold_groups_param', 'y_train', '_available_plots', 'fix_imbalance', 'exp_id', '_ml_usecase', 'idx', 'seed', 'gpu_param', 'logging_param', 'USI', 'data', 'html_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_generator', 'X', 'X_test', 'y', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'pipeline', 'y_test', 'target_param'}
2023-05-24 20:34:01,133:INFO:Checking environment
2023-05-24 20:34:01,133:INFO:python_version: 3.10.11
2023-05-24 20:34:01,133:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-24 20:34:01,133:INFO:machine: AMD64
2023-05-24 20:34:01,133:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-24 20:34:01,136:INFO:Memory: svmem(total=16889774080, available=6430203904, percent=61.9, used=10459570176, free=6430203904)
2023-05-24 20:34:01,136:INFO:Physical Core: 4
2023-05-24 20:34:01,136:INFO:Logical Core: 8
2023-05-24 20:34:01,136:INFO:Checking libraries
2023-05-24 20:34:01,136:INFO:System:
2023-05-24 20:34:01,136:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-24 20:34:01,136:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-24 20:34:01,136:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-24 20:34:01,136:INFO:PyCaret required dependencies:
2023-05-24 20:34:01,137:INFO:                 pip: 23.0.1
2023-05-24 20:34:01,137:INFO:          setuptools: 66.0.0
2023-05-24 20:34:01,137:INFO:             pycaret: 3.0.2
2023-05-24 20:34:01,137:INFO:             IPython: 8.13.2
2023-05-24 20:34:01,137:INFO:          ipywidgets: 8.0.6
2023-05-24 20:34:01,137:INFO:                tqdm: 4.65.0
2023-05-24 20:34:01,137:INFO:               numpy: 1.23.5
2023-05-24 20:34:01,137:INFO:              pandas: 1.5.3
2023-05-24 20:34:01,137:INFO:              jinja2: 3.1.2
2023-05-24 20:34:01,137:INFO:               scipy: 1.10.1
2023-05-24 20:34:01,137:INFO:              joblib: 1.2.0
2023-05-24 20:34:01,137:INFO:             sklearn: 1.2.2
2023-05-24 20:34:01,137:INFO:                pyod: 1.0.9
2023-05-24 20:34:01,137:INFO:            imblearn: 0.10.1
2023-05-24 20:34:01,137:INFO:   category_encoders: 2.6.1
2023-05-24 20:34:01,137:INFO:            lightgbm: 3.3.5
2023-05-24 20:34:01,137:INFO:               numba: 0.57.0
2023-05-24 20:34:01,137:INFO:            requests: 2.31.0
2023-05-24 20:34:01,137:INFO:          matplotlib: 3.7.1
2023-05-24 20:34:01,137:INFO:          scikitplot: 0.3.7
2023-05-24 20:34:01,137:INFO:         yellowbrick: 1.5
2023-05-24 20:34:01,137:INFO:              plotly: 5.14.1
2023-05-24 20:34:01,137:INFO:             kaleido: 0.2.1
2023-05-24 20:34:01,137:INFO:         statsmodels: 0.14.0
2023-05-24 20:34:01,137:INFO:              sktime: 0.17.0
2023-05-24 20:34:01,137:INFO:               tbats: 1.1.3
2023-05-24 20:34:01,137:INFO:            pmdarima: 2.0.3
2023-05-24 20:34:01,137:INFO:              psutil: 5.9.5
2023-05-24 20:34:01,137:INFO:PyCaret optional dependencies:
2023-05-24 20:34:01,137:INFO:                shap: Not installed
2023-05-24 20:34:01,138:INFO:           interpret: Not installed
2023-05-24 20:34:01,138:INFO:                umap: Not installed
2023-05-24 20:34:01,138:INFO:    pandas_profiling: Not installed
2023-05-24 20:34:01,138:INFO:  explainerdashboard: Not installed
2023-05-24 20:34:01,138:INFO:             autoviz: Not installed
2023-05-24 20:34:01,138:INFO:           fairlearn: Not installed
2023-05-24 20:34:01,138:INFO:             xgboost: Not installed
2023-05-24 20:34:01,138:INFO:            catboost: Not installed
2023-05-24 20:34:01,138:INFO:              kmodes: Not installed
2023-05-24 20:34:01,138:INFO:             mlxtend: Not installed
2023-05-24 20:34:01,138:INFO:       statsforecast: Not installed
2023-05-24 20:34:01,138:INFO:        tune_sklearn: 0.4.5
2023-05-24 20:34:01,138:INFO:                 ray: 2.4.0
2023-05-24 20:34:01,138:INFO:            hyperopt: 0.2.7
2023-05-24 20:34:01,138:INFO:              optuna: 3.1.1
2023-05-24 20:34:01,138:INFO:               skopt: 0.9.0
2023-05-24 20:34:01,138:INFO:              mlflow: Not installed
2023-05-24 20:34:01,138:INFO:              gradio: Not installed
2023-05-24 20:34:01,138:INFO:             fastapi: Not installed
2023-05-24 20:34:01,138:INFO:             uvicorn: Not installed
2023-05-24 20:34:01,138:INFO:              m2cgen: Not installed
2023-05-24 20:34:01,138:INFO:           evidently: Not installed
2023-05-24 20:34:01,138:INFO:               fugue: Not installed
2023-05-24 20:34:01,139:INFO:           streamlit: Not installed
2023-05-24 20:34:01,139:INFO:             prophet: Not installed
2023-05-24 20:34:01,139:INFO:None
2023-05-24 20:34:01,139:INFO:Set up data.
2023-05-24 20:34:01,689:INFO:Set up train/test split.
2023-05-24 20:34:01,778:INFO:Set up index.
2023-05-24 20:34:01,780:INFO:Set up folding strategy.
2023-05-24 20:34:01,780:INFO:Assigning column types.
2023-05-24 20:34:01,833:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-24 20:34:01,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:34:01,881:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:34:01,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:01,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:01,952:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-24 20:34:01,953:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:34:01,977:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:01,977:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:01,977:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-24 20:34:02,015:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:34:02,039:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:02,039:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:02,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-24 20:34:02,100:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:02,100:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:02,101:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-24 20:34:02,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:02,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:02,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:02,223:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:02,224:INFO:Preparing preprocessing pipeline...
2023-05-24 20:34:02,230:INFO:Set up label encoding.
2023-05-24 20:34:02,230:INFO:Set up simple imputation.
2023-05-24 20:34:02,230:INFO:Set up imbalanced handling.
2023-05-24 20:34:02,236:INFO:Set up column name cleaning.
2023-05-24 20:34:02,646:INFO:Finished creating preprocessing pipeline.
2023-05-24 20:34:02,658:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-24 20:34:02,658:INFO:Creating final display dataframe.
2023-05-24 20:34:03,255:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 508)
5        Transformed data shape              (41153, 508)
6   Transformed train set shape              (30052, 508)
7    Transformed test set shape              (11101, 508)
8              Numeric features                       507
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      eae1
2023-05-24 20:34:03,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:03,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:03,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:03,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-24 20:34:03,437:INFO:setup() successfully completed in 2.59s...............
2023-05-24 20:34:19,882:INFO:Initializing compare_models()
2023-05-24 20:34:19,882:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-24 20:34:19,882:INFO:Checking exceptions
2023-05-24 20:34:19,964:INFO:Preparing display monitor
2023-05-24 20:34:19,993:INFO:Initializing Logistic Regression
2023-05-24 20:34:19,994:INFO:Total runtime is 1.911322275797526e-05 minutes
2023-05-24 20:34:20,000:INFO:SubProcess create_model() called ==================================
2023-05-24 20:34:20,001:INFO:Initializing create_model()
2023-05-24 20:34:20,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285A14FD330>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:34:20,001:INFO:Checking exceptions
2023-05-24 20:34:20,001:INFO:Importing libraries
2023-05-24 20:34:20,001:INFO:Copying training dataset
2023-05-24 20:34:20,163:INFO:Defining folds
2023-05-24 20:34:20,163:INFO:Declaring metric variables
2023-05-24 20:34:20,168:INFO:Importing untrained model
2023-05-24 20:34:20,170:INFO:Logistic Regression Imported successfully
2023-05-24 20:34:20,177:INFO:Starting cross validation
2023-05-24 20:34:20,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:35:39,205:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 20:35:40,460:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 20:35:40,616:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 20:35:40,783:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 20:35:40,943:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 20:35:42,623:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 20:35:42,868:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 20:35:43,032:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 20:35:57,165:INFO:Initializing compare_models()
2023-05-24 20:35:57,165:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-24 20:35:57,166:INFO:Checking exceptions
2023-05-24 20:35:57,196:INFO:Preparing display monitor
2023-05-24 20:35:57,219:INFO:Initializing Logistic Regression
2023-05-24 20:35:57,220:INFO:Total runtime is 1.662572224934896e-05 minutes
2023-05-24 20:35:57,225:INFO:SubProcess create_model() called ==================================
2023-05-24 20:35:57,225:INFO:Initializing create_model()
2023-05-24 20:35:57,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:35:57,225:INFO:Checking exceptions
2023-05-24 20:35:57,225:INFO:Importing libraries
2023-05-24 20:35:57,225:INFO:Copying training dataset
2023-05-24 20:35:57,307:INFO:Defining folds
2023-05-24 20:35:57,307:INFO:Declaring metric variables
2023-05-24 20:35:57,313:INFO:Importing untrained model
2023-05-24 20:35:57,316:INFO:Logistic Regression Imported successfully
2023-05-24 20:35:57,325:INFO:Starting cross validation
2023-05-24 20:35:57,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:36:28,984:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 20:36:29,332:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-24 20:36:29,901:INFO:Calculating mean and std
2023-05-24 20:36:29,903:INFO:Creating metrics dataframe
2023-05-24 20:36:30,282:INFO:Uploading results into container
2023-05-24 20:36:30,286:INFO:Uploading model into container now
2023-05-24 20:36:30,286:INFO:_master_model_container: 1
2023-05-24 20:36:30,286:INFO:_display_container: 2
2023-05-24 20:36:30,286:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-24 20:36:30,287:INFO:create_model() successfully completed......................................
2023-05-24 20:36:30,394:INFO:SubProcess create_model() end ==================================
2023-05-24 20:36:30,394:INFO:Creating metrics dataframe
2023-05-24 20:36:30,404:INFO:Initializing K Neighbors Classifier
2023-05-24 20:36:30,404:INFO:Total runtime is 0.5530678908030192 minutes
2023-05-24 20:36:30,408:INFO:SubProcess create_model() called ==================================
2023-05-24 20:36:30,409:INFO:Initializing create_model()
2023-05-24 20:36:30,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:36:30,409:INFO:Checking exceptions
2023-05-24 20:36:30,409:INFO:Importing libraries
2023-05-24 20:36:30,409:INFO:Copying training dataset
2023-05-24 20:36:30,478:INFO:Defining folds
2023-05-24 20:36:30,478:INFO:Declaring metric variables
2023-05-24 20:36:30,482:INFO:Importing untrained model
2023-05-24 20:36:30,487:INFO:K Neighbors Classifier Imported successfully
2023-05-24 20:36:30,494:INFO:Starting cross validation
2023-05-24 20:36:30,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:36:49,452:INFO:Calculating mean and std
2023-05-24 20:36:49,453:INFO:Creating metrics dataframe
2023-05-24 20:36:49,789:INFO:Uploading results into container
2023-05-24 20:36:49,790:INFO:Uploading model into container now
2023-05-24 20:36:49,790:INFO:_master_model_container: 2
2023-05-24 20:36:49,790:INFO:_display_container: 2
2023-05-24 20:36:49,791:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-24 20:36:49,791:INFO:create_model() successfully completed......................................
2023-05-24 20:36:49,893:INFO:SubProcess create_model() end ==================================
2023-05-24 20:36:49,893:INFO:Creating metrics dataframe
2023-05-24 20:36:49,903:INFO:Initializing Naive Bayes
2023-05-24 20:36:49,903:INFO:Total runtime is 0.8780521074930827 minutes
2023-05-24 20:36:49,907:INFO:SubProcess create_model() called ==================================
2023-05-24 20:36:49,907:INFO:Initializing create_model()
2023-05-24 20:36:49,907:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:36:49,907:INFO:Checking exceptions
2023-05-24 20:36:49,907:INFO:Importing libraries
2023-05-24 20:36:49,907:INFO:Copying training dataset
2023-05-24 20:36:49,977:INFO:Defining folds
2023-05-24 20:36:49,977:INFO:Declaring metric variables
2023-05-24 20:36:49,980:INFO:Importing untrained model
2023-05-24 20:36:49,985:INFO:Naive Bayes Imported successfully
2023-05-24 20:36:49,993:INFO:Starting cross validation
2023-05-24 20:36:49,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:36:57,169:INFO:Calculating mean and std
2023-05-24 20:36:57,170:INFO:Creating metrics dataframe
2023-05-24 20:36:57,491:INFO:Uploading results into container
2023-05-24 20:36:57,492:INFO:Uploading model into container now
2023-05-24 20:36:57,492:INFO:_master_model_container: 3
2023-05-24 20:36:57,492:INFO:_display_container: 2
2023-05-24 20:36:57,492:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-24 20:36:57,492:INFO:create_model() successfully completed......................................
2023-05-24 20:36:57,597:INFO:SubProcess create_model() end ==================================
2023-05-24 20:36:57,597:INFO:Creating metrics dataframe
2023-05-24 20:36:57,607:INFO:Initializing Decision Tree Classifier
2023-05-24 20:36:57,607:INFO:Total runtime is 1.006464739640554 minutes
2023-05-24 20:36:57,611:INFO:SubProcess create_model() called ==================================
2023-05-24 20:36:57,611:INFO:Initializing create_model()
2023-05-24 20:36:57,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:36:57,611:INFO:Checking exceptions
2023-05-24 20:36:57,611:INFO:Importing libraries
2023-05-24 20:36:57,611:INFO:Copying training dataset
2023-05-24 20:36:57,681:INFO:Defining folds
2023-05-24 20:36:57,681:INFO:Declaring metric variables
2023-05-24 20:36:57,685:INFO:Importing untrained model
2023-05-24 20:36:57,691:INFO:Decision Tree Classifier Imported successfully
2023-05-24 20:36:57,697:INFO:Starting cross validation
2023-05-24 20:36:57,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:37:10,964:INFO:Calculating mean and std
2023-05-24 20:37:10,965:INFO:Creating metrics dataframe
2023-05-24 20:37:11,306:INFO:Uploading results into container
2023-05-24 20:37:11,306:INFO:Uploading model into container now
2023-05-24 20:37:11,307:INFO:_master_model_container: 4
2023-05-24 20:37:11,307:INFO:_display_container: 2
2023-05-24 20:37:11,307:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-24 20:37:11,307:INFO:create_model() successfully completed......................................
2023-05-24 20:37:11,408:INFO:SubProcess create_model() end ==================================
2023-05-24 20:37:11,408:INFO:Creating metrics dataframe
2023-05-24 20:37:11,419:INFO:Initializing SVM - Linear Kernel
2023-05-24 20:37:11,419:INFO:Total runtime is 1.2366588632265727 minutes
2023-05-24 20:37:11,424:INFO:SubProcess create_model() called ==================================
2023-05-24 20:37:11,424:INFO:Initializing create_model()
2023-05-24 20:37:11,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:37:11,425:INFO:Checking exceptions
2023-05-24 20:37:11,425:INFO:Importing libraries
2023-05-24 20:37:11,425:INFO:Copying training dataset
2023-05-24 20:37:11,495:INFO:Defining folds
2023-05-24 20:37:11,495:INFO:Declaring metric variables
2023-05-24 20:37:11,499:INFO:Importing untrained model
2023-05-24 20:37:11,503:INFO:SVM - Linear Kernel Imported successfully
2023-05-24 20:37:11,510:INFO:Starting cross validation
2023-05-24 20:37:11,513:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:37:14,647:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 20:37:14,779:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 20:37:14,822:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 20:37:14,945:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 20:37:14,971:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 20:37:15,099:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 20:37:15,243:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 20:37:15,391:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 20:37:17,355:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 20:37:17,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-24 20:37:18,770:INFO:Calculating mean and std
2023-05-24 20:37:18,771:INFO:Creating metrics dataframe
2023-05-24 20:37:19,112:INFO:Uploading results into container
2023-05-24 20:37:19,113:INFO:Uploading model into container now
2023-05-24 20:37:19,113:INFO:_master_model_container: 5
2023-05-24 20:37:19,113:INFO:_display_container: 2
2023-05-24 20:37:19,114:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-24 20:37:19,114:INFO:create_model() successfully completed......................................
2023-05-24 20:37:19,215:INFO:SubProcess create_model() end ==================================
2023-05-24 20:37:19,215:INFO:Creating metrics dataframe
2023-05-24 20:37:19,227:INFO:Initializing Ridge Classifier
2023-05-24 20:37:19,227:INFO:Total runtime is 1.3667838136355082 minutes
2023-05-24 20:37:19,230:INFO:SubProcess create_model() called ==================================
2023-05-24 20:37:19,231:INFO:Initializing create_model()
2023-05-24 20:37:19,231:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:37:19,231:INFO:Checking exceptions
2023-05-24 20:37:19,231:INFO:Importing libraries
2023-05-24 20:37:19,231:INFO:Copying training dataset
2023-05-24 20:37:19,300:INFO:Defining folds
2023-05-24 20:37:19,300:INFO:Declaring metric variables
2023-05-24 20:37:19,305:INFO:Importing untrained model
2023-05-24 20:37:19,309:INFO:Ridge Classifier Imported successfully
2023-05-24 20:37:19,316:INFO:Starting cross validation
2023-05-24 20:37:19,321:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:37:22,816:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 20:37:22,857:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 20:37:22,880:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 20:37:22,888:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 20:37:22,889:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 20:37:22,897:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 20:37:22,944:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 20:37:22,950:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 20:37:25,815:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 20:37:26,103:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-24 20:37:27,319:INFO:Calculating mean and std
2023-05-24 20:37:27,321:INFO:Creating metrics dataframe
2023-05-24 20:37:27,694:INFO:Uploading results into container
2023-05-24 20:37:27,695:INFO:Uploading model into container now
2023-05-24 20:37:27,696:INFO:_master_model_container: 6
2023-05-24 20:37:27,696:INFO:_display_container: 2
2023-05-24 20:37:27,696:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-24 20:37:27,696:INFO:create_model() successfully completed......................................
2023-05-24 20:37:27,796:INFO:SubProcess create_model() end ==================================
2023-05-24 20:37:27,797:INFO:Creating metrics dataframe
2023-05-24 20:37:27,807:INFO:Initializing Random Forest Classifier
2023-05-24 20:37:27,807:INFO:Total runtime is 1.509791338443756 minutes
2023-05-24 20:37:27,811:INFO:SubProcess create_model() called ==================================
2023-05-24 20:37:27,811:INFO:Initializing create_model()
2023-05-24 20:37:27,811:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:37:27,812:INFO:Checking exceptions
2023-05-24 20:37:27,812:INFO:Importing libraries
2023-05-24 20:37:27,812:INFO:Copying training dataset
2023-05-24 20:37:27,881:INFO:Defining folds
2023-05-24 20:37:27,881:INFO:Declaring metric variables
2023-05-24 20:37:27,883:INFO:Importing untrained model
2023-05-24 20:37:27,891:INFO:Random Forest Classifier Imported successfully
2023-05-24 20:37:27,897:INFO:Starting cross validation
2023-05-24 20:37:27,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:37:53,382:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.24s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:37:53,489:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:37:53,539:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:37:53,550:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:37:53,639:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:37:54,581:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:37:54,668:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:37:55,234:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:37:55,532:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:38:04,954:INFO:Calculating mean and std
2023-05-24 20:38:04,956:INFO:Creating metrics dataframe
2023-05-24 20:38:05,309:INFO:Uploading results into container
2023-05-24 20:38:05,310:INFO:Uploading model into container now
2023-05-24 20:38:05,310:INFO:_master_model_container: 7
2023-05-24 20:38:05,310:INFO:_display_container: 2
2023-05-24 20:38:05,311:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-24 20:38:05,311:INFO:create_model() successfully completed......................................
2023-05-24 20:38:05,414:INFO:SubProcess create_model() end ==================================
2023-05-24 20:38:05,415:INFO:Creating metrics dataframe
2023-05-24 20:38:05,426:INFO:Initializing Quadratic Discriminant Analysis
2023-05-24 20:38:05,426:INFO:Total runtime is 2.1367761810620625 minutes
2023-05-24 20:38:05,429:INFO:SubProcess create_model() called ==================================
2023-05-24 20:38:05,429:INFO:Initializing create_model()
2023-05-24 20:38:05,429:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:38:05,430:INFO:Checking exceptions
2023-05-24 20:38:05,430:INFO:Importing libraries
2023-05-24 20:38:05,430:INFO:Copying training dataset
2023-05-24 20:38:05,501:INFO:Defining folds
2023-05-24 20:38:05,501:INFO:Declaring metric variables
2023-05-24 20:38:05,507:INFO:Importing untrained model
2023-05-24 20:38:05,511:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-24 20:38:05,519:INFO:Starting cross validation
2023-05-24 20:38:05,522:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:38:11,272:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 20:38:11,309:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 20:38:11,335:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 20:38:11,345:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 20:38:11,373:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 20:38:11,403:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 20:38:11,410:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 20:38:11,435:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 20:38:20,683:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 20:38:20,728:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-24 20:38:23,105:INFO:Calculating mean and std
2023-05-24 20:38:23,106:INFO:Creating metrics dataframe
2023-05-24 20:38:23,475:INFO:Uploading results into container
2023-05-24 20:38:23,476:INFO:Uploading model into container now
2023-05-24 20:38:23,476:INFO:_master_model_container: 8
2023-05-24 20:38:23,476:INFO:_display_container: 2
2023-05-24 20:38:23,476:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-24 20:38:23,476:INFO:create_model() successfully completed......................................
2023-05-24 20:38:23,579:INFO:SubProcess create_model() end ==================================
2023-05-24 20:38:23,579:INFO:Creating metrics dataframe
2023-05-24 20:38:23,590:INFO:Initializing Ada Boost Classifier
2023-05-24 20:38:23,590:INFO:Total runtime is 2.4395023107528684 minutes
2023-05-24 20:38:23,594:INFO:SubProcess create_model() called ==================================
2023-05-24 20:38:23,594:INFO:Initializing create_model()
2023-05-24 20:38:23,594:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:38:23,595:INFO:Checking exceptions
2023-05-24 20:38:23,595:INFO:Importing libraries
2023-05-24 20:38:23,595:INFO:Copying training dataset
2023-05-24 20:38:23,664:INFO:Defining folds
2023-05-24 20:38:23,664:INFO:Declaring metric variables
2023-05-24 20:38:23,667:INFO:Importing untrained model
2023-05-24 20:38:23,673:INFO:Ada Boost Classifier Imported successfully
2023-05-24 20:38:23,680:INFO:Starting cross validation
2023-05-24 20:38:23,683:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:38:54,122:INFO:Calculating mean and std
2023-05-24 20:38:54,123:INFO:Creating metrics dataframe
2023-05-24 20:38:54,528:INFO:Uploading results into container
2023-05-24 20:38:54,529:INFO:Uploading model into container now
2023-05-24 20:38:54,529:INFO:_master_model_container: 9
2023-05-24 20:38:54,529:INFO:_display_container: 2
2023-05-24 20:38:54,529:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-24 20:38:54,530:INFO:create_model() successfully completed......................................
2023-05-24 20:38:54,631:INFO:SubProcess create_model() end ==================================
2023-05-24 20:38:54,631:INFO:Creating metrics dataframe
2023-05-24 20:38:54,643:INFO:Initializing Gradient Boosting Classifier
2023-05-24 20:38:54,643:INFO:Total runtime is 2.957050196329752 minutes
2023-05-24 20:38:54,646:INFO:SubProcess create_model() called ==================================
2023-05-24 20:38:54,647:INFO:Initializing create_model()
2023-05-24 20:38:54,647:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:38:54,647:INFO:Checking exceptions
2023-05-24 20:38:54,647:INFO:Importing libraries
2023-05-24 20:38:54,647:INFO:Copying training dataset
2023-05-24 20:38:54,717:INFO:Defining folds
2023-05-24 20:38:54,717:INFO:Declaring metric variables
2023-05-24 20:38:54,722:INFO:Importing untrained model
2023-05-24 20:38:54,727:INFO:Gradient Boosting Classifier Imported successfully
2023-05-24 20:38:54,735:INFO:Starting cross validation
2023-05-24 20:38:54,740:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:40:13,657:INFO:Calculating mean and std
2023-05-24 20:40:13,658:INFO:Creating metrics dataframe
2023-05-24 20:40:14,034:INFO:Uploading results into container
2023-05-24 20:40:14,035:INFO:Uploading model into container now
2023-05-24 20:40:14,035:INFO:_master_model_container: 10
2023-05-24 20:40:14,035:INFO:_display_container: 2
2023-05-24 20:40:14,036:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-24 20:40:14,036:INFO:create_model() successfully completed......................................
2023-05-24 20:40:14,141:INFO:SubProcess create_model() end ==================================
2023-05-24 20:40:14,141:INFO:Creating metrics dataframe
2023-05-24 20:40:14,153:INFO:Initializing Linear Discriminant Analysis
2023-05-24 20:40:14,153:INFO:Total runtime is 4.282218384742737 minutes
2023-05-24 20:40:14,158:INFO:SubProcess create_model() called ==================================
2023-05-24 20:40:14,158:INFO:Initializing create_model()
2023-05-24 20:40:14,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:40:14,158:INFO:Checking exceptions
2023-05-24 20:40:14,158:INFO:Importing libraries
2023-05-24 20:40:14,158:INFO:Copying training dataset
2023-05-24 20:40:14,230:INFO:Defining folds
2023-05-24 20:40:14,230:INFO:Declaring metric variables
2023-05-24 20:40:14,234:INFO:Importing untrained model
2023-05-24 20:40:14,237:INFO:Linear Discriminant Analysis Imported successfully
2023-05-24 20:40:14,247:INFO:Starting cross validation
2023-05-24 20:40:14,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:40:36,442:INFO:Calculating mean and std
2023-05-24 20:40:36,443:INFO:Creating metrics dataframe
2023-05-24 20:40:36,833:INFO:Uploading results into container
2023-05-24 20:40:36,833:INFO:Uploading model into container now
2023-05-24 20:40:36,835:INFO:_master_model_container: 11
2023-05-24 20:40:36,835:INFO:_display_container: 2
2023-05-24 20:40:36,835:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-24 20:40:36,835:INFO:create_model() successfully completed......................................
2023-05-24 20:40:36,936:INFO:SubProcess create_model() end ==================================
2023-05-24 20:40:36,936:INFO:Creating metrics dataframe
2023-05-24 20:40:36,948:INFO:Initializing Extra Trees Classifier
2023-05-24 20:40:36,948:INFO:Total runtime is 4.662140150864919 minutes
2023-05-24 20:40:36,950:INFO:SubProcess create_model() called ==================================
2023-05-24 20:40:36,951:INFO:Initializing create_model()
2023-05-24 20:40:36,951:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:40:36,951:INFO:Checking exceptions
2023-05-24 20:40:36,951:INFO:Importing libraries
2023-05-24 20:40:36,951:INFO:Copying training dataset
2023-05-24 20:40:37,024:INFO:Defining folds
2023-05-24 20:40:37,024:INFO:Declaring metric variables
2023-05-24 20:40:37,027:INFO:Importing untrained model
2023-05-24 20:40:37,032:INFO:Extra Trees Classifier Imported successfully
2023-05-24 20:40:37,040:INFO:Starting cross validation
2023-05-24 20:40:37,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:41:23,620:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:41:24,586:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:41:24,679:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:41:24,752:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:41:24,755:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 20:41:25,226:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:41:25,611:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:41:25,649:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:41:25,692:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:41:25,917:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:41:25,951:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:41:25,982:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 20:41:41,957:INFO:Calculating mean and std
2023-05-24 20:41:41,959:INFO:Creating metrics dataframe
2023-05-24 20:41:42,279:INFO:Uploading results into container
2023-05-24 20:41:42,280:INFO:Uploading model into container now
2023-05-24 20:41:42,280:INFO:_master_model_container: 12
2023-05-24 20:41:42,281:INFO:_display_container: 2
2023-05-24 20:41:42,281:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-24 20:41:42,281:INFO:create_model() successfully completed......................................
2023-05-24 20:41:42,391:INFO:SubProcess create_model() end ==================================
2023-05-24 20:41:42,391:INFO:Creating metrics dataframe
2023-05-24 20:41:42,403:INFO:Initializing Light Gradient Boosting Machine
2023-05-24 20:41:42,403:INFO:Total runtime is 5.753060440222422 minutes
2023-05-24 20:41:42,408:INFO:SubProcess create_model() called ==================================
2023-05-24 20:41:42,409:INFO:Initializing create_model()
2023-05-24 20:41:42,409:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:41:42,409:INFO:Checking exceptions
2023-05-24 20:41:42,409:INFO:Importing libraries
2023-05-24 20:41:42,409:INFO:Copying training dataset
2023-05-24 20:41:42,483:INFO:Defining folds
2023-05-24 20:41:42,483:INFO:Declaring metric variables
2023-05-24 20:41:42,485:INFO:Importing untrained model
2023-05-24 20:41:42,490:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 20:41:42,497:INFO:Starting cross validation
2023-05-24 20:41:42,500:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:41:55,422:INFO:Calculating mean and std
2023-05-24 20:41:55,424:INFO:Creating metrics dataframe
2023-05-24 20:41:55,802:INFO:Uploading results into container
2023-05-24 20:41:55,803:INFO:Uploading model into container now
2023-05-24 20:41:55,803:INFO:_master_model_container: 13
2023-05-24 20:41:55,803:INFO:_display_container: 2
2023-05-24 20:41:55,804:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 20:41:55,804:INFO:create_model() successfully completed......................................
2023-05-24 20:41:55,906:INFO:SubProcess create_model() end ==================================
2023-05-24 20:41:55,907:INFO:Creating metrics dataframe
2023-05-24 20:41:55,918:INFO:Initializing Dummy Classifier
2023-05-24 20:41:55,919:INFO:Total runtime is 5.978319597244262 minutes
2023-05-24 20:41:55,922:INFO:SubProcess create_model() called ==================================
2023-05-24 20:41:55,922:INFO:Initializing create_model()
2023-05-24 20:41:55,922:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1ED2590>, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:41:55,922:INFO:Checking exceptions
2023-05-24 20:41:55,922:INFO:Importing libraries
2023-05-24 20:41:55,922:INFO:Copying training dataset
2023-05-24 20:41:55,992:INFO:Defining folds
2023-05-24 20:41:55,992:INFO:Declaring metric variables
2023-05-24 20:41:55,996:INFO:Importing untrained model
2023-05-24 20:41:56,002:INFO:Dummy Classifier Imported successfully
2023-05-24 20:41:56,009:INFO:Starting cross validation
2023-05-24 20:41:56,013:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 20:41:57,871:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 20:41:57,986:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 20:41:57,994:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 20:41:57,997:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 20:41:58,047:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 20:41:58,066:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 20:41:58,067:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 20:41:58,088:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 20:42:00,099:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 20:42:00,218:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-24 20:42:01,927:INFO:Calculating mean and std
2023-05-24 20:42:01,928:INFO:Creating metrics dataframe
2023-05-24 20:42:02,301:INFO:Uploading results into container
2023-05-24 20:42:02,302:INFO:Uploading model into container now
2023-05-24 20:42:02,302:INFO:_master_model_container: 14
2023-05-24 20:42:02,302:INFO:_display_container: 2
2023-05-24 20:42:02,303:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-24 20:42:02,303:INFO:create_model() successfully completed......................................
2023-05-24 20:42:02,402:INFO:SubProcess create_model() end ==================================
2023-05-24 20:42:02,402:INFO:Creating metrics dataframe
2023-05-24 20:42:02,425:INFO:Initializing create_model()
2023-05-24 20:42:02,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-24 20:42:02,425:INFO:Checking exceptions
2023-05-24 20:42:02,428:INFO:Importing libraries
2023-05-24 20:42:02,428:INFO:Copying training dataset
2023-05-24 20:42:02,497:INFO:Defining folds
2023-05-24 20:42:02,497:INFO:Declaring metric variables
2023-05-24 20:42:02,497:INFO:Importing untrained model
2023-05-24 20:42:02,497:INFO:Declaring custom model
2023-05-24 20:42:02,497:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 20:42:02,501:INFO:Cross validation set to False
2023-05-24 20:42:02,501:INFO:Fitting Model
2023-05-24 20:42:04,909:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 20:42:04,910:INFO:create_model() successfully completed......................................
2023-05-24 20:42:05,041:INFO:_master_model_container: 14
2023-05-24 20:42:05,041:INFO:_display_container: 2
2023-05-24 20:42:05,042:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 20:42:05,042:INFO:compare_models() successfully completed......................................
2023-05-24 20:44:51,400:INFO:Initializing predict_model()
2023-05-24 20:44:51,400:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AFA3E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000285CCA73BE0>)
2023-05-24 20:44:51,400:INFO:Checking exceptions
2023-05-24 20:44:51,400:INFO:Preloading libraries
2023-05-24 20:44:58,633:INFO:Initializing predict_model()
2023-05-24 20:44:58,633:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000285CCA73880>)
2023-05-24 20:44:58,633:INFO:Checking exceptions
2023-05-24 20:44:58,633:INFO:Preloading libraries
2023-05-24 20:44:58,649:INFO:Set up data.
2023-05-24 20:44:58,772:INFO:Set up index.
2023-05-24 20:52:44,314:INFO:Initializing tune_model()
2023-05-24 20:52:44,315:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>)
2023-05-24 20:52:44,315:INFO:Checking exceptions
2023-05-24 20:52:44,315:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-24 20:52:44,808:INFO:Copying training dataset
2023-05-24 20:52:44,876:INFO:Checking base model
2023-05-24 20:52:44,876:INFO:Base model : Light Gradient Boosting Machine
2023-05-24 20:52:44,881:INFO:Declaring metric variables
2023-05-24 20:52:44,885:INFO:Defining Hyperparameters
2023-05-24 20:52:45,044:INFO:Tuning with n_jobs=-1
2023-05-24 20:52:45,046:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-24 20:52:45,046:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-24 20:52:45,046:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-24 20:52:45,050:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-24 21:03:24,597:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 21:03:24,742:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 21:03:25,211:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-24 21:07:34,681:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 21:07:36,948:INFO:best_params: {'actual_estimator__num_leaves': 82, 'actual_estimator__learning_rate': 0.0364611479281597, 'actual_estimator__n_estimators': 181, 'actual_estimator__min_split_gain': 0.28908713340023673, 'actual_estimator__reg_alpha': 5.746360899277371e-06, 'actual_estimator__reg_lambda': 0.0006500418806757982, 'actual_estimator__feature_fraction': 0.8954632787661868, 'actual_estimator__bagging_fraction': 0.6717010340302931, 'actual_estimator__bagging_freq': 1, 'actual_estimator__min_child_samples': 36}
2023-05-24 21:07:36,948:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-05-24 21:07:36,948:WARNING:Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2666, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-05-24 21:07:36,949:INFO:Hyperparameter search completed
2023-05-24 21:07:36,949:INFO:SubProcess create_model() called ==================================
2023-05-24 21:07:36,950:INFO:Initializing create_model()
2023-05-24 21:07:36,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285B1E06050>, model_only=True, return_train_score=False, kwargs={'num_leaves': 82, 'learning_rate': 0.0364611479281597, 'n_estimators': 181, 'min_split_gain': 0.28908713340023673, 'reg_alpha': 5.746360899277371e-06, 'reg_lambda': 0.0006500418806757982, 'feature_fraction': 0.8954632787661868, 'bagging_fraction': 0.6717010340302931, 'bagging_freq': 1, 'min_child_samples': 36})
2023-05-24 21:07:36,950:INFO:Checking exceptions
2023-05-24 21:07:36,950:INFO:Importing libraries
2023-05-24 21:07:36,950:INFO:Copying training dataset
2023-05-24 21:07:37,044:INFO:Defining folds
2023-05-24 21:07:37,044:INFO:Declaring metric variables
2023-05-24 21:07:37,048:INFO:Importing untrained model
2023-05-24 21:07:37,049:INFO:Declaring custom model
2023-05-24 21:07:37,056:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 21:07:37,065:INFO:Starting cross validation
2023-05-24 21:07:37,069:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 21:07:45,961:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 21:07:46,065:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 21:07:46,095:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 21:07:46,112:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 21:07:46,133:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 21:07:46,146:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-24 21:07:53,071:INFO:Calculating mean and std
2023-05-24 21:07:53,073:INFO:Creating metrics dataframe
2023-05-24 21:07:53,079:INFO:Finalizing model
2023-05-24 21:07:54,118:INFO:[LightGBM] [Warning] feature_fraction is set=0.8954632787661868, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8954632787661868
2023-05-24 21:07:54,118:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6717010340302931, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6717010340302931
2023-05-24 21:07:54,118:INFO:[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1
2023-05-24 21:07:57,633:INFO:Uploading results into container
2023-05-24 21:07:57,635:INFO:Uploading model into container now
2023-05-24 21:07:57,635:INFO:_master_model_container: 15
2023-05-24 21:07:57,636:INFO:_display_container: 3
2023-05-24 21:07:57,637:INFO:LGBMClassifier(bagging_fraction=0.6717010340302931, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.8954632787661868, importance_type='split',
               learning_rate=0.0364611479281597, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001,
               min_split_gain=0.28908713340023673, n_estimators=181, n_jobs=-1,
               num_leaves=82, objective=None, random_state=123,
               reg_alpha=5.746360899277371e-06,
               reg_lambda=0.0006500418806757982, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-05-24 21:07:57,638:INFO:create_model() successfully completed......................................
2023-05-24 21:07:57,787:INFO:SubProcess create_model() end ==================================
2023-05-24 21:07:57,787:INFO:choose_better activated
2023-05-24 21:07:57,791:INFO:SubProcess create_model() called ==================================
2023-05-24 21:07:57,792:INFO:Initializing create_model()
2023-05-24 21:07:57,792:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285B3AF9EA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-24 21:07:57,792:INFO:Checking exceptions
2023-05-24 21:07:57,794:INFO:Importing libraries
2023-05-24 21:07:57,794:INFO:Copying training dataset
2023-05-24 21:07:57,881:INFO:Defining folds
2023-05-24 21:07:57,881:INFO:Declaring metric variables
2023-05-24 21:07:57,881:INFO:Importing untrained model
2023-05-24 21:07:57,881:INFO:Declaring custom model
2023-05-24 21:07:57,882:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-24 21:07:57,882:INFO:Starting cross validation
2023-05-24 21:07:57,884:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-24 21:08:05,192:INFO:Calculating mean and std
2023-05-24 21:08:05,193:INFO:Creating metrics dataframe
2023-05-24 21:08:05,195:INFO:Finalizing model
2023-05-24 21:08:06,341:INFO:Uploading results into container
2023-05-24 21:08:06,341:INFO:Uploading model into container now
2023-05-24 21:08:06,342:INFO:_master_model_container: 16
2023-05-24 21:08:06,342:INFO:_display_container: 4
2023-05-24 21:08:06,342:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-24 21:08:06,342:INFO:create_model() successfully completed......................................
2023-05-24 21:08:06,463:INFO:SubProcess create_model() end ==================================
2023-05-24 21:08:06,464:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7395
2023-05-24 21:08:06,465:INFO:LGBMClassifier(bagging_fraction=0.6717010340302931, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.8954632787661868, importance_type='split',
               learning_rate=0.0364611479281597, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001,
               min_split_gain=0.28908713340023673, n_estimators=181, n_jobs=-1,
               num_leaves=82, objective=None, random_state=123,
               reg_alpha=5.746360899277371e-06,
               reg_lambda=0.0006500418806757982, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7446
2023-05-24 21:08:06,465:INFO:LGBMClassifier(bagging_fraction=0.6717010340302931, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.8954632787661868, importance_type='split',
               learning_rate=0.0364611479281597, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001,
               min_split_gain=0.28908713340023673, n_estimators=181, n_jobs=-1,
               num_leaves=82, objective=None, random_state=123,
               reg_alpha=5.746360899277371e-06,
               reg_lambda=0.0006500418806757982, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-05-24 21:08:06,465:INFO:choose_better completed
2023-05-24 21:08:06,477:INFO:_master_model_container: 16
2023-05-24 21:08:06,477:INFO:_display_container: 3
2023-05-24 21:08:06,478:INFO:LGBMClassifier(bagging_fraction=0.6717010340302931, bagging_freq=1,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.8954632787661868, importance_type='split',
               learning_rate=0.0364611479281597, max_depth=-1,
               min_child_samples=36, min_child_weight=0.001,
               min_split_gain=0.28908713340023673, n_estimators=181, n_jobs=-1,
               num_leaves=82, objective=None, random_state=123,
               reg_alpha=5.746360899277371e-06,
               reg_lambda=0.0006500418806757982, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-05-24 21:08:06,478:INFO:tune_model() successfully completed......................................
2023-05-25 10:55:38,838:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 10:55:38,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 10:55:38,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 10:55:38,839:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 10:55:40,119:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-25 11:06:58,314:INFO:PyCaret ClassificationExperiment
2023-05-25 11:06:58,314:INFO:Logging name: clf-default-name
2023-05-25 11:06:58,314:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-25 11:06:58,314:INFO:version 3.0.2
2023-05-25 11:06:58,314:INFO:Initializing setup()
2023-05-25 11:06:58,314:INFO:self.USI: 8593
2023-05-25 11:06:58,314:INFO:self._variable_keys: {'X_train', 'memory', 'fold_groups_param', 'y_train', '_available_plots', 'fix_imbalance', 'exp_id', '_ml_usecase', 'idx', 'seed', 'gpu_param', 'logging_param', 'USI', 'data', 'html_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_generator', 'X', 'X_test', 'y', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'pipeline', 'y_test', 'target_param'}
2023-05-25 11:06:58,314:INFO:Checking environment
2023-05-25 11:06:58,314:INFO:python_version: 3.10.11
2023-05-25 11:06:58,314:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-25 11:06:58,314:INFO:machine: AMD64
2023-05-25 11:06:58,314:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-25 11:06:58,322:INFO:Memory: svmem(total=16889774080, available=7534174208, percent=55.4, used=9355599872, free=7534174208)
2023-05-25 11:06:58,322:INFO:Physical Core: 4
2023-05-25 11:06:58,322:INFO:Logical Core: 8
2023-05-25 11:06:58,322:INFO:Checking libraries
2023-05-25 11:06:58,322:INFO:System:
2023-05-25 11:06:58,322:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-25 11:06:58,322:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-25 11:06:58,322:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-25 11:06:58,322:INFO:PyCaret required dependencies:
2023-05-25 11:06:58,322:INFO:                 pip: 23.0.1
2023-05-25 11:06:58,322:INFO:          setuptools: 66.0.0
2023-05-25 11:06:58,322:INFO:             pycaret: 3.0.2
2023-05-25 11:06:58,322:INFO:             IPython: 8.13.2
2023-05-25 11:06:58,322:INFO:          ipywidgets: 8.0.6
2023-05-25 11:06:58,322:INFO:                tqdm: 4.65.0
2023-05-25 11:06:58,322:INFO:               numpy: 1.23.5
2023-05-25 11:06:58,322:INFO:              pandas: 1.5.3
2023-05-25 11:06:58,322:INFO:              jinja2: 3.1.2
2023-05-25 11:06:58,322:INFO:               scipy: 1.10.1
2023-05-25 11:06:58,322:INFO:              joblib: 1.2.0
2023-05-25 11:06:58,322:INFO:             sklearn: 1.2.2
2023-05-25 11:06:58,322:INFO:                pyod: 1.0.9
2023-05-25 11:06:58,322:INFO:            imblearn: 0.10.1
2023-05-25 11:06:58,322:INFO:   category_encoders: 2.6.1
2023-05-25 11:06:58,322:INFO:            lightgbm: 3.3.5
2023-05-25 11:06:58,322:INFO:               numba: 0.57.0
2023-05-25 11:06:58,322:INFO:            requests: 2.31.0
2023-05-25 11:06:58,322:INFO:          matplotlib: 3.7.1
2023-05-25 11:06:58,322:INFO:          scikitplot: 0.3.7
2023-05-25 11:06:58,322:INFO:         yellowbrick: 1.5
2023-05-25 11:06:58,322:INFO:              plotly: 5.14.1
2023-05-25 11:06:58,322:INFO:             kaleido: 0.2.1
2023-05-25 11:06:58,322:INFO:         statsmodels: 0.14.0
2023-05-25 11:06:58,322:INFO:              sktime: 0.17.0
2023-05-25 11:06:58,322:INFO:               tbats: 1.1.3
2023-05-25 11:06:58,322:INFO:            pmdarima: 2.0.3
2023-05-25 11:06:58,322:INFO:              psutil: 5.9.5
2023-05-25 11:06:58,322:INFO:PyCaret optional dependencies:
2023-05-25 11:06:58,322:INFO:                shap: Not installed
2023-05-25 11:06:58,322:INFO:           interpret: Not installed
2023-05-25 11:06:58,322:INFO:                umap: Not installed
2023-05-25 11:06:58,322:INFO:    pandas_profiling: Not installed
2023-05-25 11:06:58,322:INFO:  explainerdashboard: Not installed
2023-05-25 11:06:58,322:INFO:             autoviz: Not installed
2023-05-25 11:06:58,322:INFO:           fairlearn: Not installed
2023-05-25 11:06:58,322:INFO:             xgboost: Not installed
2023-05-25 11:06:58,322:INFO:            catboost: Not installed
2023-05-25 11:06:58,322:INFO:              kmodes: Not installed
2023-05-25 11:06:58,322:INFO:             mlxtend: Not installed
2023-05-25 11:06:58,322:INFO:       statsforecast: Not installed
2023-05-25 11:06:58,322:INFO:        tune_sklearn: 0.4.5
2023-05-25 11:06:58,322:INFO:                 ray: 2.4.0
2023-05-25 11:06:58,322:INFO:            hyperopt: 0.2.7
2023-05-25 11:06:58,322:INFO:              optuna: 3.1.1
2023-05-25 11:06:58,322:INFO:               skopt: 0.9.0
2023-05-25 11:06:58,322:INFO:              mlflow: Not installed
2023-05-25 11:06:58,322:INFO:              gradio: Not installed
2023-05-25 11:06:58,322:INFO:             fastapi: Not installed
2023-05-25 11:06:58,322:INFO:             uvicorn: Not installed
2023-05-25 11:06:58,322:INFO:              m2cgen: Not installed
2023-05-25 11:06:58,322:INFO:           evidently: Not installed
2023-05-25 11:06:58,322:INFO:               fugue: Not installed
2023-05-25 11:06:58,322:INFO:           streamlit: Not installed
2023-05-25 11:06:58,322:INFO:             prophet: Not installed
2023-05-25 11:06:58,322:INFO:None
2023-05-25 11:06:58,322:INFO:Set up data.
2023-05-25 11:06:58,657:INFO:Set up train/test split.
2023-05-25 11:06:58,788:INFO:Set up index.
2023-05-25 11:06:58,796:INFO:Set up folding strategy.
2023-05-25 11:06:58,796:INFO:Assigning column types.
2023-05-25 11:06:58,870:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-25 11:06:58,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:58,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:59,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:59,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:59,040:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-25 11:06:59,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:59,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:59,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:59,241:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:59,241:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-25 11:06:59,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:59,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:59,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:59,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:06:59,963:INFO:Preparing preprocessing pipeline...
2023-05-25 11:06:59,970:INFO:Set up label encoding.
2023-05-25 11:06:59,970:INFO:Set up simple imputation.
2023-05-25 11:06:59,970:INFO:Set up imbalanced handling.
2023-05-25 11:06:59,987:INFO:Set up column name cleaning.
2023-05-25 11:07:00,668:INFO:Finished creating preprocessing pipeline.
2023-05-25 11:07:00,692:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-25 11:07:00,692:INFO:Creating final display dataframe.
2023-05-25 11:07:02,604:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 508)
5        Transformed data shape              (41153, 508)
6   Transformed train set shape              (30052, 508)
7    Transformed test set shape              (11101, 508)
8              Numeric features                       507
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      8593
2023-05-25 11:07:02,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:07:02,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:07:02,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:07:02,830:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:07:02,830:INFO:setup() successfully completed in 5.31s...............
2023-05-25 11:09:17,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 11:09:17,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 11:09:17,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 11:09:17,579:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 11:09:18,513:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-25 11:10:54,013:INFO:PyCaret ClassificationExperiment
2023-05-25 11:10:54,013:INFO:Logging name: clf-default-name
2023-05-25 11:10:54,013:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-25 11:10:54,013:INFO:version 3.0.2
2023-05-25 11:10:54,013:INFO:Initializing setup()
2023-05-25 11:10:54,013:INFO:self.USI: 6873
2023-05-25 11:10:54,013:INFO:self._variable_keys: {'log_plots_param', 'y_train', 'X', 'exp_name_log', 'X_test', 'fold_groups_param', 'fold_shuffle_param', '_available_plots', 'memory', '_ml_usecase', 'logging_param', 'gpu_param', 'html_param', 'fold_generator', 'data', 'exp_id', 'is_multiclass', 'pipeline', 'target_param', 'fix_imbalance', 'gpu_n_jobs_param', 'idx', 'USI', 'X_train', 'y', 'y_test', 'seed', 'n_jobs_param'}
2023-05-25 11:10:54,013:INFO:Checking environment
2023-05-25 11:10:54,013:INFO:python_version: 3.10.11
2023-05-25 11:10:54,013:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-25 11:10:54,013:INFO:machine: AMD64
2023-05-25 11:10:54,013:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-25 11:10:54,013:INFO:Memory: svmem(total=16889774080, available=7422767104, percent=56.1, used=9467006976, free=7422767104)
2023-05-25 11:10:54,013:INFO:Physical Core: 4
2023-05-25 11:10:54,013:INFO:Logical Core: 8
2023-05-25 11:10:54,021:INFO:Checking libraries
2023-05-25 11:10:54,021:INFO:System:
2023-05-25 11:10:54,021:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-25 11:10:54,021:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-25 11:10:54,021:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-25 11:10:54,021:INFO:PyCaret required dependencies:
2023-05-25 11:10:54,021:INFO:                 pip: 23.0.1
2023-05-25 11:10:54,021:INFO:          setuptools: 66.0.0
2023-05-25 11:10:54,021:INFO:             pycaret: 3.0.2
2023-05-25 11:10:54,021:INFO:             IPython: 8.13.2
2023-05-25 11:10:54,021:INFO:          ipywidgets: 8.0.6
2023-05-25 11:10:54,021:INFO:                tqdm: 4.65.0
2023-05-25 11:10:54,021:INFO:               numpy: 1.23.5
2023-05-25 11:10:54,021:INFO:              pandas: 1.5.3
2023-05-25 11:10:54,021:INFO:              jinja2: 3.1.2
2023-05-25 11:10:54,021:INFO:               scipy: 1.10.1
2023-05-25 11:10:54,021:INFO:              joblib: 1.2.0
2023-05-25 11:10:54,021:INFO:             sklearn: 1.2.2
2023-05-25 11:10:54,021:INFO:                pyod: 1.0.9
2023-05-25 11:10:54,021:INFO:            imblearn: 0.10.1
2023-05-25 11:10:54,021:INFO:   category_encoders: 2.6.1
2023-05-25 11:10:54,021:INFO:            lightgbm: 3.3.5
2023-05-25 11:10:54,021:INFO:               numba: 0.57.0
2023-05-25 11:10:54,021:INFO:            requests: 2.31.0
2023-05-25 11:10:54,021:INFO:          matplotlib: 3.7.1
2023-05-25 11:10:54,021:INFO:          scikitplot: 0.3.7
2023-05-25 11:10:54,021:INFO:         yellowbrick: 1.5
2023-05-25 11:10:54,021:INFO:              plotly: 5.14.1
2023-05-25 11:10:54,021:INFO:             kaleido: 0.2.1
2023-05-25 11:10:54,021:INFO:         statsmodels: 0.14.0
2023-05-25 11:10:54,021:INFO:              sktime: 0.17.0
2023-05-25 11:10:54,021:INFO:               tbats: 1.1.3
2023-05-25 11:10:54,021:INFO:            pmdarima: 2.0.3
2023-05-25 11:10:54,021:INFO:              psutil: 5.9.5
2023-05-25 11:10:54,021:INFO:PyCaret optional dependencies:
2023-05-25 11:10:54,037:INFO:                shap: Not installed
2023-05-25 11:10:54,037:INFO:           interpret: Not installed
2023-05-25 11:10:54,037:INFO:                umap: Not installed
2023-05-25 11:10:54,037:INFO:    pandas_profiling: Not installed
2023-05-25 11:10:54,037:INFO:  explainerdashboard: Not installed
2023-05-25 11:10:54,037:INFO:             autoviz: Not installed
2023-05-25 11:10:54,037:INFO:           fairlearn: Not installed
2023-05-25 11:10:54,037:INFO:             xgboost: Not installed
2023-05-25 11:10:54,037:INFO:            catboost: Not installed
2023-05-25 11:10:54,037:INFO:              kmodes: Not installed
2023-05-25 11:10:54,037:INFO:             mlxtend: Not installed
2023-05-25 11:10:54,037:INFO:       statsforecast: Not installed
2023-05-25 11:10:54,037:INFO:        tune_sklearn: 0.4.5
2023-05-25 11:10:54,037:INFO:                 ray: 2.4.0
2023-05-25 11:10:54,037:INFO:            hyperopt: 0.2.7
2023-05-25 11:10:54,037:INFO:              optuna: 3.1.1
2023-05-25 11:10:54,037:INFO:               skopt: 0.9.0
2023-05-25 11:10:54,037:INFO:              mlflow: Not installed
2023-05-25 11:10:54,037:INFO:              gradio: Not installed
2023-05-25 11:10:54,037:INFO:             fastapi: Not installed
2023-05-25 11:10:54,037:INFO:             uvicorn: Not installed
2023-05-25 11:10:54,037:INFO:              m2cgen: Not installed
2023-05-25 11:10:54,037:INFO:           evidently: Not installed
2023-05-25 11:10:54,037:INFO:               fugue: Not installed
2023-05-25 11:10:54,037:INFO:           streamlit: Not installed
2023-05-25 11:10:54,037:INFO:             prophet: Not installed
2023-05-25 11:10:54,037:INFO:None
2023-05-25 11:10:54,037:INFO:Set up data.
2023-05-25 11:10:54,326:INFO:Set up train/test split.
2023-05-25 11:10:54,459:INFO:Set up index.
2023-05-25 11:10:54,459:INFO:Set up folding strategy.
2023-05-25 11:10:54,459:INFO:Assigning column types.
2023-05-25 11:10:54,530:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-25 11:10:54,594:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 11:10:54,611:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:10:54,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:54,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:54,740:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 11:10:54,740:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:10:54,772:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:54,772:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:54,772:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-25 11:10:54,820:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:10:54,853:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:54,853:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:54,901:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:10:54,925:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:54,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:54,933:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-25 11:10:55,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:55,007:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:55,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:55,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:10:55,096:INFO:Preparing preprocessing pipeline...
2023-05-25 11:10:55,104:INFO:Set up label encoding.
2023-05-25 11:10:55,104:INFO:Set up simple imputation.
2023-05-25 11:10:55,104:INFO:Set up imbalanced handling.
2023-05-25 11:10:55,112:INFO:Set up column name cleaning.
2023-05-25 11:10:58,891:INFO:Finished creating preprocessing pipeline.
2023-05-25 11:10:58,902:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-25 11:10:58,902:INFO:Creating final display dataframe.
2023-05-25 11:11:03,692:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 504)
5        Transformed data shape              (41153, 504)
6   Transformed train set shape              (30052, 504)
7    Transformed test set shape              (11101, 504)
8              Numeric features                       503
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      6873
2023-05-25 11:11:03,840:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:11:03,840:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:11:03,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:11:03,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:11:03,946:INFO:setup() successfully completed in 10.68s...............
2023-05-25 11:14:19,065:INFO:PyCaret ClassificationExperiment
2023-05-25 11:14:19,065:INFO:Logging name: clf-default-name
2023-05-25 11:14:19,065:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-25 11:14:19,065:INFO:version 3.0.2
2023-05-25 11:14:19,065:INFO:Initializing setup()
2023-05-25 11:14:19,065:INFO:self.USI: c2d8
2023-05-25 11:14:19,065:INFO:self._variable_keys: {'log_plots_param', 'y_train', 'X', 'exp_name_log', 'X_test', 'fold_groups_param', 'fold_shuffle_param', '_available_plots', 'memory', '_ml_usecase', 'logging_param', 'gpu_param', 'html_param', 'fold_generator', 'data', 'exp_id', 'is_multiclass', 'pipeline', 'target_param', 'fix_imbalance', 'gpu_n_jobs_param', 'idx', 'USI', 'X_train', 'y', 'y_test', 'seed', 'n_jobs_param'}
2023-05-25 11:14:19,065:INFO:Checking environment
2023-05-25 11:14:19,065:INFO:python_version: 3.10.11
2023-05-25 11:14:19,065:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-25 11:14:19,065:INFO:machine: AMD64
2023-05-25 11:14:19,065:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-25 11:14:19,074:INFO:Memory: svmem(total=16889774080, available=7156707328, percent=57.6, used=9733066752, free=7156707328)
2023-05-25 11:14:19,074:INFO:Physical Core: 4
2023-05-25 11:14:19,074:INFO:Logical Core: 8
2023-05-25 11:14:19,074:INFO:Checking libraries
2023-05-25 11:14:19,074:INFO:System:
2023-05-25 11:14:19,074:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-25 11:14:19,074:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-25 11:14:19,074:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-25 11:14:19,074:INFO:PyCaret required dependencies:
2023-05-25 11:14:19,074:INFO:                 pip: 23.0.1
2023-05-25 11:14:19,074:INFO:          setuptools: 66.0.0
2023-05-25 11:14:19,074:INFO:             pycaret: 3.0.2
2023-05-25 11:14:19,074:INFO:             IPython: 8.13.2
2023-05-25 11:14:19,074:INFO:          ipywidgets: 8.0.6
2023-05-25 11:14:19,074:INFO:                tqdm: 4.65.0
2023-05-25 11:14:19,074:INFO:               numpy: 1.23.5
2023-05-25 11:14:19,074:INFO:              pandas: 1.5.3
2023-05-25 11:14:19,074:INFO:              jinja2: 3.1.2
2023-05-25 11:14:19,074:INFO:               scipy: 1.10.1
2023-05-25 11:14:19,074:INFO:              joblib: 1.2.0
2023-05-25 11:14:19,074:INFO:             sklearn: 1.2.2
2023-05-25 11:14:19,074:INFO:                pyod: 1.0.9
2023-05-25 11:14:19,074:INFO:            imblearn: 0.10.1
2023-05-25 11:14:19,074:INFO:   category_encoders: 2.6.1
2023-05-25 11:14:19,074:INFO:            lightgbm: 3.3.5
2023-05-25 11:14:19,074:INFO:               numba: 0.57.0
2023-05-25 11:14:19,074:INFO:            requests: 2.31.0
2023-05-25 11:14:19,074:INFO:          matplotlib: 3.7.1
2023-05-25 11:14:19,074:INFO:          scikitplot: 0.3.7
2023-05-25 11:14:19,074:INFO:         yellowbrick: 1.5
2023-05-25 11:14:19,074:INFO:              plotly: 5.14.1
2023-05-25 11:14:19,074:INFO:             kaleido: 0.2.1
2023-05-25 11:14:19,074:INFO:         statsmodels: 0.14.0
2023-05-25 11:14:19,074:INFO:              sktime: 0.17.0
2023-05-25 11:14:19,074:INFO:               tbats: 1.1.3
2023-05-25 11:14:19,074:INFO:            pmdarima: 2.0.3
2023-05-25 11:14:19,074:INFO:              psutil: 5.9.5
2023-05-25 11:14:19,074:INFO:PyCaret optional dependencies:
2023-05-25 11:14:19,074:INFO:                shap: Not installed
2023-05-25 11:14:19,074:INFO:           interpret: Not installed
2023-05-25 11:14:19,074:INFO:                umap: Not installed
2023-05-25 11:14:19,074:INFO:    pandas_profiling: Not installed
2023-05-25 11:14:19,074:INFO:  explainerdashboard: Not installed
2023-05-25 11:14:19,074:INFO:             autoviz: Not installed
2023-05-25 11:14:19,074:INFO:           fairlearn: Not installed
2023-05-25 11:14:19,074:INFO:             xgboost: Not installed
2023-05-25 11:14:19,074:INFO:            catboost: Not installed
2023-05-25 11:14:19,074:INFO:              kmodes: Not installed
2023-05-25 11:14:19,074:INFO:             mlxtend: Not installed
2023-05-25 11:14:19,074:INFO:       statsforecast: Not installed
2023-05-25 11:14:19,074:INFO:        tune_sklearn: 0.4.5
2023-05-25 11:14:19,074:INFO:                 ray: 2.4.0
2023-05-25 11:14:19,074:INFO:            hyperopt: 0.2.7
2023-05-25 11:14:19,074:INFO:              optuna: 3.1.1
2023-05-25 11:14:19,074:INFO:               skopt: 0.9.0
2023-05-25 11:14:19,074:INFO:              mlflow: Not installed
2023-05-25 11:14:19,074:INFO:              gradio: Not installed
2023-05-25 11:14:19,074:INFO:             fastapi: Not installed
2023-05-25 11:14:19,074:INFO:             uvicorn: Not installed
2023-05-25 11:14:19,074:INFO:              m2cgen: Not installed
2023-05-25 11:14:19,074:INFO:           evidently: Not installed
2023-05-25 11:14:19,074:INFO:               fugue: Not installed
2023-05-25 11:14:19,074:INFO:           streamlit: Not installed
2023-05-25 11:14:19,074:INFO:             prophet: Not installed
2023-05-25 11:14:19,074:INFO:None
2023-05-25 11:14:19,074:INFO:Set up data.
2023-05-25 11:14:19,334:INFO:Set up train/test split.
2023-05-25 11:14:19,438:INFO:Set up index.
2023-05-25 11:14:19,447:INFO:Set up folding strategy.
2023-05-25 11:14:19,447:INFO:Assigning column types.
2023-05-25 11:14:19,520:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-25 11:14:19,609:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 11:14:19,609:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:14:19,656:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:19,656:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:19,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 11:14:19,705:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:14:19,738:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:19,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:19,746:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-25 11:14:19,794:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:14:19,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:19,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:19,874:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:14:19,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:19,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:19,906:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-25 11:14:19,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:19,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:20,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:20,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:20,068:INFO:Preparing preprocessing pipeline...
2023-05-25 11:14:20,076:INFO:Set up label encoding.
2023-05-25 11:14:20,076:INFO:Set up simple imputation.
2023-05-25 11:14:20,076:INFO:Set up imbalanced handling.
2023-05-25 11:14:20,084:INFO:Set up column name cleaning.
2023-05-25 11:14:20,702:INFO:Finished creating preprocessing pipeline.
2023-05-25 11:14:20,710:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-25 11:14:20,710:INFO:Creating final display dataframe.
2023-05-25 11:14:23,482:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 504)
5        Transformed data shape              (41153, 504)
6   Transformed train set shape              (30052, 504)
7    Transformed test set shape              (11101, 504)
8              Numeric features                       503
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      c2d8
2023-05-25 11:14:23,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:23,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:23,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:23,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:14:23,766:INFO:setup() successfully completed in 5.31s...............
2023-05-25 11:14:23,856:INFO:Initializing compare_models()
2023-05-25 11:14:23,856:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-25 11:14:23,856:INFO:Checking exceptions
2023-05-25 11:14:23,929:INFO:Preparing display monitor
2023-05-25 11:14:23,978:INFO:Initializing Logistic Regression
2023-05-25 11:14:23,978:INFO:Total runtime is 0.0 minutes
2023-05-25 11:14:23,987:INFO:SubProcess create_model() called ==================================
2023-05-25 11:14:23,987:INFO:Initializing create_model()
2023-05-25 11:14:23,987:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:14:23,995:INFO:Checking exceptions
2023-05-25 11:14:23,995:INFO:Importing libraries
2023-05-25 11:14:23,995:INFO:Copying training dataset
2023-05-25 11:14:24,181:INFO:Defining folds
2023-05-25 11:14:24,181:INFO:Declaring metric variables
2023-05-25 11:14:24,197:INFO:Importing untrained model
2023-05-25 11:14:24,213:INFO:Logistic Regression Imported successfully
2023-05-25 11:14:24,250:INFO:Starting cross validation
2023-05-25 11:14:24,262:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:14:35,372:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:35,469:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-25 11:14:35,672:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-25 11:14:35,725:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-25 11:14:35,755:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:36,859:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:36,994:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:50,990:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:51,718:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:51,780:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:52,257:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:52,410:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:52,947:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-25 11:14:53,340:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:53,373:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:53,419:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-25 11:14:53,529:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-25 11:14:53,592:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:53,592:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-25 11:14:53,829:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-25 11:14:54,240:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:54,829:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-25 11:14:54,903:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:54,918:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-25 11:14:55,031:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-25 11:14:55,138:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:56,494:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:56,525:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:14:56,643:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:16:03,098:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:16:03,129:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:16:05,655:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:16:06,153:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:16:06,243:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:16:06,269:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:16:06,735:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:16:06,944:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:16:35,295:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:16:35,499:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:16:36,661:INFO:Calculating mean and std
2023-05-25 11:16:36,661:INFO:Creating metrics dataframe
2023-05-25 11:16:37,476:INFO:Uploading results into container
2023-05-25 11:16:37,476:INFO:Uploading model into container now
2023-05-25 11:16:37,476:INFO:_master_model_container: 1
2023-05-25 11:16:37,476:INFO:_display_container: 2
2023-05-25 11:16:37,476:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-25 11:16:37,476:INFO:create_model() successfully completed......................................
2023-05-25 11:16:37,608:INFO:SubProcess create_model() end ==================================
2023-05-25 11:16:37,608:INFO:Creating metrics dataframe
2023-05-25 11:16:37,612:INFO:Initializing K Neighbors Classifier
2023-05-25 11:16:37,612:INFO:Total runtime is 2.227227250734965 minutes
2023-05-25 11:16:37,625:INFO:SubProcess create_model() called ==================================
2023-05-25 11:16:37,625:INFO:Initializing create_model()
2023-05-25 11:16:37,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:16:37,625:INFO:Checking exceptions
2023-05-25 11:16:37,625:INFO:Importing libraries
2023-05-25 11:16:37,625:INFO:Copying training dataset
2023-05-25 11:16:37,720:INFO:Defining folds
2023-05-25 11:16:37,720:INFO:Declaring metric variables
2023-05-25 11:16:37,736:INFO:Importing untrained model
2023-05-25 11:16:37,736:INFO:K Neighbors Classifier Imported successfully
2023-05-25 11:16:37,752:INFO:Starting cross validation
2023-05-25 11:16:37,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:16:41,200:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:16:58,347:INFO:Calculating mean and std
2023-05-25 11:16:58,347:INFO:Creating metrics dataframe
2023-05-25 11:16:59,546:INFO:Uploading results into container
2023-05-25 11:16:59,547:INFO:Uploading model into container now
2023-05-25 11:16:59,547:INFO:_master_model_container: 2
2023-05-25 11:16:59,547:INFO:_display_container: 2
2023-05-25 11:16:59,547:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-25 11:16:59,548:INFO:create_model() successfully completed......................................
2023-05-25 11:16:59,648:INFO:SubProcess create_model() end ==================================
2023-05-25 11:16:59,648:INFO:Creating metrics dataframe
2023-05-25 11:16:59,657:INFO:Initializing Naive Bayes
2023-05-25 11:16:59,657:INFO:Total runtime is 2.5946555296579996 minutes
2023-05-25 11:16:59,662:INFO:SubProcess create_model() called ==================================
2023-05-25 11:16:59,662:INFO:Initializing create_model()
2023-05-25 11:16:59,662:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:16:59,662:INFO:Checking exceptions
2023-05-25 11:16:59,662:INFO:Importing libraries
2023-05-25 11:16:59,662:INFO:Copying training dataset
2023-05-25 11:16:59,735:INFO:Defining folds
2023-05-25 11:16:59,736:INFO:Declaring metric variables
2023-05-25 11:16:59,739:INFO:Importing untrained model
2023-05-25 11:16:59,744:INFO:Naive Bayes Imported successfully
2023-05-25 11:16:59,751:INFO:Starting cross validation
2023-05-25 11:16:59,754:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:17:07,020:INFO:Calculating mean and std
2023-05-25 11:17:07,021:INFO:Creating metrics dataframe
2023-05-25 11:17:07,437:INFO:Uploading results into container
2023-05-25 11:17:07,437:INFO:Uploading model into container now
2023-05-25 11:17:07,438:INFO:_master_model_container: 3
2023-05-25 11:17:07,438:INFO:_display_container: 2
2023-05-25 11:17:07,438:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-25 11:17:07,438:INFO:create_model() successfully completed......................................
2023-05-25 11:17:07,533:INFO:SubProcess create_model() end ==================================
2023-05-25 11:17:07,533:INFO:Creating metrics dataframe
2023-05-25 11:17:07,541:INFO:Initializing Decision Tree Classifier
2023-05-25 11:17:07,541:INFO:Total runtime is 2.7260576168696087 minutes
2023-05-25 11:17:07,546:INFO:SubProcess create_model() called ==================================
2023-05-25 11:17:07,546:INFO:Initializing create_model()
2023-05-25 11:17:07,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:17:07,546:INFO:Checking exceptions
2023-05-25 11:17:07,546:INFO:Importing libraries
2023-05-25 11:17:07,546:INFO:Copying training dataset
2023-05-25 11:17:07,614:INFO:Defining folds
2023-05-25 11:17:07,614:INFO:Declaring metric variables
2023-05-25 11:17:07,618:INFO:Importing untrained model
2023-05-25 11:17:07,622:INFO:Decision Tree Classifier Imported successfully
2023-05-25 11:17:07,630:INFO:Starting cross validation
2023-05-25 11:17:07,634:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:17:20,374:INFO:Calculating mean and std
2023-05-25 11:17:20,375:INFO:Creating metrics dataframe
2023-05-25 11:17:20,810:INFO:Uploading results into container
2023-05-25 11:17:20,811:INFO:Uploading model into container now
2023-05-25 11:17:20,812:INFO:_master_model_container: 4
2023-05-25 11:17:20,812:INFO:_display_container: 2
2023-05-25 11:17:20,812:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-25 11:17:20,812:INFO:create_model() successfully completed......................................
2023-05-25 11:17:20,907:INFO:SubProcess create_model() end ==================================
2023-05-25 11:17:20,907:INFO:Creating metrics dataframe
2023-05-25 11:17:20,919:INFO:Initializing SVM - Linear Kernel
2023-05-25 11:17:20,919:INFO:Total runtime is 2.949011611938477 minutes
2023-05-25 11:17:20,923:INFO:SubProcess create_model() called ==================================
2023-05-25 11:17:20,923:INFO:Initializing create_model()
2023-05-25 11:17:20,923:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:17:20,923:INFO:Checking exceptions
2023-05-25 11:17:20,923:INFO:Importing libraries
2023-05-25 11:17:20,923:INFO:Copying training dataset
2023-05-25 11:17:21,004:INFO:Defining folds
2023-05-25 11:17:21,004:INFO:Declaring metric variables
2023-05-25 11:17:21,008:INFO:Importing untrained model
2023-05-25 11:17:21,012:INFO:SVM - Linear Kernel Imported successfully
2023-05-25 11:17:21,021:INFO:Starting cross validation
2023-05-25 11:17:21,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:17:24,047:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:17:24,165:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:17:24,167:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:17:24,437:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:17:24,454:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:17:24,589:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:17:24,627:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:17:24,725:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:17:27,056:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:17:27,289:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:17:28,911:INFO:Calculating mean and std
2023-05-25 11:17:28,912:INFO:Creating metrics dataframe
2023-05-25 11:17:29,390:INFO:Uploading results into container
2023-05-25 11:17:29,390:INFO:Uploading model into container now
2023-05-25 11:17:29,390:INFO:_master_model_container: 5
2023-05-25 11:17:29,390:INFO:_display_container: 2
2023-05-25 11:17:29,390:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-25 11:17:29,391:INFO:create_model() successfully completed......................................
2023-05-25 11:17:29,488:INFO:SubProcess create_model() end ==================================
2023-05-25 11:17:29,488:INFO:Creating metrics dataframe
2023-05-25 11:17:29,498:INFO:Initializing Ridge Classifier
2023-05-25 11:17:29,499:INFO:Total runtime is 3.0920193552970887 minutes
2023-05-25 11:17:29,502:INFO:SubProcess create_model() called ==================================
2023-05-25 11:17:29,502:INFO:Initializing create_model()
2023-05-25 11:17:29,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:17:29,503:INFO:Checking exceptions
2023-05-25 11:17:29,503:INFO:Importing libraries
2023-05-25 11:17:29,503:INFO:Copying training dataset
2023-05-25 11:17:29,575:INFO:Defining folds
2023-05-25 11:17:29,576:INFO:Declaring metric variables
2023-05-25 11:17:29,580:INFO:Importing untrained model
2023-05-25 11:17:29,583:INFO:Ridge Classifier Imported successfully
2023-05-25 11:17:29,590:INFO:Starting cross validation
2023-05-25 11:17:29,594:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:17:32,637:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:17:32,662:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:17:32,741:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:17:32,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:17:32,773:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:17:32,918:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:17:32,926:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:17:32,977:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:17:36,009:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:17:36,072:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:17:37,904:INFO:Calculating mean and std
2023-05-25 11:17:37,905:INFO:Creating metrics dataframe
2023-05-25 11:17:38,383:INFO:Uploading results into container
2023-05-25 11:17:38,383:INFO:Uploading model into container now
2023-05-25 11:17:38,384:INFO:_master_model_container: 6
2023-05-25 11:17:38,384:INFO:_display_container: 2
2023-05-25 11:17:38,384:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-25 11:17:38,384:INFO:create_model() successfully completed......................................
2023-05-25 11:17:38,479:INFO:SubProcess create_model() end ==================================
2023-05-25 11:17:38,479:INFO:Creating metrics dataframe
2023-05-25 11:17:38,490:INFO:Initializing Random Forest Classifier
2023-05-25 11:17:38,490:INFO:Total runtime is 3.2418612082799276 minutes
2023-05-25 11:17:38,494:INFO:SubProcess create_model() called ==================================
2023-05-25 11:17:38,494:INFO:Initializing create_model()
2023-05-25 11:17:38,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:17:38,495:INFO:Checking exceptions
2023-05-25 11:17:38,495:INFO:Importing libraries
2023-05-25 11:17:38,495:INFO:Copying training dataset
2023-05-25 11:17:38,564:INFO:Defining folds
2023-05-25 11:17:38,564:INFO:Declaring metric variables
2023-05-25 11:17:38,567:INFO:Importing untrained model
2023-05-25 11:17:38,571:INFO:Random Forest Classifier Imported successfully
2023-05-25 11:17:38,580:INFO:Starting cross validation
2023-05-25 11:17:38,584:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:18:03,302:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 11:18:03,892:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 11:18:05,302:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:18:05,351:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:18:05,457:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:18:05,501:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:18:15,433:INFO:Calculating mean and std
2023-05-25 11:18:15,434:INFO:Creating metrics dataframe
2023-05-25 11:18:15,917:INFO:Uploading results into container
2023-05-25 11:18:15,917:INFO:Uploading model into container now
2023-05-25 11:18:15,918:INFO:_master_model_container: 7
2023-05-25 11:18:15,918:INFO:_display_container: 2
2023-05-25 11:18:15,918:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 11:18:15,918:INFO:create_model() successfully completed......................................
2023-05-25 11:18:16,014:INFO:SubProcess create_model() end ==================================
2023-05-25 11:18:16,014:INFO:Creating metrics dataframe
2023-05-25 11:18:16,023:INFO:Initializing Quadratic Discriminant Analysis
2023-05-25 11:18:16,024:INFO:Total runtime is 3.867429081598918 minutes
2023-05-25 11:18:16,028:INFO:SubProcess create_model() called ==================================
2023-05-25 11:18:16,029:INFO:Initializing create_model()
2023-05-25 11:18:16,029:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:18:16,029:INFO:Checking exceptions
2023-05-25 11:18:16,029:INFO:Importing libraries
2023-05-25 11:18:16,029:INFO:Copying training dataset
2023-05-25 11:18:16,098:INFO:Defining folds
2023-05-25 11:18:16,099:INFO:Declaring metric variables
2023-05-25 11:18:16,103:INFO:Importing untrained model
2023-05-25 11:18:16,107:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-25 11:18:16,115:INFO:Starting cross validation
2023-05-25 11:18:16,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:18:21,291:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:18:21,292:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:18:21,448:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:18:21,516:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:18:21,579:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:18:21,610:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:18:21,665:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:18:21,675:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:18:30,473:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:18:30,582:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:18:33,041:INFO:Calculating mean and std
2023-05-25 11:18:33,042:INFO:Creating metrics dataframe
2023-05-25 11:18:33,543:INFO:Uploading results into container
2023-05-25 11:18:33,544:INFO:Uploading model into container now
2023-05-25 11:18:33,544:INFO:_master_model_container: 8
2023-05-25 11:18:33,545:INFO:_display_container: 2
2023-05-25 11:18:33,545:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-25 11:18:33,545:INFO:create_model() successfully completed......................................
2023-05-25 11:18:33,639:INFO:SubProcess create_model() end ==================================
2023-05-25 11:18:33,639:INFO:Creating metrics dataframe
2023-05-25 11:18:33,650:INFO:Initializing Ada Boost Classifier
2023-05-25 11:18:33,651:INFO:Total runtime is 4.161222064495087 minutes
2023-05-25 11:18:33,655:INFO:SubProcess create_model() called ==================================
2023-05-25 11:18:33,655:INFO:Initializing create_model()
2023-05-25 11:18:33,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:18:33,655:INFO:Checking exceptions
2023-05-25 11:18:33,655:INFO:Importing libraries
2023-05-25 11:18:33,655:INFO:Copying training dataset
2023-05-25 11:18:33,724:INFO:Defining folds
2023-05-25 11:18:33,724:INFO:Declaring metric variables
2023-05-25 11:18:33,730:INFO:Importing untrained model
2023-05-25 11:18:33,735:INFO:Ada Boost Classifier Imported successfully
2023-05-25 11:18:33,741:INFO:Starting cross validation
2023-05-25 11:18:33,745:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:19:04,328:INFO:Calculating mean and std
2023-05-25 11:19:04,329:INFO:Creating metrics dataframe
2023-05-25 11:19:04,788:INFO:Uploading results into container
2023-05-25 11:19:04,788:INFO:Uploading model into container now
2023-05-25 11:19:04,789:INFO:_master_model_container: 9
2023-05-25 11:19:04,789:INFO:_display_container: 2
2023-05-25 11:19:04,789:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 11:19:04,789:INFO:create_model() successfully completed......................................
2023-05-25 11:19:04,885:INFO:SubProcess create_model() end ==================================
2023-05-25 11:19:04,885:INFO:Creating metrics dataframe
2023-05-25 11:19:04,896:INFO:Initializing Gradient Boosting Classifier
2023-05-25 11:19:04,897:INFO:Total runtime is 4.681978503863017 minutes
2023-05-25 11:19:04,901:INFO:SubProcess create_model() called ==================================
2023-05-25 11:19:04,902:INFO:Initializing create_model()
2023-05-25 11:19:04,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:19:04,902:INFO:Checking exceptions
2023-05-25 11:19:04,902:INFO:Importing libraries
2023-05-25 11:19:04,902:INFO:Copying training dataset
2023-05-25 11:19:04,972:INFO:Defining folds
2023-05-25 11:19:04,972:INFO:Declaring metric variables
2023-05-25 11:19:04,976:INFO:Importing untrained model
2023-05-25 11:19:04,980:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 11:19:04,988:INFO:Starting cross validation
2023-05-25 11:19:04,991:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:20:18,559:INFO:Calculating mean and std
2023-05-25 11:20:18,561:INFO:Creating metrics dataframe
2023-05-25 11:20:19,040:INFO:Uploading results into container
2023-05-25 11:20:19,041:INFO:Uploading model into container now
2023-05-25 11:20:19,041:INFO:_master_model_container: 10
2023-05-25 11:20:19,041:INFO:_display_container: 2
2023-05-25 11:20:19,042:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 11:20:19,042:INFO:create_model() successfully completed......................................
2023-05-25 11:20:19,137:INFO:SubProcess create_model() end ==================================
2023-05-25 11:20:19,137:INFO:Creating metrics dataframe
2023-05-25 11:20:19,148:INFO:Initializing Linear Discriminant Analysis
2023-05-25 11:20:19,149:INFO:Total runtime is 5.919511123498281 minutes
2023-05-25 11:20:19,154:INFO:SubProcess create_model() called ==================================
2023-05-25 11:20:19,154:INFO:Initializing create_model()
2023-05-25 11:20:19,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:20:19,154:INFO:Checking exceptions
2023-05-25 11:20:19,154:INFO:Importing libraries
2023-05-25 11:20:19,155:INFO:Copying training dataset
2023-05-25 11:20:19,221:INFO:Defining folds
2023-05-25 11:20:19,221:INFO:Declaring metric variables
2023-05-25 11:20:19,225:INFO:Importing untrained model
2023-05-25 11:20:19,229:INFO:Linear Discriminant Analysis Imported successfully
2023-05-25 11:20:19,237:INFO:Starting cross validation
2023-05-25 11:20:19,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:20:40,554:INFO:Calculating mean and std
2023-05-25 11:20:40,556:INFO:Creating metrics dataframe
2023-05-25 11:20:41,068:INFO:Uploading results into container
2023-05-25 11:20:41,068:INFO:Uploading model into container now
2023-05-25 11:20:41,069:INFO:_master_model_container: 11
2023-05-25 11:20:41,069:INFO:_display_container: 2
2023-05-25 11:20:41,069:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-25 11:20:41,069:INFO:create_model() successfully completed......................................
2023-05-25 11:20:41,161:INFO:SubProcess create_model() end ==================================
2023-05-25 11:20:41,162:INFO:Creating metrics dataframe
2023-05-25 11:20:41,173:INFO:Initializing Extra Trees Classifier
2023-05-25 11:20:41,173:INFO:Total runtime is 6.286588990688324 minutes
2023-05-25 11:20:41,177:INFO:SubProcess create_model() called ==================================
2023-05-25 11:20:41,177:INFO:Initializing create_model()
2023-05-25 11:20:41,177:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:20:41,177:INFO:Checking exceptions
2023-05-25 11:20:41,178:INFO:Importing libraries
2023-05-25 11:20:41,178:INFO:Copying training dataset
2023-05-25 11:20:41,250:INFO:Defining folds
2023-05-25 11:20:41,250:INFO:Declaring metric variables
2023-05-25 11:20:41,254:INFO:Importing untrained model
2023-05-25 11:20:41,258:INFO:Extra Trees Classifier Imported successfully
2023-05-25 11:20:41,265:INFO:Starting cross validation
2023-05-25 11:20:41,270:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:21:26,490:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 11:21:27,122:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 11:21:29,194:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:21:29,389:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:21:29,509:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:21:29,674:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:21:29,722:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:21:30,139:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:21:46,003:INFO:Calculating mean and std
2023-05-25 11:21:46,004:INFO:Creating metrics dataframe
2023-05-25 11:21:46,557:INFO:Uploading results into container
2023-05-25 11:21:46,558:INFO:Uploading model into container now
2023-05-25 11:21:46,558:INFO:_master_model_container: 12
2023-05-25 11:21:46,558:INFO:_display_container: 2
2023-05-25 11:21:46,558:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 11:21:46,558:INFO:create_model() successfully completed......................................
2023-05-25 11:21:46,654:INFO:SubProcess create_model() end ==================================
2023-05-25 11:21:46,654:INFO:Creating metrics dataframe
2023-05-25 11:21:46,667:INFO:Initializing Light Gradient Boosting Machine
2023-05-25 11:21:46,667:INFO:Total runtime is 7.3781439940134685 minutes
2023-05-25 11:21:46,671:INFO:SubProcess create_model() called ==================================
2023-05-25 11:21:46,672:INFO:Initializing create_model()
2023-05-25 11:21:46,672:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:21:46,672:INFO:Checking exceptions
2023-05-25 11:21:46,672:INFO:Importing libraries
2023-05-25 11:21:46,672:INFO:Copying training dataset
2023-05-25 11:21:46,741:INFO:Defining folds
2023-05-25 11:21:46,742:INFO:Declaring metric variables
2023-05-25 11:21:46,745:INFO:Importing untrained model
2023-05-25 11:21:46,750:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 11:21:46,758:INFO:Starting cross validation
2023-05-25 11:21:46,761:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:22:00,656:INFO:Calculating mean and std
2023-05-25 11:22:00,657:INFO:Creating metrics dataframe
2023-05-25 11:22:01,139:INFO:Uploading results into container
2023-05-25 11:22:01,140:INFO:Uploading model into container now
2023-05-25 11:22:01,140:INFO:_master_model_container: 13
2023-05-25 11:22:01,140:INFO:_display_container: 2
2023-05-25 11:22:01,141:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 11:22:01,141:INFO:create_model() successfully completed......................................
2023-05-25 11:22:01,236:INFO:SubProcess create_model() end ==================================
2023-05-25 11:22:01,237:INFO:Creating metrics dataframe
2023-05-25 11:22:01,248:INFO:Initializing Dummy Classifier
2023-05-25 11:22:01,249:INFO:Total runtime is 7.621184734503428 minutes
2023-05-25 11:22:01,251:INFO:SubProcess create_model() called ==================================
2023-05-25 11:22:01,251:INFO:Initializing create_model()
2023-05-25 11:22:01,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000126DE345480>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:22:01,252:INFO:Checking exceptions
2023-05-25 11:22:01,252:INFO:Importing libraries
2023-05-25 11:22:01,252:INFO:Copying training dataset
2023-05-25 11:22:01,323:INFO:Defining folds
2023-05-25 11:22:01,323:INFO:Declaring metric variables
2023-05-25 11:22:01,327:INFO:Importing untrained model
2023-05-25 11:22:01,332:INFO:Dummy Classifier Imported successfully
2023-05-25 11:22:01,339:INFO:Starting cross validation
2023-05-25 11:22:01,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:22:03,125:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 11:22:03,132:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 11:22:03,237:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 11:22:03,306:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 11:22:03,309:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 11:22:03,366:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 11:22:03,392:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 11:22:03,395:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 11:22:05,464:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 11:22:05,489:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 11:22:07,767:INFO:Calculating mean and std
2023-05-25 11:22:07,768:INFO:Creating metrics dataframe
2023-05-25 11:22:08,231:INFO:Uploading results into container
2023-05-25 11:22:08,231:INFO:Uploading model into container now
2023-05-25 11:22:08,232:INFO:_master_model_container: 14
2023-05-25 11:22:08,232:INFO:_display_container: 2
2023-05-25 11:22:08,232:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-25 11:22:08,232:INFO:create_model() successfully completed......................................
2023-05-25 11:22:08,329:INFO:SubProcess create_model() end ==================================
2023-05-25 11:22:08,329:INFO:Creating metrics dataframe
2023-05-25 11:22:08,352:INFO:Initializing create_model()
2023-05-25 11:22:08,353:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:22:08,353:INFO:Checking exceptions
2023-05-25 11:22:08,355:INFO:Importing libraries
2023-05-25 11:22:08,355:INFO:Copying training dataset
2023-05-25 11:22:08,422:INFO:Defining folds
2023-05-25 11:22:08,422:INFO:Declaring metric variables
2023-05-25 11:22:08,423:INFO:Importing untrained model
2023-05-25 11:22:08,423:INFO:Declaring custom model
2023-05-25 11:22:08,423:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 11:22:08,426:INFO:Cross validation set to False
2023-05-25 11:22:08,426:INFO:Fitting Model
2023-05-25 11:22:10,828:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 11:22:10,828:INFO:create_model() successfully completed......................................
2023-05-25 11:22:10,928:INFO:Initializing create_model()
2023-05-25 11:22:10,929:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:22:10,929:INFO:Checking exceptions
2023-05-25 11:22:10,932:INFO:Importing libraries
2023-05-25 11:22:10,932:INFO:Copying training dataset
2023-05-25 11:22:10,999:INFO:Defining folds
2023-05-25 11:22:10,999:INFO:Declaring metric variables
2023-05-25 11:22:10,999:INFO:Importing untrained model
2023-05-25 11:22:11,000:INFO:Declaring custom model
2023-05-25 11:22:11,000:INFO:Random Forest Classifier Imported successfully
2023-05-25 11:22:11,003:INFO:Cross validation set to False
2023-05-25 11:22:11,003:INFO:Fitting Model
2023-05-25 11:22:15,204:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 11:22:15,204:INFO:create_model() successfully completed......................................
2023-05-25 11:22:15,307:INFO:Initializing create_model()
2023-05-25 11:22:15,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:22:15,307:INFO:Checking exceptions
2023-05-25 11:22:15,309:INFO:Importing libraries
2023-05-25 11:22:15,309:INFO:Copying training dataset
2023-05-25 11:22:15,383:INFO:Defining folds
2023-05-25 11:22:15,383:INFO:Declaring metric variables
2023-05-25 11:22:15,383:INFO:Importing untrained model
2023-05-25 11:22:15,383:INFO:Declaring custom model
2023-05-25 11:22:15,384:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 11:22:15,386:INFO:Cross validation set to False
2023-05-25 11:22:15,386:INFO:Fitting Model
2023-05-25 11:22:39,470:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 11:22:39,470:INFO:create_model() successfully completed......................................
2023-05-25 11:22:39,570:INFO:Initializing create_model()
2023-05-25 11:22:39,570:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:22:39,571:INFO:Checking exceptions
2023-05-25 11:22:39,573:INFO:Importing libraries
2023-05-25 11:22:39,573:INFO:Copying training dataset
2023-05-25 11:22:39,642:INFO:Defining folds
2023-05-25 11:22:39,642:INFO:Declaring metric variables
2023-05-25 11:22:39,642:INFO:Importing untrained model
2023-05-25 11:22:39,642:INFO:Declaring custom model
2023-05-25 11:22:39,643:INFO:Ada Boost Classifier Imported successfully
2023-05-25 11:22:39,645:INFO:Cross validation set to False
2023-05-25 11:22:39,645:INFO:Fitting Model
2023-05-25 11:22:47,445:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 11:22:47,445:INFO:create_model() successfully completed......................................
2023-05-25 11:22:47,543:INFO:Initializing create_model()
2023-05-25 11:22:47,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:22:47,544:INFO:Checking exceptions
2023-05-25 11:22:47,546:INFO:Importing libraries
2023-05-25 11:22:47,546:INFO:Copying training dataset
2023-05-25 11:22:47,614:INFO:Defining folds
2023-05-25 11:22:47,614:INFO:Declaring metric variables
2023-05-25 11:22:47,615:INFO:Importing untrained model
2023-05-25 11:22:47,615:INFO:Declaring custom model
2023-05-25 11:22:47,616:INFO:Extra Trees Classifier Imported successfully
2023-05-25 11:22:47,619:INFO:Cross validation set to False
2023-05-25 11:22:47,619:INFO:Fitting Model
2023-05-25 11:22:54,541:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 11:22:54,542:INFO:create_model() successfully completed......................................
2023-05-25 11:22:54,665:INFO:_master_model_container: 14
2023-05-25 11:22:54,666:INFO:_display_container: 2
2023-05-25 11:22:54,668:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)]
2023-05-25 11:22:54,668:INFO:compare_models() successfully completed......................................
2023-05-25 11:22:55,043:INFO:Initializing predict_model()
2023-05-25 11:22:55,043:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000126DE243AF0>, estimator=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)], probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000012680031120>)
2023-05-25 11:22:55,043:INFO:Checking exceptions
2023-05-25 11:22:55,043:INFO:Preloading libraries
2023-05-25 11:22:55,046:INFO:Set up data.
2023-05-25 11:22:55,165:INFO:Set up index.
2023-05-25 11:52:15,453:INFO:PyCaret ClassificationExperiment
2023-05-25 11:52:15,453:INFO:Logging name: clf-default-name
2023-05-25 11:52:15,453:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-25 11:52:15,453:INFO:version 3.0.2
2023-05-25 11:52:15,453:INFO:Initializing setup()
2023-05-25 11:52:15,453:INFO:self.USI: 0d64
2023-05-25 11:52:15,454:INFO:self._variable_keys: {'X_train', 'memory', 'fold_groups_param', 'y_train', '_available_plots', 'fix_imbalance', 'exp_id', '_ml_usecase', 'idx', 'seed', 'gpu_param', 'logging_param', 'USI', 'data', 'html_param', 'n_jobs_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'fold_generator', 'X', 'X_test', 'y', 'exp_name_log', 'log_plots_param', 'is_multiclass', 'pipeline', 'y_test', 'target_param'}
2023-05-25 11:52:15,454:INFO:Checking environment
2023-05-25 11:52:15,454:INFO:python_version: 3.10.11
2023-05-25 11:52:15,454:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-25 11:52:15,454:INFO:machine: AMD64
2023-05-25 11:52:15,454:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-25 11:52:15,459:INFO:Memory: svmem(total=16889774080, available=5096435712, percent=69.8, used=11793338368, free=5096435712)
2023-05-25 11:52:15,459:INFO:Physical Core: 4
2023-05-25 11:52:15,459:INFO:Logical Core: 8
2023-05-25 11:52:15,459:INFO:Checking libraries
2023-05-25 11:52:15,459:INFO:System:
2023-05-25 11:52:15,459:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-25 11:52:15,459:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-25 11:52:15,459:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-25 11:52:15,459:INFO:PyCaret required dependencies:
2023-05-25 11:52:15,460:INFO:                 pip: 23.0.1
2023-05-25 11:52:15,460:INFO:          setuptools: 66.0.0
2023-05-25 11:52:15,460:INFO:             pycaret: 3.0.2
2023-05-25 11:52:15,460:INFO:             IPython: 8.13.2
2023-05-25 11:52:15,460:INFO:          ipywidgets: 8.0.6
2023-05-25 11:52:15,460:INFO:                tqdm: 4.65.0
2023-05-25 11:52:15,460:INFO:               numpy: 1.23.5
2023-05-25 11:52:15,460:INFO:              pandas: 1.5.3
2023-05-25 11:52:15,460:INFO:              jinja2: 3.1.2
2023-05-25 11:52:15,460:INFO:               scipy: 1.10.1
2023-05-25 11:52:15,460:INFO:              joblib: 1.2.0
2023-05-25 11:52:15,460:INFO:             sklearn: 1.2.2
2023-05-25 11:52:15,461:INFO:                pyod: 1.0.9
2023-05-25 11:52:15,461:INFO:            imblearn: 0.10.1
2023-05-25 11:52:15,461:INFO:   category_encoders: 2.6.1
2023-05-25 11:52:15,461:INFO:            lightgbm: 3.3.5
2023-05-25 11:52:15,461:INFO:               numba: 0.57.0
2023-05-25 11:52:15,461:INFO:            requests: 2.31.0
2023-05-25 11:52:15,461:INFO:          matplotlib: 3.7.1
2023-05-25 11:52:15,461:INFO:          scikitplot: 0.3.7
2023-05-25 11:52:15,461:INFO:         yellowbrick: 1.5
2023-05-25 11:52:15,461:INFO:              plotly: 5.14.1
2023-05-25 11:52:15,461:INFO:             kaleido: 0.2.1
2023-05-25 11:52:15,461:INFO:         statsmodels: 0.14.0
2023-05-25 11:52:15,461:INFO:              sktime: 0.17.0
2023-05-25 11:52:15,461:INFO:               tbats: 1.1.3
2023-05-25 11:52:15,461:INFO:            pmdarima: 2.0.3
2023-05-25 11:52:15,461:INFO:              psutil: 5.9.5
2023-05-25 11:52:15,461:INFO:PyCaret optional dependencies:
2023-05-25 11:52:15,461:INFO:                shap: Not installed
2023-05-25 11:52:15,461:INFO:           interpret: Not installed
2023-05-25 11:52:15,461:INFO:                umap: Not installed
2023-05-25 11:52:15,461:INFO:    pandas_profiling: Not installed
2023-05-25 11:52:15,461:INFO:  explainerdashboard: Not installed
2023-05-25 11:52:15,461:INFO:             autoviz: Not installed
2023-05-25 11:52:15,461:INFO:           fairlearn: Not installed
2023-05-25 11:52:15,461:INFO:             xgboost: Not installed
2023-05-25 11:52:15,461:INFO:            catboost: Not installed
2023-05-25 11:52:15,461:INFO:              kmodes: Not installed
2023-05-25 11:52:15,461:INFO:             mlxtend: Not installed
2023-05-25 11:52:15,461:INFO:       statsforecast: Not installed
2023-05-25 11:52:15,462:INFO:        tune_sklearn: 0.4.5
2023-05-25 11:52:15,462:INFO:                 ray: 2.4.0
2023-05-25 11:52:15,462:INFO:            hyperopt: 0.2.7
2023-05-25 11:52:15,462:INFO:              optuna: 3.1.1
2023-05-25 11:52:15,462:INFO:               skopt: 0.9.0
2023-05-25 11:52:15,462:INFO:              mlflow: Not installed
2023-05-25 11:52:15,462:INFO:              gradio: Not installed
2023-05-25 11:52:15,462:INFO:             fastapi: Not installed
2023-05-25 11:52:15,462:INFO:             uvicorn: Not installed
2023-05-25 11:52:15,462:INFO:              m2cgen: Not installed
2023-05-25 11:52:15,462:INFO:           evidently: Not installed
2023-05-25 11:52:15,462:INFO:               fugue: Not installed
2023-05-25 11:52:15,462:INFO:           streamlit: Not installed
2023-05-25 11:52:15,462:INFO:             prophet: Not installed
2023-05-25 11:52:15,462:INFO:None
2023-05-25 11:52:15,462:INFO:Set up data.
2023-05-25 11:52:15,730:INFO:Set up train/test split.
2023-05-25 11:52:15,850:INFO:Set up index.
2023-05-25 11:52:15,854:INFO:Set up folding strategy.
2023-05-25 11:52:15,854:INFO:Assigning column types.
2023-05-25 11:52:15,923:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-25 11:52:15,987:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 11:52:15,989:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:52:16,016:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,059:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 11:52:16,060:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:52:16,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,086:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-25 11:52:16,126:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:52:16,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,186:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:52:16,211:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,212:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,212:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-25 11:52:16,274:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:16,338:INFO:Preparing preprocessing pipeline...
2023-05-25 11:52:16,346:INFO:Set up label encoding.
2023-05-25 11:52:16,347:INFO:Set up simple imputation.
2023-05-25 11:52:16,347:INFO:Set up imbalanced handling.
2023-05-25 11:52:16,364:INFO:Set up column name cleaning.
2023-05-25 11:52:18,736:INFO:Finished creating preprocessing pipeline.
2023-05-25 11:52:18,747:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-25 11:52:18,748:INFO:Creating final display dataframe.
2023-05-25 11:52:22,396:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 511)
5        Transformed data shape              (41153, 511)
6   Transformed train set shape              (30052, 511)
7    Transformed test set shape              (11101, 511)
8              Numeric features                       510
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      0d64
2023-05-25 11:52:22,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:22,481:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:22,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:22,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:52:22,547:INFO:setup() successfully completed in 7.62s...............
2023-05-25 11:52:26,517:INFO:Initializing compare_models()
2023-05-25 11:52:26,517:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-25 11:52:26,517:INFO:Checking exceptions
2023-05-25 11:52:26,562:INFO:Preparing display monitor
2023-05-25 11:52:26,591:INFO:Initializing Logistic Regression
2023-05-25 11:52:26,591:INFO:Total runtime is 0.0 minutes
2023-05-25 11:52:26,595:INFO:SubProcess create_model() called ==================================
2023-05-25 11:52:26,596:INFO:Initializing create_model()
2023-05-25 11:52:26,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285A1483A30>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:52:26,596:INFO:Checking exceptions
2023-05-25 11:52:26,596:INFO:Importing libraries
2023-05-25 11:52:26,597:INFO:Copying training dataset
2023-05-25 11:52:26,755:INFO:Defining folds
2023-05-25 11:52:26,755:INFO:Declaring metric variables
2023-05-25 11:52:26,763:INFO:Importing untrained model
2023-05-25 11:52:26,770:INFO:Logistic Regression Imported successfully
2023-05-25 11:52:26,777:INFO:Starting cross validation
2023-05-25 11:52:26,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:53:45,189:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:53:45,838:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:53:46,222:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:53:46,511:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:53:50,243:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:53:50,777:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:53:52,217:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:53:52,442:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:54:16,458:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:54:16,493:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 11:54:17,467:INFO:Calculating mean and std
2023-05-25 11:54:17,469:INFO:Creating metrics dataframe
2023-05-25 11:54:17,949:INFO:Uploading results into container
2023-05-25 11:54:17,949:INFO:Uploading model into container now
2023-05-25 11:54:17,950:INFO:_master_model_container: 1
2023-05-25 11:54:17,950:INFO:_display_container: 2
2023-05-25 11:54:17,950:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-25 11:54:17,951:INFO:create_model() successfully completed......................................
2023-05-25 11:54:18,097:INFO:SubProcess create_model() end ==================================
2023-05-25 11:54:18,097:INFO:Creating metrics dataframe
2023-05-25 11:54:18,107:INFO:Initializing K Neighbors Classifier
2023-05-25 11:54:18,109:INFO:Total runtime is 1.8586316665013631 minutes
2023-05-25 11:54:18,112:INFO:SubProcess create_model() called ==================================
2023-05-25 11:54:18,112:INFO:Initializing create_model()
2023-05-25 11:54:18,112:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285A1483A30>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:54:18,112:INFO:Checking exceptions
2023-05-25 11:54:18,112:INFO:Importing libraries
2023-05-25 11:54:18,112:INFO:Copying training dataset
2023-05-25 11:54:18,189:INFO:Defining folds
2023-05-25 11:54:18,190:INFO:Declaring metric variables
2023-05-25 11:54:18,195:INFO:Importing untrained model
2023-05-25 11:54:18,199:INFO:K Neighbors Classifier Imported successfully
2023-05-25 11:54:18,207:INFO:Starting cross validation
2023-05-25 11:54:18,218:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:54:20,704:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:54:21,256:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:54:21,385:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:54:21,589:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:54:21,627:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 11:54:39,663:INFO:Calculating mean and std
2023-05-25 11:54:39,664:INFO:Creating metrics dataframe
2023-05-25 11:54:40,147:INFO:Uploading results into container
2023-05-25 11:54:40,147:INFO:Uploading model into container now
2023-05-25 11:54:40,148:INFO:_master_model_container: 2
2023-05-25 11:54:40,148:INFO:_display_container: 2
2023-05-25 11:54:40,148:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-25 11:54:40,149:INFO:create_model() successfully completed......................................
2023-05-25 11:54:40,314:INFO:SubProcess create_model() end ==================================
2023-05-25 11:54:40,315:INFO:Creating metrics dataframe
2023-05-25 11:54:40,327:INFO:Initializing Naive Bayes
2023-05-25 11:54:40,327:INFO:Total runtime is 2.2289451122283936 minutes
2023-05-25 11:54:40,345:INFO:SubProcess create_model() called ==================================
2023-05-25 11:54:40,346:INFO:Initializing create_model()
2023-05-25 11:54:40,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285A1483A30>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:54:40,346:INFO:Checking exceptions
2023-05-25 11:54:40,346:INFO:Importing libraries
2023-05-25 11:54:40,346:INFO:Copying training dataset
2023-05-25 11:54:40,424:INFO:Defining folds
2023-05-25 11:54:40,424:INFO:Declaring metric variables
2023-05-25 11:54:40,427:INFO:Importing untrained model
2023-05-25 11:54:40,432:INFO:Naive Bayes Imported successfully
2023-05-25 11:54:40,441:INFO:Starting cross validation
2023-05-25 11:54:40,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:54:48,885:INFO:Calculating mean and std
2023-05-25 11:54:48,887:INFO:Creating metrics dataframe
2023-05-25 11:54:49,346:INFO:Uploading results into container
2023-05-25 11:54:49,348:INFO:Uploading model into container now
2023-05-25 11:54:49,348:INFO:_master_model_container: 3
2023-05-25 11:54:49,348:INFO:_display_container: 2
2023-05-25 11:54:49,349:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-25 11:54:49,349:INFO:create_model() successfully completed......................................
2023-05-25 11:54:49,513:INFO:SubProcess create_model() end ==================================
2023-05-25 11:54:49,513:INFO:Creating metrics dataframe
2023-05-25 11:54:49,522:INFO:Initializing Decision Tree Classifier
2023-05-25 11:54:49,522:INFO:Total runtime is 2.382194483280182 minutes
2023-05-25 11:54:49,527:INFO:SubProcess create_model() called ==================================
2023-05-25 11:54:49,528:INFO:Initializing create_model()
2023-05-25 11:54:49,528:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285A1483A30>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:54:49,528:INFO:Checking exceptions
2023-05-25 11:54:49,528:INFO:Importing libraries
2023-05-25 11:54:49,528:INFO:Copying training dataset
2023-05-25 11:54:49,609:INFO:Defining folds
2023-05-25 11:54:49,609:INFO:Declaring metric variables
2023-05-25 11:54:49,613:INFO:Importing untrained model
2023-05-25 11:54:49,618:INFO:Decision Tree Classifier Imported successfully
2023-05-25 11:54:49,626:INFO:Starting cross validation
2023-05-25 11:54:49,638:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:55:03,957:INFO:Calculating mean and std
2023-05-25 11:55:03,960:INFO:Creating metrics dataframe
2023-05-25 11:55:04,831:INFO:Uploading results into container
2023-05-25 11:55:04,832:INFO:Uploading model into container now
2023-05-25 11:55:04,834:INFO:_master_model_container: 4
2023-05-25 11:55:04,836:INFO:_display_container: 2
2023-05-25 11:55:04,837:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-25 11:55:04,837:INFO:create_model() successfully completed......................................
2023-05-25 11:55:05,030:INFO:SubProcess create_model() end ==================================
2023-05-25 11:55:05,030:INFO:Creating metrics dataframe
2023-05-25 11:55:05,040:INFO:Initializing SVM - Linear Kernel
2023-05-25 11:55:05,041:INFO:Total runtime is 2.640840991338094 minutes
2023-05-25 11:55:05,046:INFO:SubProcess create_model() called ==================================
2023-05-25 11:55:05,046:INFO:Initializing create_model()
2023-05-25 11:55:05,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285A1483A30>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:55:05,047:INFO:Checking exceptions
2023-05-25 11:55:05,047:INFO:Importing libraries
2023-05-25 11:55:05,047:INFO:Copying training dataset
2023-05-25 11:55:05,132:INFO:Defining folds
2023-05-25 11:55:05,132:INFO:Declaring metric variables
2023-05-25 11:55:05,140:INFO:Importing untrained model
2023-05-25 11:55:05,143:INFO:SVM - Linear Kernel Imported successfully
2023-05-25 11:55:05,150:INFO:Starting cross validation
2023-05-25 11:55:05,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:55:08,325:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:55:08,425:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:55:08,543:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:55:08,829:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:55:08,831:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:55:08,841:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:55:08,875:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:55:09,293:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:55:11,858:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:55:12,228:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:55:13,730:INFO:Calculating mean and std
2023-05-25 11:55:13,731:INFO:Creating metrics dataframe
2023-05-25 11:55:14,227:INFO:Uploading results into container
2023-05-25 11:55:14,228:INFO:Uploading model into container now
2023-05-25 11:55:14,228:INFO:_master_model_container: 5
2023-05-25 11:55:14,229:INFO:_display_container: 2
2023-05-25 11:55:14,229:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-25 11:55:14,230:INFO:create_model() successfully completed......................................
2023-05-25 11:55:14,385:INFO:SubProcess create_model() end ==================================
2023-05-25 11:55:14,385:INFO:Creating metrics dataframe
2023-05-25 11:55:14,396:INFO:Initializing Ridge Classifier
2023-05-25 11:55:14,397:INFO:Total runtime is 2.7967724879582723 minutes
2023-05-25 11:55:14,400:INFO:SubProcess create_model() called ==================================
2023-05-25 11:55:14,401:INFO:Initializing create_model()
2023-05-25 11:55:14,401:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285A1483A30>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:55:14,401:INFO:Checking exceptions
2023-05-25 11:55:14,401:INFO:Importing libraries
2023-05-25 11:55:14,401:INFO:Copying training dataset
2023-05-25 11:55:14,482:INFO:Defining folds
2023-05-25 11:55:14,483:INFO:Declaring metric variables
2023-05-25 11:55:14,487:INFO:Importing untrained model
2023-05-25 11:55:14,491:INFO:Ridge Classifier Imported successfully
2023-05-25 11:55:14,500:INFO:Starting cross validation
2023-05-25 11:55:14,512:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:55:18,013:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:55:18,029:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:55:18,041:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:55:18,083:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:55:18,102:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:55:18,152:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:55:18,197:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:55:18,221:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:55:21,230:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:55:21,233:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:55:23,267:INFO:Calculating mean and std
2023-05-25 11:55:23,268:INFO:Creating metrics dataframe
2023-05-25 11:55:23,838:INFO:Uploading results into container
2023-05-25 11:55:23,839:INFO:Uploading model into container now
2023-05-25 11:55:23,839:INFO:_master_model_container: 6
2023-05-25 11:55:23,840:INFO:_display_container: 2
2023-05-25 11:55:23,840:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-25 11:55:23,840:INFO:create_model() successfully completed......................................
2023-05-25 11:55:23,994:INFO:SubProcess create_model() end ==================================
2023-05-25 11:55:23,994:INFO:Creating metrics dataframe
2023-05-25 11:55:24,015:INFO:Initializing Random Forest Classifier
2023-05-25 11:55:24,015:INFO:Total runtime is 2.9570735096931458 minutes
2023-05-25 11:55:24,019:INFO:SubProcess create_model() called ==================================
2023-05-25 11:55:24,019:INFO:Initializing create_model()
2023-05-25 11:55:24,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285A1483A30>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:55:24,020:INFO:Checking exceptions
2023-05-25 11:55:24,020:INFO:Importing libraries
2023-05-25 11:55:24,020:INFO:Copying training dataset
2023-05-25 11:55:24,099:INFO:Defining folds
2023-05-25 11:55:24,099:INFO:Declaring metric variables
2023-05-25 11:55:24,103:INFO:Importing untrained model
2023-05-25 11:55:24,108:INFO:Random Forest Classifier Imported successfully
2023-05-25 11:55:24,116:INFO:Starting cross validation
2023-05-25 11:55:24,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:55:47,807:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 11:55:47,887:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 11:55:50,364:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 11:55:51,151:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:55:51,192:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:55:51,388:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:55:51,397:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:55:51,455:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 11:56:04,247:INFO:Calculating mean and std
2023-05-25 11:56:04,248:INFO:Creating metrics dataframe
2023-05-25 11:56:04,767:INFO:Uploading results into container
2023-05-25 11:56:04,768:INFO:Uploading model into container now
2023-05-25 11:56:04,769:INFO:_master_model_container: 7
2023-05-25 11:56:04,770:INFO:_display_container: 2
2023-05-25 11:56:04,770:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 11:56:04,770:INFO:create_model() successfully completed......................................
2023-05-25 11:56:04,944:INFO:SubProcess create_model() end ==================================
2023-05-25 11:56:04,944:INFO:Creating metrics dataframe
2023-05-25 11:56:04,967:INFO:Initializing Quadratic Discriminant Analysis
2023-05-25 11:56:04,968:INFO:Total runtime is 3.639621349175771 minutes
2023-05-25 11:56:04,974:INFO:SubProcess create_model() called ==================================
2023-05-25 11:56:04,974:INFO:Initializing create_model()
2023-05-25 11:56:04,976:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285A1483A30>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:56:04,977:INFO:Checking exceptions
2023-05-25 11:56:04,977:INFO:Importing libraries
2023-05-25 11:56:04,977:INFO:Copying training dataset
2023-05-25 11:56:05,077:INFO:Defining folds
2023-05-25 11:56:05,077:INFO:Declaring metric variables
2023-05-25 11:56:05,080:INFO:Importing untrained model
2023-05-25 11:56:05,084:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-25 11:56:05,093:INFO:Starting cross validation
2023-05-25 11:56:05,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:56:10,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:56:10,889:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:56:10,924:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:56:11,005:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:56:11,071:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:56:11,246:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:56:11,277:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:56:11,322:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:56:20,193:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:56:20,502:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 11:56:22,994:INFO:Calculating mean and std
2023-05-25 11:56:22,995:INFO:Creating metrics dataframe
2023-05-25 11:56:23,502:INFO:Uploading results into container
2023-05-25 11:56:23,503:INFO:Uploading model into container now
2023-05-25 11:56:23,503:INFO:_master_model_container: 8
2023-05-25 11:56:23,503:INFO:_display_container: 2
2023-05-25 11:56:23,504:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-25 11:56:23,504:INFO:create_model() successfully completed......................................
2023-05-25 11:56:23,662:INFO:SubProcess create_model() end ==================================
2023-05-25 11:56:23,662:INFO:Creating metrics dataframe
2023-05-25 11:56:23,684:INFO:Initializing Ada Boost Classifier
2023-05-25 11:56:23,684:INFO:Total runtime is 3.951546796162923 minutes
2023-05-25 11:56:23,689:INFO:SubProcess create_model() called ==================================
2023-05-25 11:56:23,689:INFO:Initializing create_model()
2023-05-25 11:56:23,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285A1483A30>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:56:23,690:INFO:Checking exceptions
2023-05-25 11:56:23,690:INFO:Importing libraries
2023-05-25 11:56:23,690:INFO:Copying training dataset
2023-05-25 11:56:23,772:INFO:Defining folds
2023-05-25 11:56:23,773:INFO:Declaring metric variables
2023-05-25 11:56:23,778:INFO:Importing untrained model
2023-05-25 11:56:23,782:INFO:Ada Boost Classifier Imported successfully
2023-05-25 11:56:23,790:INFO:Starting cross validation
2023-05-25 11:56:23,802:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:56:41,850:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 11:56:55,960:INFO:Calculating mean and std
2023-05-25 11:56:55,962:INFO:Creating metrics dataframe
2023-05-25 11:56:56,581:INFO:Uploading results into container
2023-05-25 11:56:56,581:INFO:Uploading model into container now
2023-05-25 11:56:56,582:INFO:_master_model_container: 9
2023-05-25 11:56:56,582:INFO:_display_container: 2
2023-05-25 11:56:56,584:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 11:56:56,584:INFO:create_model() successfully completed......................................
2023-05-25 11:56:56,742:INFO:SubProcess create_model() end ==================================
2023-05-25 11:56:56,743:INFO:Creating metrics dataframe
2023-05-25 11:56:56,753:INFO:Initializing Gradient Boosting Classifier
2023-05-25 11:56:56,755:INFO:Total runtime is 4.502723522981007 minutes
2023-05-25 11:56:56,759:INFO:SubProcess create_model() called ==================================
2023-05-25 11:56:56,759:INFO:Initializing create_model()
2023-05-25 11:56:56,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000285E67640A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000285A1483A30>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:56:56,760:INFO:Checking exceptions
2023-05-25 11:56:56,760:INFO:Importing libraries
2023-05-25 11:56:56,760:INFO:Copying training dataset
2023-05-25 11:56:56,841:INFO:Defining folds
2023-05-25 11:56:56,842:INFO:Declaring metric variables
2023-05-25 11:56:56,847:INFO:Importing untrained model
2023-05-25 11:56:56,850:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 11:56:56,859:INFO:Starting cross validation
2023-05-25 11:56:56,870:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:57:40,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 11:57:40,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 11:57:40,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 11:57:40,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 11:57:41,132:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-25 11:57:54,650:INFO:PyCaret ClassificationExperiment
2023-05-25 11:57:54,651:INFO:Logging name: clf-default-name
2023-05-25 11:57:54,651:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-25 11:57:54,651:INFO:version 3.0.2
2023-05-25 11:57:54,651:INFO:Initializing setup()
2023-05-25 11:57:54,651:INFO:self.USI: f628
2023-05-25 11:57:54,651:INFO:self._variable_keys: {'data', 'fold_shuffle_param', 'logging_param', 'X', 'seed', 'fold_generator', 'USI', 'idx', 'exp_name_log', 'y', 'y_train', 'fold_groups_param', 'is_multiclass', 'X_test', 'gpu_n_jobs_param', 'log_plots_param', 'pipeline', 'y_test', 'X_train', 'gpu_param', 'exp_id', 'target_param', '_available_plots', '_ml_usecase', 'html_param', 'memory', 'fix_imbalance', 'n_jobs_param'}
2023-05-25 11:57:54,651:INFO:Checking environment
2023-05-25 11:57:54,651:INFO:python_version: 3.10.11
2023-05-25 11:57:54,651:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-25 11:57:54,651:INFO:machine: AMD64
2023-05-25 11:57:54,651:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-25 11:57:54,654:INFO:Memory: svmem(total=16889774080, available=8428638208, percent=50.1, used=8461135872, free=8428638208)
2023-05-25 11:57:54,655:INFO:Physical Core: 4
2023-05-25 11:57:54,655:INFO:Logical Core: 8
2023-05-25 11:57:54,655:INFO:Checking libraries
2023-05-25 11:57:54,655:INFO:System:
2023-05-25 11:57:54,655:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-25 11:57:54,655:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-25 11:57:54,655:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-25 11:57:54,655:INFO:PyCaret required dependencies:
2023-05-25 11:57:54,655:INFO:                 pip: 23.0.1
2023-05-25 11:57:54,655:INFO:          setuptools: 66.0.0
2023-05-25 11:57:54,655:INFO:             pycaret: 3.0.2
2023-05-25 11:57:54,655:INFO:             IPython: 8.13.2
2023-05-25 11:57:54,655:INFO:          ipywidgets: 8.0.6
2023-05-25 11:57:54,655:INFO:                tqdm: 4.65.0
2023-05-25 11:57:54,655:INFO:               numpy: 1.23.5
2023-05-25 11:57:54,655:INFO:              pandas: 1.5.3
2023-05-25 11:57:54,655:INFO:              jinja2: 3.1.2
2023-05-25 11:57:54,656:INFO:               scipy: 1.10.1
2023-05-25 11:57:54,656:INFO:              joblib: 1.2.0
2023-05-25 11:57:54,656:INFO:             sklearn: 1.2.2
2023-05-25 11:57:54,656:INFO:                pyod: 1.0.9
2023-05-25 11:57:54,656:INFO:            imblearn: 0.10.1
2023-05-25 11:57:54,656:INFO:   category_encoders: 2.6.1
2023-05-25 11:57:54,656:INFO:            lightgbm: 3.3.5
2023-05-25 11:57:54,656:INFO:               numba: 0.57.0
2023-05-25 11:57:54,656:INFO:            requests: 2.31.0
2023-05-25 11:57:54,656:INFO:          matplotlib: 3.7.1
2023-05-25 11:57:54,656:INFO:          scikitplot: 0.3.7
2023-05-25 11:57:54,656:INFO:         yellowbrick: 1.5
2023-05-25 11:57:54,656:INFO:              plotly: 5.14.1
2023-05-25 11:57:54,656:INFO:             kaleido: 0.2.1
2023-05-25 11:57:54,656:INFO:         statsmodels: 0.14.0
2023-05-25 11:57:54,656:INFO:              sktime: 0.17.0
2023-05-25 11:57:54,656:INFO:               tbats: 1.1.3
2023-05-25 11:57:54,656:INFO:            pmdarima: 2.0.3
2023-05-25 11:57:54,656:INFO:              psutil: 5.9.5
2023-05-25 11:57:54,656:INFO:PyCaret optional dependencies:
2023-05-25 11:57:54,663:INFO:                shap: Not installed
2023-05-25 11:57:54,663:INFO:           interpret: Not installed
2023-05-25 11:57:54,663:INFO:                umap: Not installed
2023-05-25 11:57:54,663:INFO:    pandas_profiling: Not installed
2023-05-25 11:57:54,663:INFO:  explainerdashboard: Not installed
2023-05-25 11:57:54,663:INFO:             autoviz: Not installed
2023-05-25 11:57:54,663:INFO:           fairlearn: Not installed
2023-05-25 11:57:54,663:INFO:             xgboost: Not installed
2023-05-25 11:57:54,663:INFO:            catboost: Not installed
2023-05-25 11:57:54,663:INFO:              kmodes: Not installed
2023-05-25 11:57:54,663:INFO:             mlxtend: Not installed
2023-05-25 11:57:54,663:INFO:       statsforecast: Not installed
2023-05-25 11:57:54,663:INFO:        tune_sklearn: 0.4.5
2023-05-25 11:57:54,663:INFO:                 ray: 2.4.0
2023-05-25 11:57:54,663:INFO:            hyperopt: 0.2.7
2023-05-25 11:57:54,664:INFO:              optuna: 3.1.1
2023-05-25 11:57:54,664:INFO:               skopt: 0.9.0
2023-05-25 11:57:54,664:INFO:              mlflow: Not installed
2023-05-25 11:57:54,664:INFO:              gradio: Not installed
2023-05-25 11:57:54,664:INFO:             fastapi: Not installed
2023-05-25 11:57:54,664:INFO:             uvicorn: Not installed
2023-05-25 11:57:54,664:INFO:              m2cgen: Not installed
2023-05-25 11:57:54,664:INFO:           evidently: Not installed
2023-05-25 11:57:54,664:INFO:               fugue: Not installed
2023-05-25 11:57:54,664:INFO:           streamlit: Not installed
2023-05-25 11:57:54,664:INFO:             prophet: Not installed
2023-05-25 11:57:54,664:INFO:None
2023-05-25 11:57:54,664:INFO:Set up data.
2023-05-25 11:57:54,858:INFO:Set up train/test split.
2023-05-25 11:57:54,961:INFO:Set up index.
2023-05-25 11:57:54,964:INFO:Set up folding strategy.
2023-05-25 11:57:54,964:INFO:Assigning column types.
2023-05-25 11:57:55,016:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-25 11:57:55,052:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 11:57:55,056:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:57:55,089:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,156:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 11:57:55,156:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:57:55,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,181:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-25 11:57:55,219:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:57:55,242:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,242:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,281:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 11:57:55,315:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,316:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,316:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-25 11:57:55,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,456:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,456:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:55,458:INFO:Preparing preprocessing pipeline...
2023-05-25 11:57:55,464:INFO:Set up label encoding.
2023-05-25 11:57:55,464:INFO:Set up simple imputation.
2023-05-25 11:57:55,464:INFO:Set up imbalanced handling.
2023-05-25 11:57:55,469:INFO:Set up column name cleaning.
2023-05-25 11:57:56,178:INFO:Finished creating preprocessing pipeline.
2023-05-25 11:57:56,201:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-25 11:57:56,201:INFO:Creating final display dataframe.
2023-05-25 11:57:57,704:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 511)
5        Transformed data shape              (41153, 511)
6   Transformed train set shape              (30052, 511)
7    Transformed test set shape              (11101, 511)
8              Numeric features                       510
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      f628
2023-05-25 11:57:57,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:57,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:57,843:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:57,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 11:57:57,844:INFO:setup() successfully completed in 3.56s...............
2023-05-25 11:57:57,886:INFO:Initializing compare_models()
2023-05-25 11:57:57,886:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-25 11:57:57,887:INFO:Checking exceptions
2023-05-25 11:57:57,934:INFO:Preparing display monitor
2023-05-25 11:57:57,960:INFO:Initializing Logistic Regression
2023-05-25 11:57:57,960:INFO:Total runtime is 0.0 minutes
2023-05-25 11:57:57,965:INFO:SubProcess create_model() called ==================================
2023-05-25 11:57:57,965:INFO:Initializing create_model()
2023-05-25 11:57:57,965:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:57:57,965:INFO:Checking exceptions
2023-05-25 11:57:57,966:INFO:Importing libraries
2023-05-25 11:57:57,966:INFO:Copying training dataset
2023-05-25 11:57:58,067:INFO:Defining folds
2023-05-25 11:57:58,067:INFO:Declaring metric variables
2023-05-25 11:57:58,072:INFO:Importing untrained model
2023-05-25 11:57:58,076:INFO:Logistic Regression Imported successfully
2023-05-25 11:57:58,085:INFO:Starting cross validation
2023-05-25 11:57:58,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:58:09,468:INFO:Calculating mean and std
2023-05-25 11:58:09,469:INFO:Creating metrics dataframe
2023-05-25 11:58:09,958:INFO:Uploading results into container
2023-05-25 11:58:09,959:INFO:Uploading model into container now
2023-05-25 11:58:09,959:INFO:_master_model_container: 1
2023-05-25 11:58:09,959:INFO:_display_container: 2
2023-05-25 11:58:09,959:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-25 11:58:09,959:INFO:create_model() successfully completed......................................
2023-05-25 11:58:10,029:INFO:SubProcess create_model() end ==================================
2023-05-25 11:58:10,030:INFO:Creating metrics dataframe
2023-05-25 11:58:10,039:INFO:Initializing K Neighbors Classifier
2023-05-25 11:58:10,039:INFO:Total runtime is 0.2013149897257487 minutes
2023-05-25 11:58:10,043:INFO:SubProcess create_model() called ==================================
2023-05-25 11:58:10,043:INFO:Initializing create_model()
2023-05-25 11:58:10,043:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:58:10,043:INFO:Checking exceptions
2023-05-25 11:58:10,043:INFO:Importing libraries
2023-05-25 11:58:10,043:INFO:Copying training dataset
2023-05-25 11:58:10,118:INFO:Defining folds
2023-05-25 11:58:10,118:INFO:Declaring metric variables
2023-05-25 11:58:10,123:INFO:Importing untrained model
2023-05-25 11:58:10,128:INFO:K Neighbors Classifier Imported successfully
2023-05-25 11:58:10,136:INFO:Starting cross validation
2023-05-25 11:58:10,140:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:58:29,149:INFO:Calculating mean and std
2023-05-25 11:58:29,150:INFO:Creating metrics dataframe
2023-05-25 11:58:29,750:INFO:Uploading results into container
2023-05-25 11:58:29,750:INFO:Uploading model into container now
2023-05-25 11:58:29,750:INFO:_master_model_container: 2
2023-05-25 11:58:29,750:INFO:_display_container: 2
2023-05-25 11:58:29,750:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-25 11:58:29,750:INFO:create_model() successfully completed......................................
2023-05-25 11:58:29,819:INFO:SubProcess create_model() end ==================================
2023-05-25 11:58:29,819:INFO:Creating metrics dataframe
2023-05-25 11:58:29,832:INFO:Initializing Naive Bayes
2023-05-25 11:58:29,832:INFO:Total runtime is 0.5312094648679098 minutes
2023-05-25 11:58:29,836:INFO:SubProcess create_model() called ==================================
2023-05-25 11:58:29,836:INFO:Initializing create_model()
2023-05-25 11:58:29,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:58:29,837:INFO:Checking exceptions
2023-05-25 11:58:29,837:INFO:Importing libraries
2023-05-25 11:58:29,837:INFO:Copying training dataset
2023-05-25 11:58:29,908:INFO:Defining folds
2023-05-25 11:58:29,908:INFO:Declaring metric variables
2023-05-25 11:58:29,912:INFO:Importing untrained model
2023-05-25 11:58:29,916:INFO:Naive Bayes Imported successfully
2023-05-25 11:58:29,924:INFO:Starting cross validation
2023-05-25 11:58:29,927:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:58:36,450:INFO:Calculating mean and std
2023-05-25 11:58:36,451:INFO:Creating metrics dataframe
2023-05-25 11:58:36,936:INFO:Uploading results into container
2023-05-25 11:58:36,936:INFO:Uploading model into container now
2023-05-25 11:58:36,937:INFO:_master_model_container: 3
2023-05-25 11:58:36,937:INFO:_display_container: 2
2023-05-25 11:58:36,937:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-25 11:58:36,937:INFO:create_model() successfully completed......................................
2023-05-25 11:58:37,010:INFO:SubProcess create_model() end ==================================
2023-05-25 11:58:37,010:INFO:Creating metrics dataframe
2023-05-25 11:58:37,019:INFO:Initializing Decision Tree Classifier
2023-05-25 11:58:37,019:INFO:Total runtime is 0.650982932249705 minutes
2023-05-25 11:58:37,024:INFO:SubProcess create_model() called ==================================
2023-05-25 11:58:37,024:INFO:Initializing create_model()
2023-05-25 11:58:37,024:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:58:37,024:INFO:Checking exceptions
2023-05-25 11:58:37,024:INFO:Importing libraries
2023-05-25 11:58:37,024:INFO:Copying training dataset
2023-05-25 11:58:37,095:INFO:Defining folds
2023-05-25 11:58:37,095:INFO:Declaring metric variables
2023-05-25 11:58:37,098:INFO:Importing untrained model
2023-05-25 11:58:37,102:INFO:Decision Tree Classifier Imported successfully
2023-05-25 11:58:37,110:INFO:Starting cross validation
2023-05-25 11:58:37,114:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:58:43,277:INFO:Calculating mean and std
2023-05-25 11:58:43,278:INFO:Creating metrics dataframe
2023-05-25 11:58:43,812:INFO:Uploading results into container
2023-05-25 11:58:43,813:INFO:Uploading model into container now
2023-05-25 11:58:43,814:INFO:_master_model_container: 4
2023-05-25 11:58:43,814:INFO:_display_container: 2
2023-05-25 11:58:43,814:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-25 11:58:43,815:INFO:create_model() successfully completed......................................
2023-05-25 11:58:43,887:INFO:SubProcess create_model() end ==================================
2023-05-25 11:58:43,887:INFO:Creating metrics dataframe
2023-05-25 11:58:43,898:INFO:Initializing SVM - Linear Kernel
2023-05-25 11:58:43,898:INFO:Total runtime is 0.7656319499015809 minutes
2023-05-25 11:58:43,901:INFO:SubProcess create_model() called ==================================
2023-05-25 11:58:43,901:INFO:Initializing create_model()
2023-05-25 11:58:43,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:58:43,901:INFO:Checking exceptions
2023-05-25 11:58:43,901:INFO:Importing libraries
2023-05-25 11:58:43,901:INFO:Copying training dataset
2023-05-25 11:58:43,973:INFO:Defining folds
2023-05-25 11:58:43,973:INFO:Declaring metric variables
2023-05-25 11:58:43,977:INFO:Importing untrained model
2023-05-25 11:58:43,981:INFO:SVM - Linear Kernel Imported successfully
2023-05-25 11:58:43,991:INFO:Starting cross validation
2023-05-25 11:58:43,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:58:45,421:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:58:45,500:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:58:45,525:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:58:45,542:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:58:45,554:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:58:45,582:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:58:45,677:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:58:45,724:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:58:47,717:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:58:47,844:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 11:58:50,273:INFO:Calculating mean and std
2023-05-25 11:58:50,276:INFO:Creating metrics dataframe
2023-05-25 11:58:50,883:INFO:Uploading results into container
2023-05-25 11:58:50,883:INFO:Uploading model into container now
2023-05-25 11:58:50,884:INFO:_master_model_container: 5
2023-05-25 11:58:50,884:INFO:_display_container: 2
2023-05-25 11:58:50,886:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-25 11:58:50,886:INFO:create_model() successfully completed......................................
2023-05-25 11:58:50,968:INFO:SubProcess create_model() end ==================================
2023-05-25 11:58:50,968:INFO:Creating metrics dataframe
2023-05-25 11:58:50,980:INFO:Initializing Ridge Classifier
2023-05-25 11:58:50,980:INFO:Total runtime is 0.8836805820465089 minutes
2023-05-25 11:58:50,984:INFO:SubProcess create_model() called ==================================
2023-05-25 11:58:50,984:INFO:Initializing create_model()
2023-05-25 11:58:50,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:58:50,984:INFO:Checking exceptions
2023-05-25 11:58:50,984:INFO:Importing libraries
2023-05-25 11:58:50,984:INFO:Copying training dataset
2023-05-25 11:58:51,068:INFO:Defining folds
2023-05-25 11:58:51,068:INFO:Declaring metric variables
2023-05-25 11:58:51,073:INFO:Importing untrained model
2023-05-25 11:58:51,078:INFO:Ridge Classifier Imported successfully
2023-05-25 11:58:51,086:INFO:Starting cross validation
2023-05-25 11:58:51,102:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:58:52,667:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:58:52,675:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:58:52,714:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:58:52,728:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:58:52,730:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:58:52,800:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:58:52,835:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:58:52,891:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:58:55,176:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:58:55,303:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 11:58:58,354:INFO:Calculating mean and std
2023-05-25 11:58:58,357:INFO:Creating metrics dataframe
2023-05-25 11:58:59,060:INFO:Uploading results into container
2023-05-25 11:58:59,062:INFO:Uploading model into container now
2023-05-25 11:58:59,063:INFO:_master_model_container: 6
2023-05-25 11:58:59,063:INFO:_display_container: 2
2023-05-25 11:58:59,064:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-25 11:58:59,064:INFO:create_model() successfully completed......................................
2023-05-25 11:58:59,153:INFO:SubProcess create_model() end ==================================
2023-05-25 11:58:59,153:INFO:Creating metrics dataframe
2023-05-25 11:58:59,166:INFO:Initializing Random Forest Classifier
2023-05-25 11:58:59,166:INFO:Total runtime is 1.0201077461242676 minutes
2023-05-25 11:58:59,171:INFO:SubProcess create_model() called ==================================
2023-05-25 11:58:59,171:INFO:Initializing create_model()
2023-05-25 11:58:59,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:58:59,171:INFO:Checking exceptions
2023-05-25 11:58:59,171:INFO:Importing libraries
2023-05-25 11:58:59,171:INFO:Copying training dataset
2023-05-25 11:58:59,254:INFO:Defining folds
2023-05-25 11:58:59,254:INFO:Declaring metric variables
2023-05-25 11:58:59,258:INFO:Importing untrained model
2023-05-25 11:58:59,264:INFO:Random Forest Classifier Imported successfully
2023-05-25 11:58:59,272:INFO:Starting cross validation
2023-05-25 11:58:59,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:59:07,808:INFO:Calculating mean and std
2023-05-25 11:59:07,809:INFO:Creating metrics dataframe
2023-05-25 11:59:08,569:INFO:Uploading results into container
2023-05-25 11:59:08,571:INFO:Uploading model into container now
2023-05-25 11:59:08,572:INFO:_master_model_container: 7
2023-05-25 11:59:08,573:INFO:_display_container: 2
2023-05-25 11:59:08,574:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 11:59:08,574:INFO:create_model() successfully completed......................................
2023-05-25 11:59:08,650:INFO:SubProcess create_model() end ==================================
2023-05-25 11:59:08,650:INFO:Creating metrics dataframe
2023-05-25 11:59:08,659:INFO:Initializing Quadratic Discriminant Analysis
2023-05-25 11:59:08,659:INFO:Total runtime is 1.1783305644989013 minutes
2023-05-25 11:59:08,663:INFO:SubProcess create_model() called ==================================
2023-05-25 11:59:08,663:INFO:Initializing create_model()
2023-05-25 11:59:08,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:59:08,663:INFO:Checking exceptions
2023-05-25 11:59:08,663:INFO:Importing libraries
2023-05-25 11:59:08,663:INFO:Copying training dataset
2023-05-25 11:59:08,736:INFO:Defining folds
2023-05-25 11:59:08,736:INFO:Declaring metric variables
2023-05-25 11:59:08,740:INFO:Importing untrained model
2023-05-25 11:59:08,745:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-25 11:59:08,751:INFO:Starting cross validation
2023-05-25 11:59:08,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:59:15,170:INFO:Calculating mean and std
2023-05-25 11:59:15,171:INFO:Creating metrics dataframe
2023-05-25 11:59:15,637:INFO:Uploading results into container
2023-05-25 11:59:15,638:INFO:Uploading model into container now
2023-05-25 11:59:15,639:INFO:_master_model_container: 8
2023-05-25 11:59:15,639:INFO:_display_container: 2
2023-05-25 11:59:15,639:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-25 11:59:15,639:INFO:create_model() successfully completed......................................
2023-05-25 11:59:15,709:INFO:SubProcess create_model() end ==================================
2023-05-25 11:59:15,709:INFO:Creating metrics dataframe
2023-05-25 11:59:15,720:INFO:Initializing Ada Boost Classifier
2023-05-25 11:59:15,720:INFO:Total runtime is 1.296007752418518 minutes
2023-05-25 11:59:15,725:INFO:SubProcess create_model() called ==================================
2023-05-25 11:59:15,726:INFO:Initializing create_model()
2023-05-25 11:59:15,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:59:15,726:INFO:Checking exceptions
2023-05-25 11:59:15,726:INFO:Importing libraries
2023-05-25 11:59:15,726:INFO:Copying training dataset
2023-05-25 11:59:15,796:INFO:Defining folds
2023-05-25 11:59:15,796:INFO:Declaring metric variables
2023-05-25 11:59:15,800:INFO:Importing untrained model
2023-05-25 11:59:15,804:INFO:Ada Boost Classifier Imported successfully
2023-05-25 11:59:15,812:INFO:Starting cross validation
2023-05-25 11:59:15,815:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 11:59:22,915:INFO:Calculating mean and std
2023-05-25 11:59:22,916:INFO:Creating metrics dataframe
2023-05-25 11:59:23,390:INFO:Uploading results into container
2023-05-25 11:59:23,391:INFO:Uploading model into container now
2023-05-25 11:59:23,392:INFO:_master_model_container: 9
2023-05-25 11:59:23,392:INFO:_display_container: 2
2023-05-25 11:59:23,392:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 11:59:23,393:INFO:create_model() successfully completed......................................
2023-05-25 11:59:23,464:INFO:SubProcess create_model() end ==================================
2023-05-25 11:59:23,464:INFO:Creating metrics dataframe
2023-05-25 11:59:23,474:INFO:Initializing Gradient Boosting Classifier
2023-05-25 11:59:23,474:INFO:Total runtime is 1.4252408027648926 minutes
2023-05-25 11:59:23,478:INFO:SubProcess create_model() called ==================================
2023-05-25 11:59:23,478:INFO:Initializing create_model()
2023-05-25 11:59:23,478:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 11:59:23,478:INFO:Checking exceptions
2023-05-25 11:59:23,478:INFO:Importing libraries
2023-05-25 11:59:23,478:INFO:Copying training dataset
2023-05-25 11:59:23,548:INFO:Defining folds
2023-05-25 11:59:23,548:INFO:Declaring metric variables
2023-05-25 11:59:23,552:INFO:Importing untrained model
2023-05-25 11:59:23,556:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 11:59:23,563:INFO:Starting cross validation
2023-05-25 11:59:23,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:00:15,639:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:00:15,927:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:00:50,329:INFO:Calculating mean and std
2023-05-25 12:00:50,330:INFO:Creating metrics dataframe
2023-05-25 12:00:50,767:INFO:Uploading results into container
2023-05-25 12:00:50,768:INFO:Uploading model into container now
2023-05-25 12:00:50,768:INFO:_master_model_container: 10
2023-05-25 12:00:50,768:INFO:_display_container: 2
2023-05-25 12:00:50,769:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 12:00:50,769:INFO:create_model() successfully completed......................................
2023-05-25 12:00:50,840:INFO:SubProcess create_model() end ==================================
2023-05-25 12:00:50,840:INFO:Creating metrics dataframe
2023-05-25 12:00:50,881:INFO:Initializing Linear Discriminant Analysis
2023-05-25 12:00:50,881:INFO:Total runtime is 2.882017234961192 minutes
2023-05-25 12:00:50,888:INFO:SubProcess create_model() called ==================================
2023-05-25 12:00:50,889:INFO:Initializing create_model()
2023-05-25 12:00:50,889:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:00:50,889:INFO:Checking exceptions
2023-05-25 12:00:50,889:INFO:Importing libraries
2023-05-25 12:00:50,889:INFO:Copying training dataset
2023-05-25 12:00:51,020:INFO:Defining folds
2023-05-25 12:00:51,021:INFO:Declaring metric variables
2023-05-25 12:00:51,025:INFO:Importing untrained model
2023-05-25 12:00:51,030:INFO:Linear Discriminant Analysis Imported successfully
2023-05-25 12:00:51,035:INFO:Starting cross validation
2023-05-25 12:00:51,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:01:13,860:INFO:Calculating mean and std
2023-05-25 12:01:13,860:INFO:Creating metrics dataframe
2023-05-25 12:01:15,284:INFO:Uploading results into container
2023-05-25 12:01:15,284:INFO:Uploading model into container now
2023-05-25 12:01:15,284:INFO:_master_model_container: 11
2023-05-25 12:01:15,284:INFO:_display_container: 2
2023-05-25 12:01:15,284:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-25 12:01:15,284:INFO:create_model() successfully completed......................................
2023-05-25 12:01:15,394:INFO:SubProcess create_model() end ==================================
2023-05-25 12:01:15,394:INFO:Creating metrics dataframe
2023-05-25 12:01:15,425:INFO:Initializing Extra Trees Classifier
2023-05-25 12:01:15,425:INFO:Total runtime is 3.291091783841451 minutes
2023-05-25 12:01:15,441:INFO:SubProcess create_model() called ==================================
2023-05-25 12:01:15,441:INFO:Initializing create_model()
2023-05-25 12:01:15,441:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:01:15,441:INFO:Checking exceptions
2023-05-25 12:01:15,441:INFO:Importing libraries
2023-05-25 12:01:15,441:INFO:Copying training dataset
2023-05-25 12:01:15,566:INFO:Defining folds
2023-05-25 12:01:15,566:INFO:Declaring metric variables
2023-05-25 12:01:15,581:INFO:Importing untrained model
2023-05-25 12:01:15,581:INFO:Extra Trees Classifier Imported successfully
2023-05-25 12:01:15,613:INFO:Starting cross validation
2023-05-25 12:01:15,629:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:02:03,422:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:02:05,522:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:02:05,647:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:02:05,672:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:02:05,898:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:02:20,333:INFO:Calculating mean and std
2023-05-25 12:02:20,334:INFO:Creating metrics dataframe
2023-05-25 12:02:20,921:INFO:Uploading results into container
2023-05-25 12:02:20,922:INFO:Uploading model into container now
2023-05-25 12:02:20,922:INFO:_master_model_container: 12
2023-05-25 12:02:20,922:INFO:_display_container: 2
2023-05-25 12:02:20,923:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 12:02:20,923:INFO:create_model() successfully completed......................................
2023-05-25 12:02:20,995:INFO:SubProcess create_model() end ==================================
2023-05-25 12:02:20,995:INFO:Creating metrics dataframe
2023-05-25 12:02:21,007:INFO:Initializing Light Gradient Boosting Machine
2023-05-25 12:02:21,007:INFO:Total runtime is 4.384117964903513 minutes
2023-05-25 12:02:21,012:INFO:SubProcess create_model() called ==================================
2023-05-25 12:02:21,013:INFO:Initializing create_model()
2023-05-25 12:02:21,013:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:02:21,013:INFO:Checking exceptions
2023-05-25 12:02:21,013:INFO:Importing libraries
2023-05-25 12:02:21,013:INFO:Copying training dataset
2023-05-25 12:02:21,084:INFO:Defining folds
2023-05-25 12:02:21,084:INFO:Declaring metric variables
2023-05-25 12:02:21,087:INFO:Importing untrained model
2023-05-25 12:02:21,092:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 12:02:21,100:INFO:Starting cross validation
2023-05-25 12:02:21,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:02:34,466:INFO:Calculating mean and std
2023-05-25 12:02:34,467:INFO:Creating metrics dataframe
2023-05-25 12:02:35,054:INFO:Uploading results into container
2023-05-25 12:02:35,054:INFO:Uploading model into container now
2023-05-25 12:02:35,054:INFO:_master_model_container: 13
2023-05-25 12:02:35,055:INFO:_display_container: 2
2023-05-25 12:02:35,055:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 12:02:35,055:INFO:create_model() successfully completed......................................
2023-05-25 12:02:35,129:INFO:SubProcess create_model() end ==================================
2023-05-25 12:02:35,129:INFO:Creating metrics dataframe
2023-05-25 12:02:35,140:INFO:Initializing Dummy Classifier
2023-05-25 12:02:35,140:INFO:Total runtime is 4.6196769277254734 minutes
2023-05-25 12:02:35,146:INFO:SubProcess create_model() called ==================================
2023-05-25 12:02:35,146:INFO:Initializing create_model()
2023-05-25 12:02:35,146:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000230DCDD09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:02:35,146:INFO:Checking exceptions
2023-05-25 12:02:35,146:INFO:Importing libraries
2023-05-25 12:02:35,146:INFO:Copying training dataset
2023-05-25 12:02:35,215:INFO:Defining folds
2023-05-25 12:02:35,215:INFO:Declaring metric variables
2023-05-25 12:02:35,219:INFO:Importing untrained model
2023-05-25 12:02:35,223:INFO:Dummy Classifier Imported successfully
2023-05-25 12:02:35,231:INFO:Starting cross validation
2023-05-25 12:02:35,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:02:37,089:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:02:37,143:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:02:37,206:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:02:37,222:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:02:37,236:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:02:37,272:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:02:37,305:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:02:37,335:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:02:39,781:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:02:39,823:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:02:42,247:INFO:Calculating mean and std
2023-05-25 12:02:42,247:INFO:Creating metrics dataframe
2023-05-25 12:02:42,779:INFO:Uploading results into container
2023-05-25 12:02:42,780:INFO:Uploading model into container now
2023-05-25 12:02:42,780:INFO:_master_model_container: 14
2023-05-25 12:02:42,780:INFO:_display_container: 2
2023-05-25 12:02:42,781:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-25 12:02:42,781:INFO:create_model() successfully completed......................................
2023-05-25 12:02:42,852:INFO:SubProcess create_model() end ==================================
2023-05-25 12:02:42,852:INFO:Creating metrics dataframe
2023-05-25 12:02:42,872:INFO:Initializing create_model()
2023-05-25 12:02:42,872:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:02:42,872:INFO:Checking exceptions
2023-05-25 12:02:42,874:INFO:Importing libraries
2023-05-25 12:02:42,875:INFO:Copying training dataset
2023-05-25 12:02:42,943:INFO:Defining folds
2023-05-25 12:02:42,943:INFO:Declaring metric variables
2023-05-25 12:02:42,943:INFO:Importing untrained model
2023-05-25 12:02:42,944:INFO:Declaring custom model
2023-05-25 12:02:42,945:INFO:Random Forest Classifier Imported successfully
2023-05-25 12:02:42,947:INFO:Cross validation set to False
2023-05-25 12:02:42,947:INFO:Fitting Model
2023-05-25 12:02:47,497:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 12:02:47,497:INFO:create_model() successfully completed......................................
2023-05-25 12:02:47,575:INFO:Initializing create_model()
2023-05-25 12:02:47,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:02:47,575:INFO:Checking exceptions
2023-05-25 12:02:47,576:INFO:Importing libraries
2023-05-25 12:02:47,576:INFO:Copying training dataset
2023-05-25 12:02:47,650:INFO:Defining folds
2023-05-25 12:02:47,650:INFO:Declaring metric variables
2023-05-25 12:02:47,650:INFO:Importing untrained model
2023-05-25 12:02:47,651:INFO:Declaring custom model
2023-05-25 12:02:47,651:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 12:02:47,654:INFO:Cross validation set to False
2023-05-25 12:02:47,654:INFO:Fitting Model
2023-05-25 12:02:49,995:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 12:02:49,996:INFO:create_model() successfully completed......................................
2023-05-25 12:02:50,070:INFO:Initializing create_model()
2023-05-25 12:02:50,070:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:02:50,071:INFO:Checking exceptions
2023-05-25 12:02:50,073:INFO:Importing libraries
2023-05-25 12:02:50,073:INFO:Copying training dataset
2023-05-25 12:02:50,147:INFO:Defining folds
2023-05-25 12:02:50,147:INFO:Declaring metric variables
2023-05-25 12:02:50,147:INFO:Importing untrained model
2023-05-25 12:02:50,147:INFO:Declaring custom model
2023-05-25 12:02:50,148:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 12:02:50,150:INFO:Cross validation set to False
2023-05-25 12:02:50,150:INFO:Fitting Model
2023-05-25 12:03:15,459:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 12:03:15,459:INFO:create_model() successfully completed......................................
2023-05-25 12:03:15,535:INFO:Initializing create_model()
2023-05-25 12:03:15,535:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:03:15,535:INFO:Checking exceptions
2023-05-25 12:03:15,538:INFO:Importing libraries
2023-05-25 12:03:15,538:INFO:Copying training dataset
2023-05-25 12:03:15,609:INFO:Defining folds
2023-05-25 12:03:15,609:INFO:Declaring metric variables
2023-05-25 12:03:15,609:INFO:Importing untrained model
2023-05-25 12:03:15,609:INFO:Declaring custom model
2023-05-25 12:03:15,609:INFO:Ada Boost Classifier Imported successfully
2023-05-25 12:03:15,613:INFO:Cross validation set to False
2023-05-25 12:03:15,613:INFO:Fitting Model
2023-05-25 12:03:23,791:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 12:03:23,791:INFO:create_model() successfully completed......................................
2023-05-25 12:03:23,868:INFO:Initializing create_model()
2023-05-25 12:03:23,868:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:03:23,868:INFO:Checking exceptions
2023-05-25 12:03:23,870:INFO:Importing libraries
2023-05-25 12:03:23,870:INFO:Copying training dataset
2023-05-25 12:03:23,941:INFO:Defining folds
2023-05-25 12:03:23,941:INFO:Declaring metric variables
2023-05-25 12:03:23,941:INFO:Importing untrained model
2023-05-25 12:03:23,941:INFO:Declaring custom model
2023-05-25 12:03:23,942:INFO:Extra Trees Classifier Imported successfully
2023-05-25 12:03:23,944:INFO:Cross validation set to False
2023-05-25 12:03:23,946:INFO:Fitting Model
2023-05-25 12:03:30,898:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 12:03:30,898:INFO:create_model() successfully completed......................................
2023-05-25 12:03:31,038:INFO:_master_model_container: 14
2023-05-25 12:03:31,038:INFO:_display_container: 2
2023-05-25 12:03:31,039:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)]
2023-05-25 12:03:31,040:INFO:compare_models() successfully completed......................................
2023-05-25 12:03:31,372:INFO:Initializing predict_model()
2023-05-25 12:03:31,372:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)], probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002308C346F80>)
2023-05-25 12:03:31,372:INFO:Checking exceptions
2023-05-25 12:03:31,372:INFO:Preloading libraries
2023-05-25 12:03:31,376:INFO:Set up data.
2023-05-25 12:03:31,488:INFO:Set up index.
2023-05-25 12:13:19,740:INFO:Initializing predict_model()
2023-05-25 12:13:19,742:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000230B8E5ADD0>)
2023-05-25 12:13:19,742:INFO:Checking exceptions
2023-05-25 12:13:19,742:INFO:Preloading libraries
2023-05-25 12:13:19,744:INFO:Set up data.
2023-05-25 12:13:19,901:INFO:Set up index.
2023-05-25 12:19:04,841:INFO:Initializing predict_model()
2023-05-25 12:19:04,842:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000230943F6F80>)
2023-05-25 12:19:04,842:INFO:Checking exceptions
2023-05-25 12:19:04,842:INFO:Preloading libraries
2023-05-25 12:19:04,843:INFO:Set up data.
2023-05-25 12:19:04,972:INFO:Set up index.
2023-05-25 12:19:05,455:INFO:Initializing tune_model()
2023-05-25 12:19:05,455:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000230E24BA680>)
2023-05-25 12:19:05,455:INFO:Checking exceptions
2023-05-25 12:19:05,455:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-25 12:19:05,913:INFO:Copying training dataset
2023-05-25 12:19:06,004:INFO:Checking base model
2023-05-25 12:19:06,004:INFO:Base model : Random Forest Classifier
2023-05-25 12:19:06,012:INFO:Declaring metric variables
2023-05-25 12:19:06,020:INFO:Defining Hyperparameters
2023-05-25 12:19:06,183:INFO:Tuning with n_jobs=-1
2023-05-25 12:19:06,186:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 12:19:06,186:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 12:19:06,187:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-05-25 12:19:06,187:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-25 12:19:06,190:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-25 12:22:02,981:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:22:20,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 12:22:20,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 12:22:20,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 12:22:20,269:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 12:22:21,008:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-25 12:22:34,080:INFO:PyCaret ClassificationExperiment
2023-05-25 12:22:34,080:INFO:Logging name: clf-default-name
2023-05-25 12:22:34,080:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-25 12:22:34,080:INFO:version 3.0.2
2023-05-25 12:22:34,080:INFO:Initializing setup()
2023-05-25 12:22:34,080:INFO:self.USI: a4a2
2023-05-25 12:22:34,080:INFO:self._variable_keys: {'y', 'exp_id', 'X_train', 'pipeline', '_available_plots', 'idx', 'X_test', 'fix_imbalance', 'log_plots_param', 'fold_generator', 'data', 'html_param', 'is_multiclass', 'target_param', 'logging_param', 'seed', 'n_jobs_param', 'y_train', 'exp_name_log', 'X', 'USI', 'gpu_n_jobs_param', 'gpu_param', '_ml_usecase', 'y_test', 'fold_groups_param', 'fold_shuffle_param', 'memory'}
2023-05-25 12:22:34,080:INFO:Checking environment
2023-05-25 12:22:34,080:INFO:python_version: 3.10.11
2023-05-25 12:22:34,080:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-25 12:22:34,080:INFO:machine: AMD64
2023-05-25 12:22:34,080:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-25 12:22:34,084:INFO:Memory: svmem(total=16889774080, available=9014362112, percent=46.6, used=7875411968, free=9014362112)
2023-05-25 12:22:34,084:INFO:Physical Core: 4
2023-05-25 12:22:34,084:INFO:Logical Core: 8
2023-05-25 12:22:34,084:INFO:Checking libraries
2023-05-25 12:22:34,084:INFO:System:
2023-05-25 12:22:34,084:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-25 12:22:34,084:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-25 12:22:34,084:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-25 12:22:34,084:INFO:PyCaret required dependencies:
2023-05-25 12:22:34,084:INFO:                 pip: 23.0.1
2023-05-25 12:22:34,084:INFO:          setuptools: 66.0.0
2023-05-25 12:22:34,084:INFO:             pycaret: 3.0.2
2023-05-25 12:22:34,084:INFO:             IPython: 8.13.2
2023-05-25 12:22:34,084:INFO:          ipywidgets: 8.0.6
2023-05-25 12:22:34,084:INFO:                tqdm: 4.65.0
2023-05-25 12:22:34,084:INFO:               numpy: 1.23.5
2023-05-25 12:22:34,084:INFO:              pandas: 1.5.3
2023-05-25 12:22:34,085:INFO:              jinja2: 3.1.2
2023-05-25 12:22:34,085:INFO:               scipy: 1.10.1
2023-05-25 12:22:34,085:INFO:              joblib: 1.2.0
2023-05-25 12:22:34,085:INFO:             sklearn: 1.2.2
2023-05-25 12:22:34,085:INFO:                pyod: 1.0.9
2023-05-25 12:22:34,085:INFO:            imblearn: 0.10.1
2023-05-25 12:22:34,085:INFO:   category_encoders: 2.6.1
2023-05-25 12:22:34,085:INFO:            lightgbm: 3.3.5
2023-05-25 12:22:34,085:INFO:               numba: 0.57.0
2023-05-25 12:22:34,085:INFO:            requests: 2.31.0
2023-05-25 12:22:34,085:INFO:          matplotlib: 3.7.1
2023-05-25 12:22:34,085:INFO:          scikitplot: 0.3.7
2023-05-25 12:22:34,085:INFO:         yellowbrick: 1.5
2023-05-25 12:22:34,085:INFO:              plotly: 5.14.1
2023-05-25 12:22:34,085:INFO:             kaleido: 0.2.1
2023-05-25 12:22:34,085:INFO:         statsmodels: 0.14.0
2023-05-25 12:22:34,085:INFO:              sktime: 0.17.0
2023-05-25 12:22:34,085:INFO:               tbats: 1.1.3
2023-05-25 12:22:34,085:INFO:            pmdarima: 2.0.3
2023-05-25 12:22:34,085:INFO:              psutil: 5.9.5
2023-05-25 12:22:34,085:INFO:PyCaret optional dependencies:
2023-05-25 12:22:34,093:INFO:                shap: Not installed
2023-05-25 12:22:34,093:INFO:           interpret: Not installed
2023-05-25 12:22:34,093:INFO:                umap: Not installed
2023-05-25 12:22:34,093:INFO:    pandas_profiling: Not installed
2023-05-25 12:22:34,093:INFO:  explainerdashboard: Not installed
2023-05-25 12:22:34,093:INFO:             autoviz: Not installed
2023-05-25 12:22:34,093:INFO:           fairlearn: Not installed
2023-05-25 12:22:34,093:INFO:             xgboost: Not installed
2023-05-25 12:22:34,093:INFO:            catboost: Not installed
2023-05-25 12:22:34,093:INFO:              kmodes: Not installed
2023-05-25 12:22:34,093:INFO:             mlxtend: Not installed
2023-05-25 12:22:34,093:INFO:       statsforecast: Not installed
2023-05-25 12:22:34,093:INFO:        tune_sklearn: 0.4.5
2023-05-25 12:22:34,093:INFO:                 ray: 2.4.0
2023-05-25 12:22:34,093:INFO:            hyperopt: 0.2.7
2023-05-25 12:22:34,093:INFO:              optuna: 3.1.1
2023-05-25 12:22:34,093:INFO:               skopt: 0.9.0
2023-05-25 12:22:34,093:INFO:              mlflow: Not installed
2023-05-25 12:22:34,093:INFO:              gradio: Not installed
2023-05-25 12:22:34,093:INFO:             fastapi: Not installed
2023-05-25 12:22:34,093:INFO:             uvicorn: Not installed
2023-05-25 12:22:34,093:INFO:              m2cgen: Not installed
2023-05-25 12:22:34,094:INFO:           evidently: Not installed
2023-05-25 12:22:34,094:INFO:               fugue: Not installed
2023-05-25 12:22:34,094:INFO:           streamlit: Not installed
2023-05-25 12:22:34,094:INFO:             prophet: Not installed
2023-05-25 12:22:34,094:INFO:None
2023-05-25 12:22:34,094:INFO:Set up data.
2023-05-25 12:22:34,290:INFO:Set up train/test split.
2023-05-25 12:22:34,379:INFO:Set up index.
2023-05-25 12:22:34,382:INFO:Set up folding strategy.
2023-05-25 12:22:34,382:INFO:Assigning column types.
2023-05-25 12:22:34,443:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-25 12:22:34,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 12:22:34,483:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:22:34,515:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,572:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 12:22:34,572:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:22:34,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,597:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,597:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-25 12:22:34,635:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:22:34,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,698:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:22:34,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,725:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-25 12:22:34,795:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,795:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:34,863:INFO:Preparing preprocessing pipeline...
2023-05-25 12:22:34,870:INFO:Set up label encoding.
2023-05-25 12:22:34,870:INFO:Set up simple imputation.
2023-05-25 12:22:34,870:INFO:Set up imbalanced handling.
2023-05-25 12:22:34,876:INFO:Set up column name cleaning.
2023-05-25 12:22:35,474:INFO:Finished creating preprocessing pipeline.
2023-05-25 12:22:35,495:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-25 12:22:35,495:INFO:Creating final display dataframe.
2023-05-25 12:22:36,213:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 511)
5        Transformed data shape              (41153, 511)
6   Transformed train set shape              (30052, 511)
7    Transformed test set shape              (11101, 511)
8              Numeric features                       510
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      a4a2
2023-05-25 12:22:36,301:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:36,301:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:36,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:36,382:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:22:36,384:INFO:setup() successfully completed in 2.69s...............
2023-05-25 12:22:36,436:INFO:Initializing compare_models()
2023-05-25 12:22:36,436:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-25 12:22:36,436:INFO:Checking exceptions
2023-05-25 12:22:36,486:INFO:Preparing display monitor
2023-05-25 12:22:36,516:INFO:Initializing Logistic Regression
2023-05-25 12:22:36,517:INFO:Total runtime is 1.677274703979492e-05 minutes
2023-05-25 12:22:36,523:INFO:SubProcess create_model() called ==================================
2023-05-25 12:22:36,524:INFO:Initializing create_model()
2023-05-25 12:22:36,524:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:22:36,524:INFO:Checking exceptions
2023-05-25 12:22:36,524:INFO:Importing libraries
2023-05-25 12:22:36,524:INFO:Copying training dataset
2023-05-25 12:22:36,605:INFO:Defining folds
2023-05-25 12:22:36,605:INFO:Declaring metric variables
2023-05-25 12:22:36,609:INFO:Importing untrained model
2023-05-25 12:22:36,612:INFO:Logistic Regression Imported successfully
2023-05-25 12:22:36,619:INFO:Starting cross validation
2023-05-25 12:22:36,623:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:22:47,041:INFO:Calculating mean and std
2023-05-25 12:22:47,042:INFO:Creating metrics dataframe
2023-05-25 12:22:47,526:INFO:Uploading results into container
2023-05-25 12:22:47,527:INFO:Uploading model into container now
2023-05-25 12:22:47,527:INFO:_master_model_container: 1
2023-05-25 12:22:47,527:INFO:_display_container: 2
2023-05-25 12:22:47,527:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-25 12:22:47,527:INFO:create_model() successfully completed......................................
2023-05-25 12:22:47,599:INFO:SubProcess create_model() end ==================================
2023-05-25 12:22:47,599:INFO:Creating metrics dataframe
2023-05-25 12:22:47,607:INFO:Initializing K Neighbors Classifier
2023-05-25 12:22:47,607:INFO:Total runtime is 0.1848518172899882 minutes
2023-05-25 12:22:47,611:INFO:SubProcess create_model() called ==================================
2023-05-25 12:22:47,611:INFO:Initializing create_model()
2023-05-25 12:22:47,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:22:47,611:INFO:Checking exceptions
2023-05-25 12:22:47,611:INFO:Importing libraries
2023-05-25 12:22:47,611:INFO:Copying training dataset
2023-05-25 12:22:47,682:INFO:Defining folds
2023-05-25 12:22:47,682:INFO:Declaring metric variables
2023-05-25 12:22:47,685:INFO:Importing untrained model
2023-05-25 12:22:47,689:INFO:K Neighbors Classifier Imported successfully
2023-05-25 12:22:47,696:INFO:Starting cross validation
2023-05-25 12:22:47,700:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:23:05,570:INFO:Calculating mean and std
2023-05-25 12:23:05,571:INFO:Creating metrics dataframe
2023-05-25 12:23:06,082:INFO:Uploading results into container
2023-05-25 12:23:06,083:INFO:Uploading model into container now
2023-05-25 12:23:06,084:INFO:_master_model_container: 2
2023-05-25 12:23:06,084:INFO:_display_container: 2
2023-05-25 12:23:06,086:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-25 12:23:06,086:INFO:create_model() successfully completed......................................
2023-05-25 12:23:06,161:INFO:SubProcess create_model() end ==================================
2023-05-25 12:23:06,161:INFO:Creating metrics dataframe
2023-05-25 12:23:06,171:INFO:Initializing Naive Bayes
2023-05-25 12:23:06,172:INFO:Total runtime is 0.49424202442169185 minutes
2023-05-25 12:23:06,175:INFO:SubProcess create_model() called ==================================
2023-05-25 12:23:06,176:INFO:Initializing create_model()
2023-05-25 12:23:06,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:23:06,176:INFO:Checking exceptions
2023-05-25 12:23:06,176:INFO:Importing libraries
2023-05-25 12:23:06,176:INFO:Copying training dataset
2023-05-25 12:23:06,249:INFO:Defining folds
2023-05-25 12:23:06,249:INFO:Declaring metric variables
2023-05-25 12:23:06,254:INFO:Importing untrained model
2023-05-25 12:23:06,258:INFO:Naive Bayes Imported successfully
2023-05-25 12:23:06,265:INFO:Starting cross validation
2023-05-25 12:23:06,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:23:12,985:INFO:Calculating mean and std
2023-05-25 12:23:12,986:INFO:Creating metrics dataframe
2023-05-25 12:23:13,524:INFO:Uploading results into container
2023-05-25 12:23:13,525:INFO:Uploading model into container now
2023-05-25 12:23:13,525:INFO:_master_model_container: 3
2023-05-25 12:23:13,525:INFO:_display_container: 2
2023-05-25 12:23:13,525:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-25 12:23:13,527:INFO:create_model() successfully completed......................................
2023-05-25 12:23:13,598:INFO:SubProcess create_model() end ==================================
2023-05-25 12:23:13,599:INFO:Creating metrics dataframe
2023-05-25 12:23:13,611:INFO:Initializing Decision Tree Classifier
2023-05-25 12:23:13,612:INFO:Total runtime is 0.6182645599047343 minutes
2023-05-25 12:23:13,615:INFO:SubProcess create_model() called ==================================
2023-05-25 12:23:13,616:INFO:Initializing create_model()
2023-05-25 12:23:13,616:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:23:13,616:INFO:Checking exceptions
2023-05-25 12:23:13,616:INFO:Importing libraries
2023-05-25 12:23:13,616:INFO:Copying training dataset
2023-05-25 12:23:13,687:INFO:Defining folds
2023-05-25 12:23:13,687:INFO:Declaring metric variables
2023-05-25 12:23:13,690:INFO:Importing untrained model
2023-05-25 12:23:13,695:INFO:Decision Tree Classifier Imported successfully
2023-05-25 12:23:13,702:INFO:Starting cross validation
2023-05-25 12:23:13,706:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:23:19,918:INFO:Calculating mean and std
2023-05-25 12:23:19,920:INFO:Creating metrics dataframe
2023-05-25 12:23:20,403:INFO:Uploading results into container
2023-05-25 12:23:20,403:INFO:Uploading model into container now
2023-05-25 12:23:20,404:INFO:_master_model_container: 4
2023-05-25 12:23:20,404:INFO:_display_container: 2
2023-05-25 12:23:20,405:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-25 12:23:20,405:INFO:create_model() successfully completed......................................
2023-05-25 12:23:20,474:INFO:SubProcess create_model() end ==================================
2023-05-25 12:23:20,474:INFO:Creating metrics dataframe
2023-05-25 12:23:20,485:INFO:Initializing SVM - Linear Kernel
2023-05-25 12:23:20,485:INFO:Total runtime is 0.7328074018160502 minutes
2023-05-25 12:23:20,489:INFO:SubProcess create_model() called ==================================
2023-05-25 12:23:20,489:INFO:Initializing create_model()
2023-05-25 12:23:20,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:23:20,489:INFO:Checking exceptions
2023-05-25 12:23:20,489:INFO:Importing libraries
2023-05-25 12:23:20,489:INFO:Copying training dataset
2023-05-25 12:23:20,560:INFO:Defining folds
2023-05-25 12:23:20,560:INFO:Declaring metric variables
2023-05-25 12:23:20,563:INFO:Importing untrained model
2023-05-25 12:23:20,567:INFO:SVM - Linear Kernel Imported successfully
2023-05-25 12:23:20,576:INFO:Starting cross validation
2023-05-25 12:23:20,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:23:21,911:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:23:21,946:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:23:21,990:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:23:21,993:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:23:21,996:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:23:22,025:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:23:22,106:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:23:22,142:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:23:24,236:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:23:24,340:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:23:26,845:INFO:Calculating mean and std
2023-05-25 12:23:26,846:INFO:Creating metrics dataframe
2023-05-25 12:23:27,329:INFO:Uploading results into container
2023-05-25 12:23:27,330:INFO:Uploading model into container now
2023-05-25 12:23:27,330:INFO:_master_model_container: 5
2023-05-25 12:23:27,330:INFO:_display_container: 2
2023-05-25 12:23:27,331:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-25 12:23:27,331:INFO:create_model() successfully completed......................................
2023-05-25 12:23:27,402:INFO:SubProcess create_model() end ==================================
2023-05-25 12:23:27,402:INFO:Creating metrics dataframe
2023-05-25 12:23:27,412:INFO:Initializing Ridge Classifier
2023-05-25 12:23:27,412:INFO:Total runtime is 0.8482602357864379 minutes
2023-05-25 12:23:27,415:INFO:SubProcess create_model() called ==================================
2023-05-25 12:23:27,415:INFO:Initializing create_model()
2023-05-25 12:23:27,415:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:23:27,415:INFO:Checking exceptions
2023-05-25 12:23:27,415:INFO:Importing libraries
2023-05-25 12:23:27,415:INFO:Copying training dataset
2023-05-25 12:23:27,485:INFO:Defining folds
2023-05-25 12:23:27,485:INFO:Declaring metric variables
2023-05-25 12:23:27,488:INFO:Importing untrained model
2023-05-25 12:23:27,492:INFO:Ridge Classifier Imported successfully
2023-05-25 12:23:27,500:INFO:Starting cross validation
2023-05-25 12:23:27,503:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:23:28,878:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:23:28,879:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:23:28,912:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:23:28,930:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:23:28,971:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:23:28,977:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:23:29,020:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:23:29,023:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:23:31,146:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:23:31,393:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:23:33,846:INFO:Calculating mean and std
2023-05-25 12:23:33,847:INFO:Creating metrics dataframe
2023-05-25 12:23:34,338:INFO:Uploading results into container
2023-05-25 12:23:34,339:INFO:Uploading model into container now
2023-05-25 12:23:34,339:INFO:_master_model_container: 6
2023-05-25 12:23:34,339:INFO:_display_container: 2
2023-05-25 12:23:34,340:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-25 12:23:34,340:INFO:create_model() successfully completed......................................
2023-05-25 12:23:34,411:INFO:SubProcess create_model() end ==================================
2023-05-25 12:23:34,411:INFO:Creating metrics dataframe
2023-05-25 12:23:34,421:INFO:Initializing Random Forest Classifier
2023-05-25 12:23:34,422:INFO:Total runtime is 0.9650955041249593 minutes
2023-05-25 12:23:34,425:INFO:SubProcess create_model() called ==================================
2023-05-25 12:23:34,426:INFO:Initializing create_model()
2023-05-25 12:23:34,426:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:23:34,426:INFO:Checking exceptions
2023-05-25 12:23:34,426:INFO:Importing libraries
2023-05-25 12:23:34,426:INFO:Copying training dataset
2023-05-25 12:23:34,496:INFO:Defining folds
2023-05-25 12:23:34,497:INFO:Declaring metric variables
2023-05-25 12:23:34,501:INFO:Importing untrained model
2023-05-25 12:23:34,506:INFO:Random Forest Classifier Imported successfully
2023-05-25 12:23:34,512:INFO:Starting cross validation
2023-05-25 12:23:34,516:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:23:42,629:INFO:Calculating mean and std
2023-05-25 12:23:42,630:INFO:Creating metrics dataframe
2023-05-25 12:23:43,159:INFO:Uploading results into container
2023-05-25 12:23:43,159:INFO:Uploading model into container now
2023-05-25 12:23:43,160:INFO:_master_model_container: 7
2023-05-25 12:23:43,160:INFO:_display_container: 2
2023-05-25 12:23:43,160:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 12:23:43,161:INFO:create_model() successfully completed......................................
2023-05-25 12:23:43,235:INFO:SubProcess create_model() end ==================================
2023-05-25 12:23:43,236:INFO:Creating metrics dataframe
2023-05-25 12:23:43,246:INFO:Initializing Quadratic Discriminant Analysis
2023-05-25 12:23:43,246:INFO:Total runtime is 1.112155810991923 minutes
2023-05-25 12:23:43,249:INFO:SubProcess create_model() called ==================================
2023-05-25 12:23:43,249:INFO:Initializing create_model()
2023-05-25 12:23:43,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:23:43,249:INFO:Checking exceptions
2023-05-25 12:23:43,249:INFO:Importing libraries
2023-05-25 12:23:43,249:INFO:Copying training dataset
2023-05-25 12:23:43,318:INFO:Defining folds
2023-05-25 12:23:43,319:INFO:Declaring metric variables
2023-05-25 12:23:43,322:INFO:Importing untrained model
2023-05-25 12:23:43,327:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-25 12:23:43,333:INFO:Starting cross validation
2023-05-25 12:23:43,339:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:23:49,964:INFO:Calculating mean and std
2023-05-25 12:23:49,965:INFO:Creating metrics dataframe
2023-05-25 12:23:50,462:INFO:Uploading results into container
2023-05-25 12:23:50,462:INFO:Uploading model into container now
2023-05-25 12:23:50,463:INFO:_master_model_container: 8
2023-05-25 12:23:50,463:INFO:_display_container: 2
2023-05-25 12:23:50,463:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-25 12:23:50,463:INFO:create_model() successfully completed......................................
2023-05-25 12:23:50,532:INFO:SubProcess create_model() end ==================================
2023-05-25 12:23:50,533:INFO:Creating metrics dataframe
2023-05-25 12:23:50,545:INFO:Initializing Ada Boost Classifier
2023-05-25 12:23:50,545:INFO:Total runtime is 1.2338054219881693 minutes
2023-05-25 12:23:50,548:INFO:SubProcess create_model() called ==================================
2023-05-25 12:23:50,548:INFO:Initializing create_model()
2023-05-25 12:23:50,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:23:50,549:INFO:Checking exceptions
2023-05-25 12:23:50,549:INFO:Importing libraries
2023-05-25 12:23:50,549:INFO:Copying training dataset
2023-05-25 12:23:50,617:INFO:Defining folds
2023-05-25 12:23:50,617:INFO:Declaring metric variables
2023-05-25 12:23:50,621:INFO:Importing untrained model
2023-05-25 12:23:50,626:INFO:Ada Boost Classifier Imported successfully
2023-05-25 12:23:50,632:INFO:Starting cross validation
2023-05-25 12:23:50,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:23:58,878:INFO:Calculating mean and std
2023-05-25 12:23:58,878:INFO:Creating metrics dataframe
2023-05-25 12:23:59,679:INFO:Uploading results into container
2023-05-25 12:23:59,679:INFO:Uploading model into container now
2023-05-25 12:23:59,679:INFO:_master_model_container: 9
2023-05-25 12:23:59,679:INFO:_display_container: 2
2023-05-25 12:23:59,687:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 12:23:59,687:INFO:create_model() successfully completed......................................
2023-05-25 12:23:59,770:INFO:SubProcess create_model() end ==================================
2023-05-25 12:23:59,770:INFO:Creating metrics dataframe
2023-05-25 12:23:59,784:INFO:Initializing Gradient Boosting Classifier
2023-05-25 12:23:59,784:INFO:Total runtime is 1.3877920786539713 minutes
2023-05-25 12:23:59,784:INFO:SubProcess create_model() called ==================================
2023-05-25 12:23:59,784:INFO:Initializing create_model()
2023-05-25 12:23:59,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:23:59,784:INFO:Checking exceptions
2023-05-25 12:23:59,784:INFO:Importing libraries
2023-05-25 12:23:59,784:INFO:Copying training dataset
2023-05-25 12:23:59,880:INFO:Defining folds
2023-05-25 12:23:59,880:INFO:Declaring metric variables
2023-05-25 12:23:59,888:INFO:Importing untrained model
2023-05-25 12:23:59,891:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 12:23:59,904:INFO:Starting cross validation
2023-05-25 12:23:59,904:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:24:02,681:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:24:02,753:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:24:02,834:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:24:02,884:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:24:02,956:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:24:02,974:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:24:10,573:INFO:Calculating mean and std
2023-05-25 12:24:10,573:INFO:Creating metrics dataframe
2023-05-25 12:24:11,577:INFO:Uploading results into container
2023-05-25 12:24:11,577:INFO:Uploading model into container now
2023-05-25 12:24:11,577:INFO:_master_model_container: 10
2023-05-25 12:24:11,577:INFO:_display_container: 2
2023-05-25 12:24:11,577:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 12:24:11,577:INFO:create_model() successfully completed......................................
2023-05-25 12:24:11,659:INFO:SubProcess create_model() end ==================================
2023-05-25 12:24:11,659:INFO:Creating metrics dataframe
2023-05-25 12:24:11,684:INFO:Initializing Linear Discriminant Analysis
2023-05-25 12:24:11,684:INFO:Total runtime is 1.5861311197280883 minutes
2023-05-25 12:24:11,691:INFO:SubProcess create_model() called ==================================
2023-05-25 12:24:11,691:INFO:Initializing create_model()
2023-05-25 12:24:11,691:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:24:11,691:INFO:Checking exceptions
2023-05-25 12:24:11,691:INFO:Importing libraries
2023-05-25 12:24:11,691:INFO:Copying training dataset
2023-05-25 12:24:11,790:INFO:Defining folds
2023-05-25 12:24:11,790:INFO:Declaring metric variables
2023-05-25 12:24:11,798:INFO:Importing untrained model
2023-05-25 12:24:11,806:INFO:Linear Discriminant Analysis Imported successfully
2023-05-25 12:24:11,814:INFO:Starting cross validation
2023-05-25 12:24:11,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:24:21,116:INFO:Calculating mean and std
2023-05-25 12:24:21,117:INFO:Creating metrics dataframe
2023-05-25 12:24:21,598:INFO:Uploading results into container
2023-05-25 12:24:21,598:INFO:Uploading model into container now
2023-05-25 12:24:21,599:INFO:_master_model_container: 11
2023-05-25 12:24:21,599:INFO:_display_container: 2
2023-05-25 12:24:21,599:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-25 12:24:21,599:INFO:create_model() successfully completed......................................
2023-05-25 12:24:21,669:INFO:SubProcess create_model() end ==================================
2023-05-25 12:24:21,669:INFO:Creating metrics dataframe
2023-05-25 12:24:21,680:INFO:Initializing Extra Trees Classifier
2023-05-25 12:24:21,680:INFO:Total runtime is 1.752732213338216 minutes
2023-05-25 12:24:21,683:INFO:SubProcess create_model() called ==================================
2023-05-25 12:24:21,683:INFO:Initializing create_model()
2023-05-25 12:24:21,683:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:24:21,683:INFO:Checking exceptions
2023-05-25 12:24:21,683:INFO:Importing libraries
2023-05-25 12:24:21,684:INFO:Copying training dataset
2023-05-25 12:24:21,753:INFO:Defining folds
2023-05-25 12:24:21,753:INFO:Declaring metric variables
2023-05-25 12:24:21,758:INFO:Importing untrained model
2023-05-25 12:24:21,761:INFO:Extra Trees Classifier Imported successfully
2023-05-25 12:24:21,768:INFO:Starting cross validation
2023-05-25 12:24:21,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:24:30,372:INFO:Calculating mean and std
2023-05-25 12:24:30,373:INFO:Creating metrics dataframe
2023-05-25 12:24:30,862:INFO:Uploading results into container
2023-05-25 12:24:30,863:INFO:Uploading model into container now
2023-05-25 12:24:30,863:INFO:_master_model_container: 12
2023-05-25 12:24:30,863:INFO:_display_container: 2
2023-05-25 12:24:30,863:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 12:24:30,863:INFO:create_model() successfully completed......................................
2023-05-25 12:24:30,931:INFO:SubProcess create_model() end ==================================
2023-05-25 12:24:30,932:INFO:Creating metrics dataframe
2023-05-25 12:24:30,943:INFO:Initializing Light Gradient Boosting Machine
2023-05-25 12:24:30,944:INFO:Total runtime is 1.907126148541768 minutes
2023-05-25 12:24:30,947:INFO:SubProcess create_model() called ==================================
2023-05-25 12:24:30,947:INFO:Initializing create_model()
2023-05-25 12:24:30,947:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:24:30,947:INFO:Checking exceptions
2023-05-25 12:24:30,947:INFO:Importing libraries
2023-05-25 12:24:30,947:INFO:Copying training dataset
2023-05-25 12:24:31,015:INFO:Defining folds
2023-05-25 12:24:31,015:INFO:Declaring metric variables
2023-05-25 12:24:31,019:INFO:Importing untrained model
2023-05-25 12:24:31,024:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 12:24:31,030:INFO:Starting cross validation
2023-05-25 12:24:31,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:24:37,627:INFO:Calculating mean and std
2023-05-25 12:24:37,628:INFO:Creating metrics dataframe
2023-05-25 12:24:38,193:INFO:Uploading results into container
2023-05-25 12:24:38,193:INFO:Uploading model into container now
2023-05-25 12:24:38,194:INFO:_master_model_container: 13
2023-05-25 12:24:38,194:INFO:_display_container: 2
2023-05-25 12:24:38,194:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 12:24:38,194:INFO:create_model() successfully completed......................................
2023-05-25 12:24:38,271:INFO:SubProcess create_model() end ==================================
2023-05-25 12:24:38,271:INFO:Creating metrics dataframe
2023-05-25 12:24:38,282:INFO:Initializing Dummy Classifier
2023-05-25 12:24:38,282:INFO:Total runtime is 2.0294346690177916 minutes
2023-05-25 12:24:38,289:INFO:SubProcess create_model() called ==================================
2023-05-25 12:24:38,289:INFO:Initializing create_model()
2023-05-25 12:24:38,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000125E2DE09D0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:24:38,290:INFO:Checking exceptions
2023-05-25 12:24:38,290:INFO:Importing libraries
2023-05-25 12:24:38,290:INFO:Copying training dataset
2023-05-25 12:24:38,360:INFO:Defining folds
2023-05-25 12:24:38,360:INFO:Declaring metric variables
2023-05-25 12:24:38,363:INFO:Importing untrained model
2023-05-25 12:24:38,368:INFO:Dummy Classifier Imported successfully
2023-05-25 12:24:38,375:INFO:Starting cross validation
2023-05-25 12:24:38,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:24:39,780:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:24:39,789:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:24:39,848:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:24:39,849:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:24:39,855:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:24:39,872:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:24:39,885:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:24:39,897:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:24:41,968:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:24:41,995:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:24:44,464:INFO:Calculating mean and std
2023-05-25 12:24:44,465:INFO:Creating metrics dataframe
2023-05-25 12:24:44,963:INFO:Uploading results into container
2023-05-25 12:24:44,964:INFO:Uploading model into container now
2023-05-25 12:24:44,964:INFO:_master_model_container: 14
2023-05-25 12:24:44,964:INFO:_display_container: 2
2023-05-25 12:24:44,964:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-25 12:24:44,964:INFO:create_model() successfully completed......................................
2023-05-25 12:24:45,033:INFO:SubProcess create_model() end ==================================
2023-05-25 12:24:45,033:INFO:Creating metrics dataframe
2023-05-25 12:24:45,055:INFO:Initializing create_model()
2023-05-25 12:24:45,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:24:45,056:INFO:Checking exceptions
2023-05-25 12:24:45,058:INFO:Importing libraries
2023-05-25 12:24:45,058:INFO:Copying training dataset
2023-05-25 12:24:45,128:INFO:Defining folds
2023-05-25 12:24:45,128:INFO:Declaring metric variables
2023-05-25 12:24:45,128:INFO:Importing untrained model
2023-05-25 12:24:45,128:INFO:Declaring custom model
2023-05-25 12:24:45,130:INFO:Random Forest Classifier Imported successfully
2023-05-25 12:24:45,133:INFO:Cross validation set to False
2023-05-25 12:24:45,133:INFO:Fitting Model
2023-05-25 12:24:46,388:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 12:24:46,388:INFO:create_model() successfully completed......................................
2023-05-25 12:24:46,463:INFO:Initializing create_model()
2023-05-25 12:24:46,463:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:24:46,463:INFO:Checking exceptions
2023-05-25 12:24:46,465:INFO:Importing libraries
2023-05-25 12:24:46,465:INFO:Copying training dataset
2023-05-25 12:24:46,535:INFO:Defining folds
2023-05-25 12:24:46,535:INFO:Declaring metric variables
2023-05-25 12:24:46,535:INFO:Importing untrained model
2023-05-25 12:24:46,535:INFO:Declaring custom model
2023-05-25 12:24:46,536:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 12:24:46,538:INFO:Cross validation set to False
2023-05-25 12:24:46,539:INFO:Fitting Model
2023-05-25 12:24:47,566:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 12:24:47,566:INFO:create_model() successfully completed......................................
2023-05-25 12:24:47,641:INFO:Initializing create_model()
2023-05-25 12:24:47,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:24:47,642:INFO:Checking exceptions
2023-05-25 12:24:47,644:INFO:Importing libraries
2023-05-25 12:24:47,644:INFO:Copying training dataset
2023-05-25 12:24:47,712:INFO:Defining folds
2023-05-25 12:24:47,712:INFO:Declaring metric variables
2023-05-25 12:24:47,713:INFO:Importing untrained model
2023-05-25 12:24:47,713:INFO:Declaring custom model
2023-05-25 12:24:47,713:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 12:24:47,716:INFO:Cross validation set to False
2023-05-25 12:24:47,716:INFO:Fitting Model
2023-05-25 12:24:48,646:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 12:24:48,646:INFO:create_model() successfully completed......................................
2023-05-25 12:24:48,720:INFO:Initializing create_model()
2023-05-25 12:24:48,721:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:24:48,721:INFO:Checking exceptions
2023-05-25 12:24:48,723:INFO:Importing libraries
2023-05-25 12:24:48,723:INFO:Copying training dataset
2023-05-25 12:24:48,791:INFO:Defining folds
2023-05-25 12:24:48,792:INFO:Declaring metric variables
2023-05-25 12:24:48,792:INFO:Importing untrained model
2023-05-25 12:24:48,792:INFO:Declaring custom model
2023-05-25 12:24:48,792:INFO:Ada Boost Classifier Imported successfully
2023-05-25 12:24:48,795:INFO:Cross validation set to False
2023-05-25 12:24:48,795:INFO:Fitting Model
2023-05-25 12:24:49,738:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 12:24:49,738:INFO:create_model() successfully completed......................................
2023-05-25 12:24:49,812:INFO:Initializing create_model()
2023-05-25 12:24:49,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:24:49,812:INFO:Checking exceptions
2023-05-25 12:24:49,814:INFO:Importing libraries
2023-05-25 12:24:49,814:INFO:Copying training dataset
2023-05-25 12:24:49,882:INFO:Defining folds
2023-05-25 12:24:49,882:INFO:Declaring metric variables
2023-05-25 12:24:49,882:INFO:Importing untrained model
2023-05-25 12:24:49,882:INFO:Declaring custom model
2023-05-25 12:24:49,883:INFO:Extra Trees Classifier Imported successfully
2023-05-25 12:24:49,886:INFO:Cross validation set to False
2023-05-25 12:24:49,886:INFO:Fitting Model
2023-05-25 12:24:51,080:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 12:24:51,080:INFO:create_model() successfully completed......................................
2023-05-25 12:24:51,175:INFO:_master_model_container: 14
2023-05-25 12:24:51,176:INFO:_display_container: 2
2023-05-25 12:24:51,178:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)]
2023-05-25 12:24:51,178:INFO:compare_models() successfully completed......................................
2023-05-25 12:25:16,056:INFO:Initializing save_model()
2023-05-25 12:25:16,057:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=saved_model0, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 12:25:16,057:INFO:Adding model into prep_pipe
2023-05-25 12:25:16,174:INFO:saved_model0.pkl saved in current working directory
2023-05-25 12:25:16,184:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 12:25:16,184:INFO:save_model() successfully completed......................................
2023-05-25 12:25:16,682:INFO:Initializing save_model()
2023-05-25 12:25:16,682:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=saved_model1, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 12:25:16,682:INFO:Adding model into prep_pipe
2023-05-25 12:25:16,745:INFO:saved_model1.pkl saved in current working directory
2023-05-25 12:25:16,763:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-05-25 12:25:16,764:INFO:save_model() successfully completed......................................
2023-05-25 12:25:17,288:INFO:Initializing save_model()
2023-05-25 12:25:17,289:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=saved_model2, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 12:25:17,289:INFO:Adding model into prep_pipe
2023-05-25 12:25:17,310:INFO:saved_model2.pkl saved in current working directory
2023-05-25 12:25:17,321:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 12:25:17,321:INFO:save_model() successfully completed......................................
2023-05-25 12:25:17,799:INFO:Initializing save_model()
2023-05-25 12:25:17,799:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), model_name=saved_model3, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 12:25:17,799:INFO:Adding model into prep_pipe
2023-05-25 12:25:17,836:INFO:saved_model3.pkl saved in current working directory
2023-05-25 12:25:17,847:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=123))],
         verbose=False)
2023-05-25 12:25:17,848:INFO:save_model() successfully completed......................................
2023-05-25 12:25:18,358:INFO:Initializing save_model()
2023-05-25 12:25:18,358:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), model_name=saved_model4, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 12:25:18,359:INFO:Adding model into prep_pipe
2023-05-25 12:25:18,545:INFO:saved_model4.pkl saved in current working directory
2023-05-25 12:25:18,558:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=123,
                                      verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 12:25:18,558:INFO:save_model() successfully completed......................................
2023-05-25 12:25:42,885:INFO:Initializing predict_model()
2023-05-25 12:25:42,885:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000012585999BD0>)
2023-05-25 12:25:42,885:INFO:Checking exceptions
2023-05-25 12:25:42,885:INFO:Preloading libraries
2023-05-25 12:25:42,887:INFO:Set up data.
2023-05-25 12:25:43,003:INFO:Set up index.
2023-05-25 12:25:43,540:INFO:Initializing tune_model()
2023-05-25 12:25:43,541:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000125E606A920>)
2023-05-25 12:25:43,541:INFO:Checking exceptions
2023-05-25 12:25:43,541:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-25 12:25:43,995:INFO:Copying training dataset
2023-05-25 12:25:44,126:INFO:Checking base model
2023-05-25 12:25:44,126:INFO:Base model : Random Forest Classifier
2023-05-25 12:25:44,130:INFO:Declaring metric variables
2023-05-25 12:25:44,134:INFO:Defining Hyperparameters
2023-05-25 12:25:44,257:INFO:Tuning with n_jobs=-1
2023-05-25 12:25:44,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 12:25:44,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 12:25:44,262:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-05-25 12:25:44,262:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-25 12:25:44,266:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-25 12:27:18,148:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:27:35,155:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:27:54,294:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:28:43,721:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:29:13,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 12:29:13,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 12:29:13,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 12:29:13,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 12:29:13,797:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-25 12:29:26,347:INFO:PyCaret ClassificationExperiment
2023-05-25 12:29:26,347:INFO:Logging name: clf-default-name
2023-05-25 12:29:26,347:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-25 12:29:26,348:INFO:version 3.0.2
2023-05-25 12:29:26,348:INFO:Initializing setup()
2023-05-25 12:29:26,348:INFO:self.USI: f6a9
2023-05-25 12:29:26,348:INFO:self._variable_keys: {'html_param', 'X', 'y', 'X_train', 'memory', '_ml_usecase', 'fold_shuffle_param', 'gpu_n_jobs_param', 'n_jobs_param', 'fold_generator', 'is_multiclass', 'y_train', 'fix_imbalance', 'idx', '_available_plots', 'exp_name_log', 'X_test', 'USI', 'seed', 'target_param', 'gpu_param', 'data', 'pipeline', 'log_plots_param', 'logging_param', 'y_test', 'fold_groups_param', 'exp_id'}
2023-05-25 12:29:26,348:INFO:Checking environment
2023-05-25 12:29:26,348:INFO:python_version: 3.10.11
2023-05-25 12:29:26,348:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-25 12:29:26,348:INFO:machine: AMD64
2023-05-25 12:29:26,348:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-25 12:29:26,350:INFO:Memory: svmem(total=16889774080, available=9150193664, percent=45.8, used=7739580416, free=9150193664)
2023-05-25 12:29:26,350:INFO:Physical Core: 4
2023-05-25 12:29:26,350:INFO:Logical Core: 8
2023-05-25 12:29:26,350:INFO:Checking libraries
2023-05-25 12:29:26,350:INFO:System:
2023-05-25 12:29:26,350:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-25 12:29:26,350:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-25 12:29:26,350:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-25 12:29:26,350:INFO:PyCaret required dependencies:
2023-05-25 12:29:26,350:INFO:                 pip: 23.0.1
2023-05-25 12:29:26,350:INFO:          setuptools: 66.0.0
2023-05-25 12:29:26,351:INFO:             pycaret: 3.0.2
2023-05-25 12:29:26,351:INFO:             IPython: 8.13.2
2023-05-25 12:29:26,351:INFO:          ipywidgets: 8.0.6
2023-05-25 12:29:26,351:INFO:                tqdm: 4.65.0
2023-05-25 12:29:26,351:INFO:               numpy: 1.23.5
2023-05-25 12:29:26,351:INFO:              pandas: 1.5.3
2023-05-25 12:29:26,351:INFO:              jinja2: 3.1.2
2023-05-25 12:29:26,351:INFO:               scipy: 1.10.1
2023-05-25 12:29:26,351:INFO:              joblib: 1.2.0
2023-05-25 12:29:26,351:INFO:             sklearn: 1.2.2
2023-05-25 12:29:26,351:INFO:                pyod: 1.0.9
2023-05-25 12:29:26,351:INFO:            imblearn: 0.10.1
2023-05-25 12:29:26,351:INFO:   category_encoders: 2.6.1
2023-05-25 12:29:26,351:INFO:            lightgbm: 3.3.5
2023-05-25 12:29:26,351:INFO:               numba: 0.57.0
2023-05-25 12:29:26,351:INFO:            requests: 2.31.0
2023-05-25 12:29:26,351:INFO:          matplotlib: 3.7.1
2023-05-25 12:29:26,351:INFO:          scikitplot: 0.3.7
2023-05-25 12:29:26,351:INFO:         yellowbrick: 1.5
2023-05-25 12:29:26,351:INFO:              plotly: 5.14.1
2023-05-25 12:29:26,351:INFO:             kaleido: 0.2.1
2023-05-25 12:29:26,351:INFO:         statsmodels: 0.14.0
2023-05-25 12:29:26,351:INFO:              sktime: 0.17.0
2023-05-25 12:29:26,351:INFO:               tbats: 1.1.3
2023-05-25 12:29:26,351:INFO:            pmdarima: 2.0.3
2023-05-25 12:29:26,351:INFO:              psutil: 5.9.5
2023-05-25 12:29:26,351:INFO:PyCaret optional dependencies:
2023-05-25 12:29:26,359:INFO:                shap: Not installed
2023-05-25 12:29:26,359:INFO:           interpret: Not installed
2023-05-25 12:29:26,359:INFO:                umap: Not installed
2023-05-25 12:29:26,359:INFO:    pandas_profiling: Not installed
2023-05-25 12:29:26,359:INFO:  explainerdashboard: Not installed
2023-05-25 12:29:26,359:INFO:             autoviz: Not installed
2023-05-25 12:29:26,359:INFO:           fairlearn: Not installed
2023-05-25 12:29:26,359:INFO:             xgboost: Not installed
2023-05-25 12:29:26,359:INFO:            catboost: Not installed
2023-05-25 12:29:26,359:INFO:              kmodes: Not installed
2023-05-25 12:29:26,359:INFO:             mlxtend: Not installed
2023-05-25 12:29:26,359:INFO:       statsforecast: Not installed
2023-05-25 12:29:26,359:INFO:        tune_sklearn: 0.4.5
2023-05-25 12:29:26,359:INFO:                 ray: 2.4.0
2023-05-25 12:29:26,359:INFO:            hyperopt: 0.2.7
2023-05-25 12:29:26,359:INFO:              optuna: 3.1.1
2023-05-25 12:29:26,359:INFO:               skopt: 0.9.0
2023-05-25 12:29:26,359:INFO:              mlflow: Not installed
2023-05-25 12:29:26,359:INFO:              gradio: Not installed
2023-05-25 12:29:26,359:INFO:             fastapi: Not installed
2023-05-25 12:29:26,359:INFO:             uvicorn: Not installed
2023-05-25 12:29:26,360:INFO:              m2cgen: Not installed
2023-05-25 12:29:26,360:INFO:           evidently: Not installed
2023-05-25 12:29:26,360:INFO:               fugue: Not installed
2023-05-25 12:29:26,360:INFO:           streamlit: Not installed
2023-05-25 12:29:26,360:INFO:             prophet: Not installed
2023-05-25 12:29:26,360:INFO:None
2023-05-25 12:29:26,360:INFO:Set up data.
2023-05-25 12:29:26,546:INFO:Set up train/test split.
2023-05-25 12:29:26,636:INFO:Set up index.
2023-05-25 12:29:26,638:INFO:Set up folding strategy.
2023-05-25 12:29:26,639:INFO:Assigning column types.
2023-05-25 12:29:26,689:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-25 12:29:26,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 12:29:26,739:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:29:26,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:26,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:26,826:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 12:29:26,826:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:29:26,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:26,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:26,850:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-25 12:29:26,889:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:29:26,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:26,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:26,950:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:29:26,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:26,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:26,973:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-25 12:29:27,033:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:27,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:27,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:27,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:27,098:INFO:Preparing preprocessing pipeline...
2023-05-25 12:29:27,104:INFO:Set up label encoding.
2023-05-25 12:29:27,104:INFO:Set up simple imputation.
2023-05-25 12:29:27,104:INFO:Set up imbalanced handling.
2023-05-25 12:29:27,111:INFO:Set up column name cleaning.
2023-05-25 12:29:27,603:INFO:Finished creating preprocessing pipeline.
2023-05-25 12:29:27,623:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-25 12:29:27,623:INFO:Creating final display dataframe.
2023-05-25 12:29:28,281:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 511)
5        Transformed data shape              (41153, 511)
6   Transformed train set shape              (30052, 511)
7    Transformed test set shape              (11101, 511)
8              Numeric features                       510
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      f6a9
2023-05-25 12:29:28,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:28,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:28,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:28,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:29:28,460:INFO:setup() successfully completed in 2.51s...............
2023-05-25 12:29:28,508:INFO:Initializing compare_models()
2023-05-25 12:29:28,508:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002274F675E40>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002274F675E40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-25 12:29:28,508:INFO:Checking exceptions
2023-05-25 12:29:28,553:INFO:Preparing display monitor
2023-05-25 12:29:28,576:INFO:Initializing Logistic Regression
2023-05-25 12:29:28,576:INFO:Total runtime is 0.0 minutes
2023-05-25 12:29:28,580:INFO:SubProcess create_model() called ==================================
2023-05-25 12:29:28,580:INFO:Initializing create_model()
2023-05-25 12:29:28,580:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002274F675E40>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F2BA230>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:29:28,581:INFO:Checking exceptions
2023-05-25 12:29:28,581:INFO:Importing libraries
2023-05-25 12:29:28,581:INFO:Copying training dataset
2023-05-25 12:29:28,664:INFO:Defining folds
2023-05-25 12:29:28,665:INFO:Declaring metric variables
2023-05-25 12:29:28,667:INFO:Importing untrained model
2023-05-25 12:29:28,670:INFO:Logistic Regression Imported successfully
2023-05-25 12:29:28,678:INFO:Starting cross validation
2023-05-25 12:29:28,682:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:30:32,735:INFO:PyCaret ClassificationExperiment
2023-05-25 12:30:32,735:INFO:Logging name: clf-default-name
2023-05-25 12:30:32,735:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-25 12:30:32,735:INFO:version 3.0.2
2023-05-25 12:30:32,735:INFO:Initializing setup()
2023-05-25 12:30:32,735:INFO:self.USI: 8f3a
2023-05-25 12:30:32,735:INFO:self._variable_keys: {'html_param', 'X', 'y', 'X_train', 'memory', '_ml_usecase', 'fold_shuffle_param', 'gpu_n_jobs_param', 'n_jobs_param', 'fold_generator', 'is_multiclass', 'y_train', 'fix_imbalance', 'idx', '_available_plots', 'exp_name_log', 'X_test', 'USI', 'seed', 'target_param', 'gpu_param', 'data', 'pipeline', 'log_plots_param', 'logging_param', 'y_test', 'fold_groups_param', 'exp_id'}
2023-05-25 12:30:32,735:INFO:Checking environment
2023-05-25 12:30:32,735:INFO:python_version: 3.10.11
2023-05-25 12:30:32,735:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-25 12:30:32,735:INFO:machine: AMD64
2023-05-25 12:30:32,735:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-25 12:30:32,737:INFO:Memory: svmem(total=16889774080, available=8761454592, percent=48.1, used=8128319488, free=8761454592)
2023-05-25 12:30:32,738:INFO:Physical Core: 4
2023-05-25 12:30:32,738:INFO:Logical Core: 8
2023-05-25 12:30:32,738:INFO:Checking libraries
2023-05-25 12:30:32,738:INFO:System:
2023-05-25 12:30:32,738:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-25 12:30:32,738:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-25 12:30:32,738:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-25 12:30:32,738:INFO:PyCaret required dependencies:
2023-05-25 12:30:32,738:INFO:                 pip: 23.0.1
2023-05-25 12:30:32,738:INFO:          setuptools: 66.0.0
2023-05-25 12:30:32,738:INFO:             pycaret: 3.0.2
2023-05-25 12:30:32,738:INFO:             IPython: 8.13.2
2023-05-25 12:30:32,738:INFO:          ipywidgets: 8.0.6
2023-05-25 12:30:32,738:INFO:                tqdm: 4.65.0
2023-05-25 12:30:32,738:INFO:               numpy: 1.23.5
2023-05-25 12:30:32,738:INFO:              pandas: 1.5.3
2023-05-25 12:30:32,738:INFO:              jinja2: 3.1.2
2023-05-25 12:30:32,738:INFO:               scipy: 1.10.1
2023-05-25 12:30:32,738:INFO:              joblib: 1.2.0
2023-05-25 12:30:32,738:INFO:             sklearn: 1.2.2
2023-05-25 12:30:32,738:INFO:                pyod: 1.0.9
2023-05-25 12:30:32,738:INFO:            imblearn: 0.10.1
2023-05-25 12:30:32,738:INFO:   category_encoders: 2.6.1
2023-05-25 12:30:32,738:INFO:            lightgbm: 3.3.5
2023-05-25 12:30:32,739:INFO:               numba: 0.57.0
2023-05-25 12:30:32,739:INFO:            requests: 2.31.0
2023-05-25 12:30:32,739:INFO:          matplotlib: 3.7.1
2023-05-25 12:30:32,739:INFO:          scikitplot: 0.3.7
2023-05-25 12:30:32,739:INFO:         yellowbrick: 1.5
2023-05-25 12:30:32,739:INFO:              plotly: 5.14.1
2023-05-25 12:30:32,739:INFO:             kaleido: 0.2.1
2023-05-25 12:30:32,739:INFO:         statsmodels: 0.14.0
2023-05-25 12:30:32,739:INFO:              sktime: 0.17.0
2023-05-25 12:30:32,739:INFO:               tbats: 1.1.3
2023-05-25 12:30:32,739:INFO:            pmdarima: 2.0.3
2023-05-25 12:30:32,739:INFO:              psutil: 5.9.5
2023-05-25 12:30:32,739:INFO:PyCaret optional dependencies:
2023-05-25 12:30:32,739:INFO:                shap: Not installed
2023-05-25 12:30:32,739:INFO:           interpret: Not installed
2023-05-25 12:30:32,739:INFO:                umap: Not installed
2023-05-25 12:30:32,739:INFO:    pandas_profiling: Not installed
2023-05-25 12:30:32,739:INFO:  explainerdashboard: Not installed
2023-05-25 12:30:32,739:INFO:             autoviz: Not installed
2023-05-25 12:30:32,739:INFO:           fairlearn: Not installed
2023-05-25 12:30:32,739:INFO:             xgboost: Not installed
2023-05-25 12:30:32,739:INFO:            catboost: Not installed
2023-05-25 12:30:32,739:INFO:              kmodes: Not installed
2023-05-25 12:30:32,739:INFO:             mlxtend: Not installed
2023-05-25 12:30:32,739:INFO:       statsforecast: Not installed
2023-05-25 12:30:32,739:INFO:        tune_sklearn: 0.4.5
2023-05-25 12:30:32,739:INFO:                 ray: 2.4.0
2023-05-25 12:30:32,739:INFO:            hyperopt: 0.2.7
2023-05-25 12:30:32,739:INFO:              optuna: 3.1.1
2023-05-25 12:30:32,739:INFO:               skopt: 0.9.0
2023-05-25 12:30:32,739:INFO:              mlflow: Not installed
2023-05-25 12:30:32,739:INFO:              gradio: Not installed
2023-05-25 12:30:32,739:INFO:             fastapi: Not installed
2023-05-25 12:30:32,739:INFO:             uvicorn: Not installed
2023-05-25 12:30:32,739:INFO:              m2cgen: Not installed
2023-05-25 12:30:32,739:INFO:           evidently: Not installed
2023-05-25 12:30:32,739:INFO:               fugue: Not installed
2023-05-25 12:30:32,739:INFO:           streamlit: Not installed
2023-05-25 12:30:32,739:INFO:             prophet: Not installed
2023-05-25 12:30:32,739:INFO:None
2023-05-25 12:30:32,740:INFO:Set up data.
2023-05-25 12:30:32,931:INFO:Set up train/test split.
2023-05-25 12:30:33,021:INFO:Set up index.
2023-05-25 12:30:33,023:INFO:Set up folding strategy.
2023-05-25 12:30:33,023:INFO:Assigning column types.
2023-05-25 12:30:33,073:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-25 12:30:33,111:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 12:30:33,111:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:30:33,134:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,135:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 12:30:33,172:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:30:33,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,196:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-25 12:30:33,232:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:30:33,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,298:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 12:30:33,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,321:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-25 12:30:33,382:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:33,445:INFO:Preparing preprocessing pipeline...
2023-05-25 12:30:33,451:INFO:Set up label encoding.
2023-05-25 12:30:33,451:INFO:Set up simple imputation.
2023-05-25 12:30:33,451:INFO:Set up imbalanced handling.
2023-05-25 12:30:33,457:INFO:Set up column name cleaning.
2023-05-25 12:30:33,944:INFO:Finished creating preprocessing pipeline.
2023-05-25 12:30:33,952:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-25 12:30:33,952:INFO:Creating final display dataframe.
2023-05-25 12:30:34,488:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 511)
5        Transformed data shape              (41153, 511)
6   Transformed train set shape              (30052, 511)
7    Transformed test set shape              (11101, 511)
8              Numeric features                       510
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      8f3a
2023-05-25 12:30:34,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:34,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:34,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:34,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 12:30:34,698:INFO:setup() successfully completed in 2.39s...............
2023-05-25 12:30:34,758:INFO:Initializing compare_models()
2023-05-25 12:30:34,759:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-25 12:30:34,759:INFO:Checking exceptions
2023-05-25 12:30:34,811:INFO:Preparing display monitor
2023-05-25 12:30:34,836:INFO:Initializing Logistic Regression
2023-05-25 12:30:34,836:INFO:Total runtime is 0.0 minutes
2023-05-25 12:30:34,839:INFO:SubProcess create_model() called ==================================
2023-05-25 12:30:34,840:INFO:Initializing create_model()
2023-05-25 12:30:34,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:30:34,840:INFO:Checking exceptions
2023-05-25 12:30:34,840:INFO:Importing libraries
2023-05-25 12:30:34,842:INFO:Copying training dataset
2023-05-25 12:30:34,980:INFO:Defining folds
2023-05-25 12:30:34,981:INFO:Declaring metric variables
2023-05-25 12:30:34,989:INFO:Importing untrained model
2023-05-25 12:30:34,995:INFO:Logistic Regression Imported successfully
2023-05-25 12:30:35,002:INFO:Starting cross validation
2023-05-25 12:30:35,005:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:30:46,039:INFO:Calculating mean and std
2023-05-25 12:30:46,040:INFO:Creating metrics dataframe
2023-05-25 12:30:46,568:INFO:Uploading results into container
2023-05-25 12:30:46,568:INFO:Uploading model into container now
2023-05-25 12:30:46,569:INFO:_master_model_container: 1
2023-05-25 12:30:46,569:INFO:_display_container: 2
2023-05-25 12:30:46,569:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-25 12:30:46,569:INFO:create_model() successfully completed......................................
2023-05-25 12:30:46,671:INFO:SubProcess create_model() end ==================================
2023-05-25 12:30:46,672:INFO:Creating metrics dataframe
2023-05-25 12:30:46,683:INFO:Initializing K Neighbors Classifier
2023-05-25 12:30:46,683:INFO:Total runtime is 0.19744712114334106 minutes
2023-05-25 12:30:46,687:INFO:SubProcess create_model() called ==================================
2023-05-25 12:30:46,688:INFO:Initializing create_model()
2023-05-25 12:30:46,688:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:30:46,688:INFO:Checking exceptions
2023-05-25 12:30:46,688:INFO:Importing libraries
2023-05-25 12:30:46,688:INFO:Copying training dataset
2023-05-25 12:30:46,763:INFO:Defining folds
2023-05-25 12:30:46,763:INFO:Declaring metric variables
2023-05-25 12:30:46,766:INFO:Importing untrained model
2023-05-25 12:30:46,770:INFO:K Neighbors Classifier Imported successfully
2023-05-25 12:30:46,778:INFO:Starting cross validation
2023-05-25 12:30:46,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:31:03,825:INFO:Calculating mean and std
2023-05-25 12:31:03,829:INFO:Creating metrics dataframe
2023-05-25 12:31:04,366:INFO:Uploading results into container
2023-05-25 12:31:04,367:INFO:Uploading model into container now
2023-05-25 12:31:04,368:INFO:_master_model_container: 2
2023-05-25 12:31:04,368:INFO:_display_container: 2
2023-05-25 12:31:04,368:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-25 12:31:04,368:INFO:create_model() successfully completed......................................
2023-05-25 12:31:04,457:INFO:SubProcess create_model() end ==================================
2023-05-25 12:31:04,457:INFO:Creating metrics dataframe
2023-05-25 12:31:04,466:INFO:Initializing Naive Bayes
2023-05-25 12:31:04,466:INFO:Total runtime is 0.49383729696273804 minutes
2023-05-25 12:31:04,470:INFO:SubProcess create_model() called ==================================
2023-05-25 12:31:04,470:INFO:Initializing create_model()
2023-05-25 12:31:04,470:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:31:04,470:INFO:Checking exceptions
2023-05-25 12:31:04,470:INFO:Importing libraries
2023-05-25 12:31:04,470:INFO:Copying training dataset
2023-05-25 12:31:04,540:INFO:Defining folds
2023-05-25 12:31:04,540:INFO:Declaring metric variables
2023-05-25 12:31:04,543:INFO:Importing untrained model
2023-05-25 12:31:04,548:INFO:Naive Bayes Imported successfully
2023-05-25 12:31:04,554:INFO:Starting cross validation
2023-05-25 12:31:04,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:31:11,149:INFO:Calculating mean and std
2023-05-25 12:31:11,150:INFO:Creating metrics dataframe
2023-05-25 12:31:11,668:INFO:Uploading results into container
2023-05-25 12:31:11,669:INFO:Uploading model into container now
2023-05-25 12:31:11,669:INFO:_master_model_container: 3
2023-05-25 12:31:11,669:INFO:_display_container: 2
2023-05-25 12:31:11,670:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-25 12:31:11,670:INFO:create_model() successfully completed......................................
2023-05-25 12:31:11,762:INFO:SubProcess create_model() end ==================================
2023-05-25 12:31:11,762:INFO:Creating metrics dataframe
2023-05-25 12:31:11,771:INFO:Initializing Decision Tree Classifier
2023-05-25 12:31:11,771:INFO:Total runtime is 0.6155796448389689 minutes
2023-05-25 12:31:11,774:INFO:SubProcess create_model() called ==================================
2023-05-25 12:31:11,774:INFO:Initializing create_model()
2023-05-25 12:31:11,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:31:11,775:INFO:Checking exceptions
2023-05-25 12:31:11,775:INFO:Importing libraries
2023-05-25 12:31:11,775:INFO:Copying training dataset
2023-05-25 12:31:11,845:INFO:Defining folds
2023-05-25 12:31:11,846:INFO:Declaring metric variables
2023-05-25 12:31:11,850:INFO:Importing untrained model
2023-05-25 12:31:11,854:INFO:Decision Tree Classifier Imported successfully
2023-05-25 12:31:11,860:INFO:Starting cross validation
2023-05-25 12:31:11,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:31:18,353:INFO:Calculating mean and std
2023-05-25 12:31:18,354:INFO:Creating metrics dataframe
2023-05-25 12:31:18,865:INFO:Uploading results into container
2023-05-25 12:31:18,866:INFO:Uploading model into container now
2023-05-25 12:31:18,866:INFO:_master_model_container: 4
2023-05-25 12:31:18,866:INFO:_display_container: 2
2023-05-25 12:31:18,867:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-25 12:31:18,867:INFO:create_model() successfully completed......................................
2023-05-25 12:31:18,957:INFO:SubProcess create_model() end ==================================
2023-05-25 12:31:18,957:INFO:Creating metrics dataframe
2023-05-25 12:31:18,969:INFO:Initializing SVM - Linear Kernel
2023-05-25 12:31:18,969:INFO:Total runtime is 0.7355527559916178 minutes
2023-05-25 12:31:18,972:INFO:SubProcess create_model() called ==================================
2023-05-25 12:31:18,972:INFO:Initializing create_model()
2023-05-25 12:31:18,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:31:18,973:INFO:Checking exceptions
2023-05-25 12:31:18,973:INFO:Importing libraries
2023-05-25 12:31:18,973:INFO:Copying training dataset
2023-05-25 12:31:19,042:INFO:Defining folds
2023-05-25 12:31:19,042:INFO:Declaring metric variables
2023-05-25 12:31:19,046:INFO:Importing untrained model
2023-05-25 12:31:19,050:INFO:SVM - Linear Kernel Imported successfully
2023-05-25 12:31:19,057:INFO:Starting cross validation
2023-05-25 12:31:19,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:31:20,410:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:31:20,438:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:31:20,439:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:31:20,485:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:31:20,485:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:31:20,506:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:31:20,600:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:31:22,651:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:31:22,703:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 12:31:25,308:INFO:Calculating mean and std
2023-05-25 12:31:25,309:INFO:Creating metrics dataframe
2023-05-25 12:31:25,935:INFO:Uploading results into container
2023-05-25 12:31:25,935:INFO:Uploading model into container now
2023-05-25 12:31:25,936:INFO:_master_model_container: 5
2023-05-25 12:31:25,936:INFO:_display_container: 2
2023-05-25 12:31:25,936:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-25 12:31:25,936:INFO:create_model() successfully completed......................................
2023-05-25 12:31:26,028:INFO:SubProcess create_model() end ==================================
2023-05-25 12:31:26,028:INFO:Creating metrics dataframe
2023-05-25 12:31:26,039:INFO:Initializing Ridge Classifier
2023-05-25 12:31:26,039:INFO:Total runtime is 0.8533832867940268 minutes
2023-05-25 12:31:26,041:INFO:SubProcess create_model() called ==================================
2023-05-25 12:31:26,043:INFO:Initializing create_model()
2023-05-25 12:31:26,044:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:31:26,044:INFO:Checking exceptions
2023-05-25 12:31:26,044:INFO:Importing libraries
2023-05-25 12:31:26,044:INFO:Copying training dataset
2023-05-25 12:31:26,114:INFO:Defining folds
2023-05-25 12:31:26,114:INFO:Declaring metric variables
2023-05-25 12:31:26,118:INFO:Importing untrained model
2023-05-25 12:31:26,122:INFO:Ridge Classifier Imported successfully
2023-05-25 12:31:26,129:INFO:Starting cross validation
2023-05-25 12:31:26,133:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:31:27,422:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:31:27,493:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:31:27,533:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:31:27,580:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:31:27,591:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:31:27,608:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:31:27,621:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:31:27,629:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:31:29,587:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:31:29,674:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 12:31:32,363:INFO:Calculating mean and std
2023-05-25 12:31:32,364:INFO:Creating metrics dataframe
2023-05-25 12:31:32,874:INFO:Uploading results into container
2023-05-25 12:31:32,876:INFO:Uploading model into container now
2023-05-25 12:31:32,877:INFO:_master_model_container: 6
2023-05-25 12:31:32,877:INFO:_display_container: 2
2023-05-25 12:31:32,878:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-25 12:31:32,878:INFO:create_model() successfully completed......................................
2023-05-25 12:31:32,968:INFO:SubProcess create_model() end ==================================
2023-05-25 12:31:32,968:INFO:Creating metrics dataframe
2023-05-25 12:31:32,978:INFO:Initializing Random Forest Classifier
2023-05-25 12:31:32,978:INFO:Total runtime is 0.9690373341242473 minutes
2023-05-25 12:31:32,982:INFO:SubProcess create_model() called ==================================
2023-05-25 12:31:32,982:INFO:Initializing create_model()
2023-05-25 12:31:32,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:31:32,982:INFO:Checking exceptions
2023-05-25 12:31:32,982:INFO:Importing libraries
2023-05-25 12:31:32,982:INFO:Copying training dataset
2023-05-25 12:31:33,051:INFO:Defining folds
2023-05-25 12:31:33,051:INFO:Declaring metric variables
2023-05-25 12:31:33,054:INFO:Importing untrained model
2023-05-25 12:31:33,058:INFO:Random Forest Classifier Imported successfully
2023-05-25 12:31:33,066:INFO:Starting cross validation
2023-05-25 12:31:33,069:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:31:41,050:INFO:Calculating mean and std
2023-05-25 12:31:41,051:INFO:Creating metrics dataframe
2023-05-25 12:31:41,569:INFO:Uploading results into container
2023-05-25 12:31:41,570:INFO:Uploading model into container now
2023-05-25 12:31:41,570:INFO:_master_model_container: 7
2023-05-25 12:31:41,570:INFO:_display_container: 2
2023-05-25 12:31:41,571:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 12:31:41,571:INFO:create_model() successfully completed......................................
2023-05-25 12:31:41,658:INFO:SubProcess create_model() end ==================================
2023-05-25 12:31:41,659:INFO:Creating metrics dataframe
2023-05-25 12:31:41,670:INFO:Initializing Quadratic Discriminant Analysis
2023-05-25 12:31:41,670:INFO:Total runtime is 1.1139106074968974 minutes
2023-05-25 12:31:41,674:INFO:SubProcess create_model() called ==================================
2023-05-25 12:31:41,674:INFO:Initializing create_model()
2023-05-25 12:31:41,674:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:31:41,674:INFO:Checking exceptions
2023-05-25 12:31:41,674:INFO:Importing libraries
2023-05-25 12:31:41,674:INFO:Copying training dataset
2023-05-25 12:31:41,745:INFO:Defining folds
2023-05-25 12:31:41,745:INFO:Declaring metric variables
2023-05-25 12:31:41,750:INFO:Importing untrained model
2023-05-25 12:31:41,753:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-25 12:31:41,759:INFO:Starting cross validation
2023-05-25 12:31:41,763:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:31:48,701:INFO:Calculating mean and std
2023-05-25 12:31:48,702:INFO:Creating metrics dataframe
2023-05-25 12:31:49,247:INFO:Uploading results into container
2023-05-25 12:31:49,247:INFO:Uploading model into container now
2023-05-25 12:31:49,248:INFO:_master_model_container: 8
2023-05-25 12:31:49,248:INFO:_display_container: 2
2023-05-25 12:31:49,248:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-25 12:31:49,248:INFO:create_model() successfully completed......................................
2023-05-25 12:31:49,338:INFO:SubProcess create_model() end ==================================
2023-05-25 12:31:49,338:INFO:Creating metrics dataframe
2023-05-25 12:31:49,350:INFO:Initializing Ada Boost Classifier
2023-05-25 12:31:49,350:INFO:Total runtime is 1.2419113039970398 minutes
2023-05-25 12:31:49,353:INFO:SubProcess create_model() called ==================================
2023-05-25 12:31:49,354:INFO:Initializing create_model()
2023-05-25 12:31:49,354:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:31:49,354:INFO:Checking exceptions
2023-05-25 12:31:49,354:INFO:Importing libraries
2023-05-25 12:31:49,354:INFO:Copying training dataset
2023-05-25 12:31:49,424:INFO:Defining folds
2023-05-25 12:31:49,424:INFO:Declaring metric variables
2023-05-25 12:31:49,428:INFO:Importing untrained model
2023-05-25 12:31:49,432:INFO:Ada Boost Classifier Imported successfully
2023-05-25 12:31:49,438:INFO:Starting cross validation
2023-05-25 12:31:49,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:31:57,806:INFO:Calculating mean and std
2023-05-25 12:31:57,807:INFO:Creating metrics dataframe
2023-05-25 12:31:58,322:INFO:Uploading results into container
2023-05-25 12:31:58,322:INFO:Uploading model into container now
2023-05-25 12:31:58,322:INFO:_master_model_container: 9
2023-05-25 12:31:58,322:INFO:_display_container: 2
2023-05-25 12:31:58,322:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 12:31:58,322:INFO:create_model() successfully completed......................................
2023-05-25 12:31:58,416:INFO:SubProcess create_model() end ==================================
2023-05-25 12:31:58,416:INFO:Creating metrics dataframe
2023-05-25 12:31:58,426:INFO:Initializing Gradient Boosting Classifier
2023-05-25 12:31:58,426:INFO:Total runtime is 1.3931629101435343 minutes
2023-05-25 12:31:58,442:INFO:SubProcess create_model() called ==================================
2023-05-25 12:31:58,443:INFO:Initializing create_model()
2023-05-25 12:31:58,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:31:58,443:INFO:Checking exceptions
2023-05-25 12:31:58,444:INFO:Importing libraries
2023-05-25 12:31:58,444:INFO:Copying training dataset
2023-05-25 12:31:58,514:INFO:Defining folds
2023-05-25 12:31:58,514:INFO:Declaring metric variables
2023-05-25 12:31:58,517:INFO:Importing untrained model
2023-05-25 12:31:58,521:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 12:31:58,528:INFO:Starting cross validation
2023-05-25 12:31:58,531:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:32:05,474:INFO:Calculating mean and std
2023-05-25 12:32:05,475:INFO:Creating metrics dataframe
2023-05-25 12:32:05,998:INFO:Uploading results into container
2023-05-25 12:32:05,999:INFO:Uploading model into container now
2023-05-25 12:32:05,999:INFO:_master_model_container: 10
2023-05-25 12:32:05,999:INFO:_display_container: 2
2023-05-25 12:32:05,999:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 12:32:05,999:INFO:create_model() successfully completed......................................
2023-05-25 12:32:06,089:INFO:SubProcess create_model() end ==================================
2023-05-25 12:32:06,089:INFO:Creating metrics dataframe
2023-05-25 12:32:06,100:INFO:Initializing Linear Discriminant Analysis
2023-05-25 12:32:06,100:INFO:Total runtime is 1.521064857641856 minutes
2023-05-25 12:32:06,104:INFO:SubProcess create_model() called ==================================
2023-05-25 12:32:06,104:INFO:Initializing create_model()
2023-05-25 12:32:06,104:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:32:06,104:INFO:Checking exceptions
2023-05-25 12:32:06,104:INFO:Importing libraries
2023-05-25 12:32:06,104:INFO:Copying training dataset
2023-05-25 12:32:06,173:INFO:Defining folds
2023-05-25 12:32:06,174:INFO:Declaring metric variables
2023-05-25 12:32:06,178:INFO:Importing untrained model
2023-05-25 12:32:06,182:INFO:Linear Discriminant Analysis Imported successfully
2023-05-25 12:32:06,188:INFO:Starting cross validation
2023-05-25 12:32:06,192:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:32:12,823:INFO:Calculating mean and std
2023-05-25 12:32:12,824:INFO:Creating metrics dataframe
2023-05-25 12:32:13,358:INFO:Uploading results into container
2023-05-25 12:32:13,359:INFO:Uploading model into container now
2023-05-25 12:32:13,359:INFO:_master_model_container: 11
2023-05-25 12:32:13,359:INFO:_display_container: 2
2023-05-25 12:32:13,359:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-25 12:32:13,359:INFO:create_model() successfully completed......................................
2023-05-25 12:32:13,451:INFO:SubProcess create_model() end ==================================
2023-05-25 12:32:13,451:INFO:Creating metrics dataframe
2023-05-25 12:32:13,463:INFO:Initializing Extra Trees Classifier
2023-05-25 12:32:13,464:INFO:Total runtime is 1.6438074350357057 minutes
2023-05-25 12:32:13,468:INFO:SubProcess create_model() called ==================================
2023-05-25 12:32:13,468:INFO:Initializing create_model()
2023-05-25 12:32:13,468:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:32:13,469:INFO:Checking exceptions
2023-05-25 12:32:13,469:INFO:Importing libraries
2023-05-25 12:32:13,469:INFO:Copying training dataset
2023-05-25 12:32:13,537:INFO:Defining folds
2023-05-25 12:32:13,537:INFO:Declaring metric variables
2023-05-25 12:32:13,541:INFO:Importing untrained model
2023-05-25 12:32:13,547:INFO:Extra Trees Classifier Imported successfully
2023-05-25 12:32:13,553:INFO:Starting cross validation
2023-05-25 12:32:13,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:32:23,677:INFO:Calculating mean and std
2023-05-25 12:32:23,679:INFO:Creating metrics dataframe
2023-05-25 12:32:24,254:INFO:Uploading results into container
2023-05-25 12:32:24,254:INFO:Uploading model into container now
2023-05-25 12:32:24,255:INFO:_master_model_container: 12
2023-05-25 12:32:24,255:INFO:_display_container: 2
2023-05-25 12:32:24,255:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 12:32:24,255:INFO:create_model() successfully completed......................................
2023-05-25 12:32:24,350:INFO:SubProcess create_model() end ==================================
2023-05-25 12:32:24,350:INFO:Creating metrics dataframe
2023-05-25 12:32:24,365:INFO:Initializing Light Gradient Boosting Machine
2023-05-25 12:32:24,365:INFO:Total runtime is 1.8254815737406414 minutes
2023-05-25 12:32:24,369:INFO:SubProcess create_model() called ==================================
2023-05-25 12:32:24,369:INFO:Initializing create_model()
2023-05-25 12:32:24,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:32:24,369:INFO:Checking exceptions
2023-05-25 12:32:24,369:INFO:Importing libraries
2023-05-25 12:32:24,370:INFO:Copying training dataset
2023-05-25 12:32:24,452:INFO:Defining folds
2023-05-25 12:32:24,452:INFO:Declaring metric variables
2023-05-25 12:32:24,456:INFO:Importing untrained model
2023-05-25 12:32:24,459:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 12:32:24,468:INFO:Starting cross validation
2023-05-25 12:32:24,472:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:32:31,149:INFO:Calculating mean and std
2023-05-25 12:32:31,150:INFO:Creating metrics dataframe
2023-05-25 12:32:31,663:INFO:Uploading results into container
2023-05-25 12:32:31,664:INFO:Uploading model into container now
2023-05-25 12:32:31,664:INFO:_master_model_container: 13
2023-05-25 12:32:31,664:INFO:_display_container: 2
2023-05-25 12:32:31,665:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 12:32:31,665:INFO:create_model() successfully completed......................................
2023-05-25 12:32:31,755:INFO:SubProcess create_model() end ==================================
2023-05-25 12:32:31,755:INFO:Creating metrics dataframe
2023-05-25 12:32:31,769:INFO:Initializing Dummy Classifier
2023-05-25 12:32:31,769:INFO:Total runtime is 1.948880918820699 minutes
2023-05-25 12:32:31,772:INFO:SubProcess create_model() called ==================================
2023-05-25 12:32:31,772:INFO:Initializing create_model()
2023-05-25 12:32:31,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002274F72A680>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:32:31,772:INFO:Checking exceptions
2023-05-25 12:32:31,773:INFO:Importing libraries
2023-05-25 12:32:31,773:INFO:Copying training dataset
2023-05-25 12:32:31,841:INFO:Defining folds
2023-05-25 12:32:31,841:INFO:Declaring metric variables
2023-05-25 12:32:31,844:INFO:Importing untrained model
2023-05-25 12:32:31,850:INFO:Dummy Classifier Imported successfully
2023-05-25 12:32:31,856:INFO:Starting cross validation
2023-05-25 12:32:31,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 12:32:33,319:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:32:33,319:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:32:33,327:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:32:33,342:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:32:33,361:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:32:33,373:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:32:33,398:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:32:33,399:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:32:35,625:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:32:35,760:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 12:32:38,281:INFO:Calculating mean and std
2023-05-25 12:32:38,282:INFO:Creating metrics dataframe
2023-05-25 12:32:38,803:INFO:Uploading results into container
2023-05-25 12:32:38,804:INFO:Uploading model into container now
2023-05-25 12:32:38,804:INFO:_master_model_container: 14
2023-05-25 12:32:38,805:INFO:_display_container: 2
2023-05-25 12:32:38,805:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-25 12:32:38,805:INFO:create_model() successfully completed......................................
2023-05-25 12:32:38,894:INFO:SubProcess create_model() end ==================================
2023-05-25 12:32:38,894:INFO:Creating metrics dataframe
2023-05-25 12:32:38,916:INFO:Initializing create_model()
2023-05-25 12:32:38,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:32:38,917:INFO:Checking exceptions
2023-05-25 12:32:38,919:INFO:Importing libraries
2023-05-25 12:32:38,919:INFO:Copying training dataset
2023-05-25 12:32:38,987:INFO:Defining folds
2023-05-25 12:32:38,987:INFO:Declaring metric variables
2023-05-25 12:32:38,987:INFO:Importing untrained model
2023-05-25 12:32:38,987:INFO:Declaring custom model
2023-05-25 12:32:38,988:INFO:Random Forest Classifier Imported successfully
2023-05-25 12:32:38,990:INFO:Cross validation set to False
2023-05-25 12:32:38,990:INFO:Fitting Model
2023-05-25 12:32:40,306:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 12:32:40,306:INFO:create_model() successfully completed......................................
2023-05-25 12:32:40,403:INFO:Initializing create_model()
2023-05-25 12:32:40,403:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:32:40,403:INFO:Checking exceptions
2023-05-25 12:32:40,405:INFO:Importing libraries
2023-05-25 12:32:40,405:INFO:Copying training dataset
2023-05-25 12:32:40,473:INFO:Defining folds
2023-05-25 12:32:40,474:INFO:Declaring metric variables
2023-05-25 12:32:40,474:INFO:Importing untrained model
2023-05-25 12:32:40,474:INFO:Declaring custom model
2023-05-25 12:32:40,474:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 12:32:40,477:INFO:Cross validation set to False
2023-05-25 12:32:40,477:INFO:Fitting Model
2023-05-25 12:32:41,487:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 12:32:41,488:INFO:create_model() successfully completed......................................
2023-05-25 12:32:41,583:INFO:Initializing create_model()
2023-05-25 12:32:41,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:32:41,583:INFO:Checking exceptions
2023-05-25 12:32:41,585:INFO:Importing libraries
2023-05-25 12:32:41,585:INFO:Copying training dataset
2023-05-25 12:32:41,652:INFO:Defining folds
2023-05-25 12:32:41,652:INFO:Declaring metric variables
2023-05-25 12:32:41,653:INFO:Importing untrained model
2023-05-25 12:32:41,653:INFO:Declaring custom model
2023-05-25 12:32:41,653:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 12:32:41,656:INFO:Cross validation set to False
2023-05-25 12:32:41,656:INFO:Fitting Model
2023-05-25 12:32:42,604:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 12:32:42,604:INFO:create_model() successfully completed......................................
2023-05-25 12:32:42,702:INFO:Initializing create_model()
2023-05-25 12:32:42,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:32:42,703:INFO:Checking exceptions
2023-05-25 12:32:42,705:INFO:Importing libraries
2023-05-25 12:32:42,705:INFO:Copying training dataset
2023-05-25 12:32:42,773:INFO:Defining folds
2023-05-25 12:32:42,773:INFO:Declaring metric variables
2023-05-25 12:32:42,773:INFO:Importing untrained model
2023-05-25 12:32:42,773:INFO:Declaring custom model
2023-05-25 12:32:42,773:INFO:Ada Boost Classifier Imported successfully
2023-05-25 12:32:42,776:INFO:Cross validation set to False
2023-05-25 12:32:42,776:INFO:Fitting Model
2023-05-25 12:32:43,746:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 12:32:43,746:INFO:create_model() successfully completed......................................
2023-05-25 12:32:43,843:INFO:Initializing create_model()
2023-05-25 12:32:43,843:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 12:32:43,844:INFO:Checking exceptions
2023-05-25 12:32:43,847:INFO:Importing libraries
2023-05-25 12:32:43,847:INFO:Copying training dataset
2023-05-25 12:32:43,915:INFO:Defining folds
2023-05-25 12:32:43,915:INFO:Declaring metric variables
2023-05-25 12:32:43,915:INFO:Importing untrained model
2023-05-25 12:32:43,915:INFO:Declaring custom model
2023-05-25 12:32:43,916:INFO:Extra Trees Classifier Imported successfully
2023-05-25 12:32:43,918:INFO:Cross validation set to False
2023-05-25 12:32:43,918:INFO:Fitting Model
2023-05-25 12:32:45,190:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 12:32:45,190:INFO:create_model() successfully completed......................................
2023-05-25 12:32:45,307:INFO:_master_model_container: 14
2023-05-25 12:32:45,307:INFO:_display_container: 2
2023-05-25 12:32:45,309:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)]
2023-05-25 12:32:45,309:INFO:compare_models() successfully completed......................................
2023-05-25 12:32:45,774:INFO:Initializing predict_model()
2023-05-25 12:32:45,774:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002274F14B490>)
2023-05-25 12:32:45,774:INFO:Checking exceptions
2023-05-25 12:32:45,774:INFO:Preloading libraries
2023-05-25 12:32:45,776:INFO:Set up data.
2023-05-25 12:32:45,940:INFO:Set up index.
2023-05-25 12:32:46,455:INFO:Initializing save_model()
2023-05-25 12:32:46,455:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=notune_model0, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 12:32:46,455:INFO:Adding model into prep_pipe
2023-05-25 12:32:46,559:INFO:notune_model0.pkl saved in current working directory
2023-05-25 12:32:46,571:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 12:32:46,571:INFO:save_model() successfully completed......................................
2023-05-25 12:32:47,051:INFO:Initializing tune_model()
2023-05-25 12:32:47,051:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000022701F91C90>)
2023-05-25 12:32:47,051:INFO:Checking exceptions
2023-05-25 12:32:47,051:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-25 12:32:47,509:INFO:Copying training dataset
2023-05-25 12:32:47,567:INFO:Checking base model
2023-05-25 12:32:47,567:INFO:Base model : Random Forest Classifier
2023-05-25 12:32:47,572:INFO:Declaring metric variables
2023-05-25 12:32:47,576:INFO:Defining Hyperparameters
2023-05-25 12:32:47,724:INFO:Tuning with n_jobs=-1
2023-05-25 12:32:47,727:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 12:32:47,727:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 12:32:47,730:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-05-25 12:32:47,730:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-25 12:32:47,733:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-25 12:36:14,224:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:36:21,909:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:36:30,576:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:36:31,834:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:36:41,410:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:36:46,855:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:36:49,314:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:36:49,435:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:39:51,467:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:39:55,911:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:40:14,222:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:40:15,557:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:40:26,131:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:40:43,305:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:40:44,095:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:40:45,452:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:43:13,138:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:43:57,547:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:44:04,436:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:44:36,757:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:44:42,944:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:46:38,831:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:46:40,177:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:46:52,351:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:47:38,215:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:47:39,541:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:50:02,185:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:51:14,569:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:51:16,115:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:51:16,126:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 12:51:17,586:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:52:17,881:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:55:04,900:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:57:40,194:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:59:10,333:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 12:59:16,355:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:00:54,879:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:00:56,410:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:03:17,052:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:03:21,685:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:04:32,587:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:04:32,933:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:04:33,912:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:04:35,591:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:04:36,952:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:06:26,617:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:06:33,510:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:07:59,922:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:08:01,393:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:09:24,393:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:09:27,304:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:09:28,587:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:11:11,760:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:11:29,077:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:11:54,400:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:12:10,624:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:12:11,804:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:12:21,456:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:13:56,227:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:13:58,270:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:14:09,048:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:14:28,020:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:15:52,916:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:15:54,268:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:16:59,997:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:18:23,566:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:18:23,695:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:19:31,694:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:22:19,549:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:22:30,931:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:24:07,644:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:25:12,145:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:30:58,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 13:30:58,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 13:30:58,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 13:30:58,085:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 13:30:58,832:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-25 13:31:13,000:INFO:PyCaret ClassificationExperiment
2023-05-25 13:31:13,000:INFO:Logging name: clf-default-name
2023-05-25 13:31:13,000:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-25 13:31:13,000:INFO:version 3.0.2
2023-05-25 13:31:13,000:INFO:Initializing setup()
2023-05-25 13:31:13,000:INFO:self.USI: 2d77
2023-05-25 13:31:13,000:INFO:self._variable_keys: {'idx', 'html_param', 'y', 'fold_shuffle_param', 'X', 'y_train', 'logging_param', 'X_test', 'exp_name_log', 'fix_imbalance', 'pipeline', 'fold_generator', '_available_plots', 'memory', 'USI', 'is_multiclass', 'data', 'n_jobs_param', 'seed', 'gpu_param', 'log_plots_param', '_ml_usecase', 'y_test', 'X_train', 'fold_groups_param', 'gpu_n_jobs_param', 'exp_id', 'target_param'}
2023-05-25 13:31:13,000:INFO:Checking environment
2023-05-25 13:31:13,000:INFO:python_version: 3.10.11
2023-05-25 13:31:13,000:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-25 13:31:13,000:INFO:machine: AMD64
2023-05-25 13:31:13,000:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-25 13:31:13,003:INFO:Memory: svmem(total=16889774080, available=8864280576, percent=47.5, used=8025493504, free=8864280576)
2023-05-25 13:31:13,003:INFO:Physical Core: 4
2023-05-25 13:31:13,003:INFO:Logical Core: 8
2023-05-25 13:31:13,003:INFO:Checking libraries
2023-05-25 13:31:13,003:INFO:System:
2023-05-25 13:31:13,003:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-25 13:31:13,003:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-25 13:31:13,003:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-25 13:31:13,004:INFO:PyCaret required dependencies:
2023-05-25 13:31:13,004:INFO:                 pip: 23.0.1
2023-05-25 13:31:13,004:INFO:          setuptools: 66.0.0
2023-05-25 13:31:13,004:INFO:             pycaret: 3.0.2
2023-05-25 13:31:13,004:INFO:             IPython: 8.13.2
2023-05-25 13:31:13,004:INFO:          ipywidgets: 8.0.6
2023-05-25 13:31:13,004:INFO:                tqdm: 4.65.0
2023-05-25 13:31:13,004:INFO:               numpy: 1.23.5
2023-05-25 13:31:13,004:INFO:              pandas: 1.5.3
2023-05-25 13:31:13,004:INFO:              jinja2: 3.1.2
2023-05-25 13:31:13,004:INFO:               scipy: 1.10.1
2023-05-25 13:31:13,004:INFO:              joblib: 1.2.0
2023-05-25 13:31:13,004:INFO:             sklearn: 1.2.2
2023-05-25 13:31:13,004:INFO:                pyod: 1.0.9
2023-05-25 13:31:13,004:INFO:            imblearn: 0.10.1
2023-05-25 13:31:13,004:INFO:   category_encoders: 2.6.1
2023-05-25 13:31:13,004:INFO:            lightgbm: 3.3.5
2023-05-25 13:31:13,004:INFO:               numba: 0.57.0
2023-05-25 13:31:13,004:INFO:            requests: 2.31.0
2023-05-25 13:31:13,004:INFO:          matplotlib: 3.7.1
2023-05-25 13:31:13,004:INFO:          scikitplot: 0.3.7
2023-05-25 13:31:13,004:INFO:         yellowbrick: 1.5
2023-05-25 13:31:13,004:INFO:              plotly: 5.14.1
2023-05-25 13:31:13,004:INFO:             kaleido: 0.2.1
2023-05-25 13:31:13,004:INFO:         statsmodels: 0.14.0
2023-05-25 13:31:13,005:INFO:              sktime: 0.17.0
2023-05-25 13:31:13,005:INFO:               tbats: 1.1.3
2023-05-25 13:31:13,005:INFO:            pmdarima: 2.0.3
2023-05-25 13:31:13,005:INFO:              psutil: 5.9.5
2023-05-25 13:31:13,005:INFO:PyCaret optional dependencies:
2023-05-25 13:31:13,013:INFO:                shap: Not installed
2023-05-25 13:31:13,013:INFO:           interpret: Not installed
2023-05-25 13:31:13,013:INFO:                umap: Not installed
2023-05-25 13:31:13,013:INFO:    pandas_profiling: Not installed
2023-05-25 13:31:13,013:INFO:  explainerdashboard: Not installed
2023-05-25 13:31:13,013:INFO:             autoviz: Not installed
2023-05-25 13:31:13,014:INFO:           fairlearn: Not installed
2023-05-25 13:31:13,014:INFO:             xgboost: Not installed
2023-05-25 13:31:13,014:INFO:            catboost: Not installed
2023-05-25 13:31:13,014:INFO:              kmodes: Not installed
2023-05-25 13:31:13,014:INFO:             mlxtend: Not installed
2023-05-25 13:31:13,014:INFO:       statsforecast: Not installed
2023-05-25 13:31:13,014:INFO:        tune_sklearn: 0.4.5
2023-05-25 13:31:13,014:INFO:                 ray: 2.4.0
2023-05-25 13:31:13,014:INFO:            hyperopt: 0.2.7
2023-05-25 13:31:13,014:INFO:              optuna: 3.1.1
2023-05-25 13:31:13,014:INFO:               skopt: 0.9.0
2023-05-25 13:31:13,014:INFO:              mlflow: Not installed
2023-05-25 13:31:13,014:INFO:              gradio: Not installed
2023-05-25 13:31:13,014:INFO:             fastapi: Not installed
2023-05-25 13:31:13,014:INFO:             uvicorn: Not installed
2023-05-25 13:31:13,014:INFO:              m2cgen: Not installed
2023-05-25 13:31:13,014:INFO:           evidently: Not installed
2023-05-25 13:31:13,014:INFO:               fugue: Not installed
2023-05-25 13:31:13,014:INFO:           streamlit: Not installed
2023-05-25 13:31:13,014:INFO:             prophet: Not installed
2023-05-25 13:31:13,014:INFO:None
2023-05-25 13:31:13,014:INFO:Set up data.
2023-05-25 13:31:13,206:INFO:Set up train/test split.
2023-05-25 13:31:13,298:INFO:Set up index.
2023-05-25 13:31:13,301:INFO:Set up folding strategy.
2023-05-25 13:31:13,301:INFO:Assigning column types.
2023-05-25 13:31:13,352:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-25 13:31:13,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 13:31:13,402:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 13:31:13,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,452:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,491:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 13:31:13,492:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 13:31:13,516:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,516:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,516:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-25 13:31:13,555:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 13:31:13,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,577:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,617:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 13:31:13,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,641:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-25 13:31:13,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,704:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,769:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:13,771:INFO:Preparing preprocessing pipeline...
2023-05-25 13:31:13,779:INFO:Set up label encoding.
2023-05-25 13:31:13,779:INFO:Set up simple imputation.
2023-05-25 13:31:13,779:INFO:Set up imbalanced handling.
2023-05-25 13:31:13,785:INFO:Set up column name cleaning.
2023-05-25 13:31:14,570:INFO:Finished creating preprocessing pipeline.
2023-05-25 13:31:14,583:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-25 13:31:14,583:INFO:Creating final display dataframe.
2023-05-25 13:31:16,460:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 511)
5        Transformed data shape              (41153, 511)
6   Transformed train set shape              (30052, 511)
7    Transformed test set shape              (11101, 511)
8              Numeric features                       510
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      2d77
2023-05-25 13:31:16,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:16,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:16,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:16,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 13:31:16,631:INFO:setup() successfully completed in 4.23s...............
2023-05-25 13:31:16,694:INFO:Initializing compare_models()
2023-05-25 13:31:16,694:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-25 13:31:16,694:INFO:Checking exceptions
2023-05-25 13:31:16,742:INFO:Preparing display monitor
2023-05-25 13:31:16,792:INFO:Initializing Logistic Regression
2023-05-25 13:31:16,792:INFO:Total runtime is 0.0 minutes
2023-05-25 13:31:16,800:INFO:SubProcess create_model() called ==================================
2023-05-25 13:31:16,800:INFO:Initializing create_model()
2023-05-25 13:31:16,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:31:16,801:INFO:Checking exceptions
2023-05-25 13:31:16,801:INFO:Importing libraries
2023-05-25 13:31:16,801:INFO:Copying training dataset
2023-05-25 13:31:16,912:INFO:Defining folds
2023-05-25 13:31:16,913:INFO:Declaring metric variables
2023-05-25 13:31:16,919:INFO:Importing untrained model
2023-05-25 13:31:16,924:INFO:Logistic Regression Imported successfully
2023-05-25 13:31:16,937:INFO:Starting cross validation
2023-05-25 13:31:16,942:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:32:29,821:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 13:32:30,694:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 13:32:31,089:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 13:32:31,183:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 13:32:31,558:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 13:32:31,642:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 13:32:31,703:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 13:32:31,765:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 13:32:52,416:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 13:32:53,203:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 13:32:53,886:INFO:Calculating mean and std
2023-05-25 13:32:53,887:INFO:Creating metrics dataframe
2023-05-25 13:32:54,427:INFO:Uploading results into container
2023-05-25 13:32:54,428:INFO:Uploading model into container now
2023-05-25 13:32:54,430:INFO:_master_model_container: 1
2023-05-25 13:32:54,430:INFO:_display_container: 2
2023-05-25 13:32:54,431:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-25 13:32:54,431:INFO:create_model() successfully completed......................................
2023-05-25 13:32:54,510:INFO:SubProcess create_model() end ==================================
2023-05-25 13:32:54,510:INFO:Creating metrics dataframe
2023-05-25 13:32:54,520:INFO:Initializing K Neighbors Classifier
2023-05-25 13:32:54,520:INFO:Total runtime is 1.6287937084833781 minutes
2023-05-25 13:32:54,522:INFO:SubProcess create_model() called ==================================
2023-05-25 13:32:54,523:INFO:Initializing create_model()
2023-05-25 13:32:54,523:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:32:54,523:INFO:Checking exceptions
2023-05-25 13:32:54,523:INFO:Importing libraries
2023-05-25 13:32:54,523:INFO:Copying training dataset
2023-05-25 13:32:54,591:INFO:Defining folds
2023-05-25 13:32:54,591:INFO:Declaring metric variables
2023-05-25 13:32:54,595:INFO:Importing untrained model
2023-05-25 13:32:54,599:INFO:K Neighbors Classifier Imported successfully
2023-05-25 13:32:54,607:INFO:Starting cross validation
2023-05-25 13:32:54,611:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:33:14,091:INFO:Calculating mean and std
2023-05-25 13:33:14,092:INFO:Creating metrics dataframe
2023-05-25 13:33:14,625:INFO:Uploading results into container
2023-05-25 13:33:14,626:INFO:Uploading model into container now
2023-05-25 13:33:14,626:INFO:_master_model_container: 2
2023-05-25 13:33:14,626:INFO:_display_container: 2
2023-05-25 13:33:14,626:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-25 13:33:14,626:INFO:create_model() successfully completed......................................
2023-05-25 13:33:14,701:INFO:SubProcess create_model() end ==================================
2023-05-25 13:33:14,701:INFO:Creating metrics dataframe
2023-05-25 13:33:14,711:INFO:Initializing Naive Bayes
2023-05-25 13:33:14,711:INFO:Total runtime is 1.965310831864675 minutes
2023-05-25 13:33:14,716:INFO:SubProcess create_model() called ==================================
2023-05-25 13:33:14,717:INFO:Initializing create_model()
2023-05-25 13:33:14,717:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:33:14,717:INFO:Checking exceptions
2023-05-25 13:33:14,717:INFO:Importing libraries
2023-05-25 13:33:14,717:INFO:Copying training dataset
2023-05-25 13:33:14,786:INFO:Defining folds
2023-05-25 13:33:14,786:INFO:Declaring metric variables
2023-05-25 13:33:14,789:INFO:Importing untrained model
2023-05-25 13:33:14,793:INFO:Naive Bayes Imported successfully
2023-05-25 13:33:14,800:INFO:Starting cross validation
2023-05-25 13:33:14,804:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:33:23,859:INFO:Calculating mean and std
2023-05-25 13:33:23,860:INFO:Creating metrics dataframe
2023-05-25 13:33:24,437:INFO:Uploading results into container
2023-05-25 13:33:24,437:INFO:Uploading model into container now
2023-05-25 13:33:24,438:INFO:_master_model_container: 3
2023-05-25 13:33:24,438:INFO:_display_container: 2
2023-05-25 13:33:24,438:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-25 13:33:24,439:INFO:create_model() successfully completed......................................
2023-05-25 13:33:24,511:INFO:SubProcess create_model() end ==================================
2023-05-25 13:33:24,512:INFO:Creating metrics dataframe
2023-05-25 13:33:24,524:INFO:Initializing Decision Tree Classifier
2023-05-25 13:33:24,524:INFO:Total runtime is 2.128875203927358 minutes
2023-05-25 13:33:24,529:INFO:SubProcess create_model() called ==================================
2023-05-25 13:33:24,529:INFO:Initializing create_model()
2023-05-25 13:33:24,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:33:24,529:INFO:Checking exceptions
2023-05-25 13:33:24,529:INFO:Importing libraries
2023-05-25 13:33:24,529:INFO:Copying training dataset
2023-05-25 13:33:24,624:INFO:Defining folds
2023-05-25 13:33:24,624:INFO:Declaring metric variables
2023-05-25 13:33:24,628:INFO:Importing untrained model
2023-05-25 13:33:24,633:INFO:Decision Tree Classifier Imported successfully
2023-05-25 13:33:24,640:INFO:Starting cross validation
2023-05-25 13:33:24,643:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:33:39,099:INFO:Calculating mean and std
2023-05-25 13:33:39,100:INFO:Creating metrics dataframe
2023-05-25 13:33:39,679:INFO:Uploading results into container
2023-05-25 13:33:39,679:INFO:Uploading model into container now
2023-05-25 13:33:39,679:INFO:_master_model_container: 4
2023-05-25 13:33:39,681:INFO:_display_container: 2
2023-05-25 13:33:39,682:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-25 13:33:39,682:INFO:create_model() successfully completed......................................
2023-05-25 13:33:39,755:INFO:SubProcess create_model() end ==================================
2023-05-25 13:33:39,755:INFO:Creating metrics dataframe
2023-05-25 13:33:39,763:INFO:Initializing SVM - Linear Kernel
2023-05-25 13:33:39,763:INFO:Total runtime is 2.382848564783732 minutes
2023-05-25 13:33:39,768:INFO:SubProcess create_model() called ==================================
2023-05-25 13:33:39,768:INFO:Initializing create_model()
2023-05-25 13:33:39,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:33:39,768:INFO:Checking exceptions
2023-05-25 13:33:39,768:INFO:Importing libraries
2023-05-25 13:33:39,769:INFO:Copying training dataset
2023-05-25 13:33:39,838:INFO:Defining folds
2023-05-25 13:33:39,838:INFO:Declaring metric variables
2023-05-25 13:33:39,842:INFO:Importing untrained model
2023-05-25 13:33:39,846:INFO:SVM - Linear Kernel Imported successfully
2023-05-25 13:33:39,853:INFO:Starting cross validation
2023-05-25 13:33:39,857:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:33:42,621:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 13:33:42,625:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 13:33:43,006:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 13:33:43,044:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 13:33:43,126:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 13:33:43,153:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 13:33:43,239:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 13:33:43,412:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 13:33:46,509:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 13:33:46,762:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 13:33:48,978:INFO:Calculating mean and std
2023-05-25 13:33:48,979:INFO:Creating metrics dataframe
2023-05-25 13:33:49,567:INFO:Uploading results into container
2023-05-25 13:33:49,568:INFO:Uploading model into container now
2023-05-25 13:33:49,568:INFO:_master_model_container: 5
2023-05-25 13:33:49,568:INFO:_display_container: 2
2023-05-25 13:33:49,569:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-25 13:33:49,569:INFO:create_model() successfully completed......................................
2023-05-25 13:33:49,644:INFO:SubProcess create_model() end ==================================
2023-05-25 13:33:49,644:INFO:Creating metrics dataframe
2023-05-25 13:33:49,656:INFO:Initializing Ridge Classifier
2023-05-25 13:33:49,656:INFO:Total runtime is 2.5477310776710507 minutes
2023-05-25 13:33:49,659:INFO:SubProcess create_model() called ==================================
2023-05-25 13:33:49,659:INFO:Initializing create_model()
2023-05-25 13:33:49,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:33:49,659:INFO:Checking exceptions
2023-05-25 13:33:49,660:INFO:Importing libraries
2023-05-25 13:33:49,660:INFO:Copying training dataset
2023-05-25 13:33:49,730:INFO:Defining folds
2023-05-25 13:33:49,731:INFO:Declaring metric variables
2023-05-25 13:33:49,737:INFO:Importing untrained model
2023-05-25 13:33:49,741:INFO:Ridge Classifier Imported successfully
2023-05-25 13:33:49,748:INFO:Starting cross validation
2023-05-25 13:33:49,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:33:52,596:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 13:33:52,835:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 13:33:52,887:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 13:33:52,962:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 13:33:52,985:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 13:33:53,038:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 13:33:53,076:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 13:33:53,118:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 13:33:56,355:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 13:33:56,453:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 13:33:59,179:INFO:Calculating mean and std
2023-05-25 13:33:59,181:INFO:Creating metrics dataframe
2023-05-25 13:33:59,876:INFO:Uploading results into container
2023-05-25 13:33:59,877:INFO:Uploading model into container now
2023-05-25 13:33:59,877:INFO:_master_model_container: 6
2023-05-25 13:33:59,878:INFO:_display_container: 2
2023-05-25 13:33:59,878:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-25 13:33:59,878:INFO:create_model() successfully completed......................................
2023-05-25 13:33:59,952:INFO:SubProcess create_model() end ==================================
2023-05-25 13:33:59,953:INFO:Creating metrics dataframe
2023-05-25 13:33:59,961:INFO:Initializing Random Forest Classifier
2023-05-25 13:33:59,961:INFO:Total runtime is 2.719477542241414 minutes
2023-05-25 13:33:59,964:INFO:SubProcess create_model() called ==================================
2023-05-25 13:33:59,964:INFO:Initializing create_model()
2023-05-25 13:33:59,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:33:59,965:INFO:Checking exceptions
2023-05-25 13:33:59,965:INFO:Importing libraries
2023-05-25 13:33:59,965:INFO:Copying training dataset
2023-05-25 13:34:00,038:INFO:Defining folds
2023-05-25 13:34:00,038:INFO:Declaring metric variables
2023-05-25 13:34:00,041:INFO:Importing untrained model
2023-05-25 13:34:00,044:INFO:Random Forest Classifier Imported successfully
2023-05-25 13:34:00,053:INFO:Starting cross validation
2023-05-25 13:34:00,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:34:21,718:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.40s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:34:21,980:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:34:31,366:INFO:Calculating mean and std
2023-05-25 13:34:31,368:INFO:Creating metrics dataframe
2023-05-25 13:34:32,033:INFO:Uploading results into container
2023-05-25 13:34:32,035:INFO:Uploading model into container now
2023-05-25 13:34:32,035:INFO:_master_model_container: 7
2023-05-25 13:34:32,035:INFO:_display_container: 2
2023-05-25 13:34:32,036:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 13:34:32,036:INFO:create_model() successfully completed......................................
2023-05-25 13:34:32,109:INFO:SubProcess create_model() end ==================================
2023-05-25 13:34:32,109:INFO:Creating metrics dataframe
2023-05-25 13:34:32,121:INFO:Initializing Quadratic Discriminant Analysis
2023-05-25 13:34:32,121:INFO:Total runtime is 3.2554880976676936 minutes
2023-05-25 13:34:32,124:INFO:SubProcess create_model() called ==================================
2023-05-25 13:34:32,125:INFO:Initializing create_model()
2023-05-25 13:34:32,125:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:34:32,125:INFO:Checking exceptions
2023-05-25 13:34:32,125:INFO:Importing libraries
2023-05-25 13:34:32,125:INFO:Copying training dataset
2023-05-25 13:34:32,194:INFO:Defining folds
2023-05-25 13:34:32,194:INFO:Declaring metric variables
2023-05-25 13:34:32,198:INFO:Importing untrained model
2023-05-25 13:34:32,203:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-25 13:34:32,211:INFO:Starting cross validation
2023-05-25 13:34:32,214:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:34:37,795:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 13:34:37,824:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 13:34:37,839:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 13:34:37,853:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 13:34:37,865:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 13:34:37,877:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 13:34:37,905:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 13:34:37,910:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 13:34:47,143:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 13:34:47,242:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 13:34:50,223:INFO:Calculating mean and std
2023-05-25 13:34:50,224:INFO:Creating metrics dataframe
2023-05-25 13:34:50,927:INFO:Uploading results into container
2023-05-25 13:34:50,928:INFO:Uploading model into container now
2023-05-25 13:34:50,928:INFO:_master_model_container: 8
2023-05-25 13:34:50,929:INFO:_display_container: 2
2023-05-25 13:34:50,929:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-25 13:34:50,929:INFO:create_model() successfully completed......................................
2023-05-25 13:34:51,006:INFO:SubProcess create_model() end ==================================
2023-05-25 13:34:51,006:INFO:Creating metrics dataframe
2023-05-25 13:34:51,017:INFO:Initializing Ada Boost Classifier
2023-05-25 13:34:51,017:INFO:Total runtime is 3.5704138517379755 minutes
2023-05-25 13:34:51,021:INFO:SubProcess create_model() called ==================================
2023-05-25 13:34:51,021:INFO:Initializing create_model()
2023-05-25 13:34:51,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:34:51,021:INFO:Checking exceptions
2023-05-25 13:34:51,021:INFO:Importing libraries
2023-05-25 13:34:51,021:INFO:Copying training dataset
2023-05-25 13:34:51,092:INFO:Defining folds
2023-05-25 13:34:51,092:INFO:Declaring metric variables
2023-05-25 13:34:51,096:INFO:Importing untrained model
2023-05-25 13:34:51,101:INFO:Ada Boost Classifier Imported successfully
2023-05-25 13:34:51,108:INFO:Starting cross validation
2023-05-25 13:34:51,111:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:35:23,114:INFO:Calculating mean and std
2023-05-25 13:35:23,117:INFO:Creating metrics dataframe
2023-05-25 13:35:23,743:INFO:Uploading results into container
2023-05-25 13:35:23,743:INFO:Uploading model into container now
2023-05-25 13:35:23,744:INFO:_master_model_container: 9
2023-05-25 13:35:23,744:INFO:_display_container: 2
2023-05-25 13:35:23,744:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 13:35:23,745:INFO:create_model() successfully completed......................................
2023-05-25 13:35:23,817:INFO:SubProcess create_model() end ==================================
2023-05-25 13:35:23,818:INFO:Creating metrics dataframe
2023-05-25 13:35:23,828:INFO:Initializing Gradient Boosting Classifier
2023-05-25 13:35:23,828:INFO:Total runtime is 4.11726070245107 minutes
2023-05-25 13:35:23,831:INFO:SubProcess create_model() called ==================================
2023-05-25 13:35:23,831:INFO:Initializing create_model()
2023-05-25 13:35:23,831:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:35:23,831:INFO:Checking exceptions
2023-05-25 13:35:23,831:INFO:Importing libraries
2023-05-25 13:35:23,831:INFO:Copying training dataset
2023-05-25 13:35:23,901:INFO:Defining folds
2023-05-25 13:35:23,901:INFO:Declaring metric variables
2023-05-25 13:35:23,904:INFO:Importing untrained model
2023-05-25 13:35:23,909:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 13:35:23,914:INFO:Starting cross validation
2023-05-25 13:35:23,919:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:36:40,022:INFO:Calculating mean and std
2023-05-25 13:36:40,024:INFO:Creating metrics dataframe
2023-05-25 13:36:40,637:INFO:Uploading results into container
2023-05-25 13:36:40,638:INFO:Uploading model into container now
2023-05-25 13:36:40,638:INFO:_master_model_container: 10
2023-05-25 13:36:40,638:INFO:_display_container: 2
2023-05-25 13:36:40,639:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 13:36:40,639:INFO:create_model() successfully completed......................................
2023-05-25 13:36:40,715:INFO:SubProcess create_model() end ==================================
2023-05-25 13:36:40,716:INFO:Creating metrics dataframe
2023-05-25 13:36:40,727:INFO:Initializing Linear Discriminant Analysis
2023-05-25 13:36:40,729:INFO:Total runtime is 5.398944548765818 minutes
2023-05-25 13:36:40,732:INFO:SubProcess create_model() called ==================================
2023-05-25 13:36:40,732:INFO:Initializing create_model()
2023-05-25 13:36:40,732:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:36:40,732:INFO:Checking exceptions
2023-05-25 13:36:40,732:INFO:Importing libraries
2023-05-25 13:36:40,732:INFO:Copying training dataset
2023-05-25 13:36:40,804:INFO:Defining folds
2023-05-25 13:36:40,804:INFO:Declaring metric variables
2023-05-25 13:36:40,807:INFO:Importing untrained model
2023-05-25 13:36:40,811:INFO:Linear Discriminant Analysis Imported successfully
2023-05-25 13:36:40,818:INFO:Starting cross validation
2023-05-25 13:36:40,822:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:37:02,977:INFO:Calculating mean and std
2023-05-25 13:37:02,979:INFO:Creating metrics dataframe
2023-05-25 13:37:03,630:INFO:Uploading results into container
2023-05-25 13:37:03,631:INFO:Uploading model into container now
2023-05-25 13:37:03,631:INFO:_master_model_container: 11
2023-05-25 13:37:03,631:INFO:_display_container: 2
2023-05-25 13:37:03,631:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-25 13:37:03,632:INFO:create_model() successfully completed......................................
2023-05-25 13:37:03,715:INFO:SubProcess create_model() end ==================================
2023-05-25 13:37:03,715:INFO:Creating metrics dataframe
2023-05-25 13:37:03,729:INFO:Initializing Extra Trees Classifier
2023-05-25 13:37:03,729:INFO:Total runtime is 5.782278800010681 minutes
2023-05-25 13:37:03,732:INFO:SubProcess create_model() called ==================================
2023-05-25 13:37:03,732:INFO:Initializing create_model()
2023-05-25 13:37:03,733:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:37:03,733:INFO:Checking exceptions
2023-05-25 13:37:03,733:INFO:Importing libraries
2023-05-25 13:37:03,733:INFO:Copying training dataset
2023-05-25 13:37:03,803:INFO:Defining folds
2023-05-25 13:37:03,804:INFO:Declaring metric variables
2023-05-25 13:37:03,807:INFO:Importing untrained model
2023-05-25 13:37:03,811:INFO:Extra Trees Classifier Imported successfully
2023-05-25 13:37:03,818:INFO:Starting cross validation
2023-05-25 13:37:03,821:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:37:25,135:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:37:27,193:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:37:31,881:INFO:Calculating mean and std
2023-05-25 13:37:31,882:INFO:Creating metrics dataframe
2023-05-25 13:37:32,461:INFO:Uploading results into container
2023-05-25 13:37:32,461:INFO:Uploading model into container now
2023-05-25 13:37:32,462:INFO:_master_model_container: 12
2023-05-25 13:37:32,462:INFO:_display_container: 2
2023-05-25 13:37:32,462:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 13:37:32,462:INFO:create_model() successfully completed......................................
2023-05-25 13:37:32,541:INFO:SubProcess create_model() end ==================================
2023-05-25 13:37:32,542:INFO:Creating metrics dataframe
2023-05-25 13:37:32,552:INFO:Initializing Light Gradient Boosting Machine
2023-05-25 13:37:32,553:INFO:Total runtime is 6.2626872499783826 minutes
2023-05-25 13:37:32,557:INFO:SubProcess create_model() called ==================================
2023-05-25 13:37:32,557:INFO:Initializing create_model()
2023-05-25 13:37:32,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:37:32,558:INFO:Checking exceptions
2023-05-25 13:37:32,558:INFO:Importing libraries
2023-05-25 13:37:32,558:INFO:Copying training dataset
2023-05-25 13:37:32,628:INFO:Defining folds
2023-05-25 13:37:32,628:INFO:Declaring metric variables
2023-05-25 13:37:32,631:INFO:Importing untrained model
2023-05-25 13:37:32,635:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 13:37:32,644:INFO:Starting cross validation
2023-05-25 13:37:32,646:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:37:46,036:INFO:Calculating mean and std
2023-05-25 13:37:46,038:INFO:Creating metrics dataframe
2023-05-25 13:37:46,645:INFO:Uploading results into container
2023-05-25 13:37:46,646:INFO:Uploading model into container now
2023-05-25 13:37:46,646:INFO:_master_model_container: 13
2023-05-25 13:37:46,646:INFO:_display_container: 2
2023-05-25 13:37:46,647:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 13:37:46,647:INFO:create_model() successfully completed......................................
2023-05-25 13:37:46,719:INFO:SubProcess create_model() end ==================================
2023-05-25 13:37:46,719:INFO:Creating metrics dataframe
2023-05-25 13:37:46,730:INFO:Initializing Dummy Classifier
2023-05-25 13:37:46,730:INFO:Total runtime is 6.4989761114120475 minutes
2023-05-25 13:37:46,735:INFO:SubProcess create_model() called ==================================
2023-05-25 13:37:46,735:INFO:Initializing create_model()
2023-05-25 13:37:46,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024402EF2890>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:37:46,735:INFO:Checking exceptions
2023-05-25 13:37:46,735:INFO:Importing libraries
2023-05-25 13:37:46,735:INFO:Copying training dataset
2023-05-25 13:37:46,806:INFO:Defining folds
2023-05-25 13:37:46,806:INFO:Declaring metric variables
2023-05-25 13:37:46,809:INFO:Importing untrained model
2023-05-25 13:37:46,813:INFO:Dummy Classifier Imported successfully
2023-05-25 13:37:46,821:INFO:Starting cross validation
2023-05-25 13:37:46,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 13:37:48,505:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 13:37:48,589:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 13:37:48,661:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 13:37:48,666:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 13:37:48,666:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 13:37:48,685:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 13:37:48,709:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 13:37:48,758:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 13:37:51,205:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 13:37:51,270:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 13:37:54,252:INFO:Calculating mean and std
2023-05-25 13:37:54,255:INFO:Creating metrics dataframe
2023-05-25 13:37:54,871:INFO:Uploading results into container
2023-05-25 13:37:54,872:INFO:Uploading model into container now
2023-05-25 13:37:54,872:INFO:_master_model_container: 14
2023-05-25 13:37:54,873:INFO:_display_container: 2
2023-05-25 13:37:54,873:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-25 13:37:54,873:INFO:create_model() successfully completed......................................
2023-05-25 13:37:54,947:INFO:SubProcess create_model() end ==================================
2023-05-25 13:37:54,947:INFO:Creating metrics dataframe
2023-05-25 13:37:54,967:INFO:Initializing create_model()
2023-05-25 13:37:54,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:37:54,967:INFO:Checking exceptions
2023-05-25 13:37:54,969:INFO:Importing libraries
2023-05-25 13:37:54,969:INFO:Copying training dataset
2023-05-25 13:37:55,036:INFO:Defining folds
2023-05-25 13:37:55,036:INFO:Declaring metric variables
2023-05-25 13:37:55,037:INFO:Importing untrained model
2023-05-25 13:37:55,037:INFO:Declaring custom model
2023-05-25 13:37:55,038:INFO:Random Forest Classifier Imported successfully
2023-05-25 13:37:55,041:INFO:Cross validation set to False
2023-05-25 13:37:55,041:INFO:Fitting Model
2023-05-25 13:37:59,574:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 13:37:59,574:INFO:create_model() successfully completed......................................
2023-05-25 13:37:59,652:INFO:Initializing create_model()
2023-05-25 13:37:59,653:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:37:59,653:INFO:Checking exceptions
2023-05-25 13:37:59,655:INFO:Importing libraries
2023-05-25 13:37:59,656:INFO:Copying training dataset
2023-05-25 13:37:59,727:INFO:Defining folds
2023-05-25 13:37:59,727:INFO:Declaring metric variables
2023-05-25 13:37:59,727:INFO:Importing untrained model
2023-05-25 13:37:59,727:INFO:Declaring custom model
2023-05-25 13:37:59,728:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 13:37:59,730:INFO:Cross validation set to False
2023-05-25 13:37:59,730:INFO:Fitting Model
2023-05-25 13:38:02,008:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 13:38:02,009:INFO:create_model() successfully completed......................................
2023-05-25 13:38:02,128:INFO:Initializing create_model()
2023-05-25 13:38:02,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:38:02,129:INFO:Checking exceptions
2023-05-25 13:38:02,131:INFO:Importing libraries
2023-05-25 13:38:02,132:INFO:Copying training dataset
2023-05-25 13:38:02,226:INFO:Defining folds
2023-05-25 13:38:02,226:INFO:Declaring metric variables
2023-05-25 13:38:02,226:INFO:Importing untrained model
2023-05-25 13:38:02,226:INFO:Declaring custom model
2023-05-25 13:38:02,227:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 13:38:02,230:INFO:Cross validation set to False
2023-05-25 13:38:02,230:INFO:Fitting Model
2023-05-25 13:38:28,374:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 13:38:28,374:INFO:create_model() successfully completed......................................
2023-05-25 13:38:28,454:INFO:Initializing create_model()
2023-05-25 13:38:28,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:38:28,455:INFO:Checking exceptions
2023-05-25 13:38:28,458:INFO:Importing libraries
2023-05-25 13:38:28,458:INFO:Copying training dataset
2023-05-25 13:38:28,530:INFO:Defining folds
2023-05-25 13:38:28,531:INFO:Declaring metric variables
2023-05-25 13:38:28,531:INFO:Importing untrained model
2023-05-25 13:38:28,531:INFO:Declaring custom model
2023-05-25 13:38:28,531:INFO:Ada Boost Classifier Imported successfully
2023-05-25 13:38:28,534:INFO:Cross validation set to False
2023-05-25 13:38:28,534:INFO:Fitting Model
2023-05-25 13:38:36,450:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 13:38:36,450:INFO:create_model() successfully completed......................................
2023-05-25 13:38:36,520:INFO:Initializing create_model()
2023-05-25 13:38:36,520:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 13:38:36,520:INFO:Checking exceptions
2023-05-25 13:38:36,520:INFO:Importing libraries
2023-05-25 13:38:36,520:INFO:Copying training dataset
2023-05-25 13:38:36,641:INFO:Defining folds
2023-05-25 13:38:36,641:INFO:Declaring metric variables
2023-05-25 13:38:36,641:INFO:Importing untrained model
2023-05-25 13:38:36,641:INFO:Declaring custom model
2023-05-25 13:38:36,642:INFO:Extra Trees Classifier Imported successfully
2023-05-25 13:38:36,644:INFO:Cross validation set to False
2023-05-25 13:38:36,644:INFO:Fitting Model
2023-05-25 13:38:43,038:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 13:38:43,038:INFO:create_model() successfully completed......................................
2023-05-25 13:38:43,130:INFO:_master_model_container: 14
2023-05-25 13:38:43,130:INFO:_display_container: 2
2023-05-25 13:38:43,132:INFO:[RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)]
2023-05-25 13:38:43,132:INFO:compare_models() successfully completed......................................
2023-05-25 13:38:43,385:INFO:Initializing predict_model()
2023-05-25 13:38:43,385:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024401BC3F40>)
2023-05-25 13:38:43,385:INFO:Checking exceptions
2023-05-25 13:38:43,385:INFO:Preloading libraries
2023-05-25 13:38:43,387:INFO:Set up data.
2023-05-25 13:38:43,498:INFO:Set up index.
2023-05-25 13:41:48,942:INFO:Initializing predict_model()
2023-05-25 13:41:48,942:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000244595BF9A0>)
2023-05-25 13:41:48,942:INFO:Checking exceptions
2023-05-25 13:41:48,942:INFO:Preloading libraries
2023-05-25 13:41:48,944:INFO:Set up data.
2023-05-25 13:41:49,077:INFO:Set up index.
2023-05-25 13:41:49,577:INFO:Initializing save_model()
2023-05-25 13:41:49,577:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 13:41:49,577:INFO:Adding model into prep_pipe
2023-05-25 13:42:45,653:INFO:Initializing predict_model()
2023-05-25 13:42:45,653:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000244205AC8B0>)
2023-05-25 13:42:45,653:INFO:Checking exceptions
2023-05-25 13:42:45,653:INFO:Preloading libraries
2023-05-25 13:42:45,655:INFO:Set up data.
2023-05-25 13:42:45,773:INFO:Set up index.
2023-05-25 13:42:46,266:INFO:Initializing save_model()
2023-05-25 13:42:46,266:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 13:42:46,266:INFO:Adding model into prep_pipe
2023-05-25 13:45:43,476:INFO:Initializing predict_model()
2023-05-25 13:45:43,476:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000244040D4F70>)
2023-05-25 13:45:43,476:INFO:Checking exceptions
2023-05-25 13:45:43,476:INFO:Preloading libraries
2023-05-25 13:45:43,478:INFO:Set up data.
2023-05-25 13:45:43,597:INFO:Set up index.
2023-05-25 13:45:44,474:INFO:Initializing save_model()
2023-05-25 13:45:44,474:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=rf_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 13:45:44,474:INFO:Adding model into prep_pipe
2023-05-25 13:45:44,573:INFO:rf_model_file.pkl saved in current working directory
2023-05-25 13:45:44,584:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 13:45:44,584:INFO:save_model() successfully completed......................................
2023-05-25 13:45:52,645:INFO:Initializing predict_model()
2023-05-25 13:45:52,645:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002442030B640>)
2023-05-25 13:45:52,645:INFO:Checking exceptions
2023-05-25 13:45:52,645:INFO:Preloading libraries
2023-05-25 13:45:52,648:INFO:Set up data.
2023-05-25 13:45:52,759:INFO:Set up index.
2023-05-25 13:45:53,116:INFO:Initializing save_model()
2023-05-25 13:45:53,116:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=lgbm_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 13:45:53,116:INFO:Adding model into prep_pipe
2023-05-25 13:45:53,153:INFO:lgbm_model_file.pkl saved in current working directory
2023-05-25 13:45:53,171:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-05-25 13:45:53,171:INFO:save_model() successfully completed......................................
2023-05-25 13:46:17,467:INFO:Initializing predict_model()
2023-05-25 13:46:17,474:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002442030BD00>)
2023-05-25 13:46:17,474:INFO:Checking exceptions
2023-05-25 13:46:17,474:INFO:Preloading libraries
2023-05-25 13:46:17,476:INFO:Set up data.
2023-05-25 13:46:17,641:INFO:Set up index.
2023-05-25 13:46:17,976:INFO:Initializing save_model()
2023-05-25 13:46:17,976:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=gbc_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 13:46:17,976:INFO:Adding model into prep_pipe
2023-05-25 13:46:18,001:INFO:gbc_model_file.pkl saved in current working directory
2023-05-25 13:46:18,011:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 13:46:18,011:INFO:save_model() successfully completed......................................
2023-05-25 13:47:11,183:INFO:Initializing predict_model()
2023-05-25 13:47:11,183:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002442030BD00>)
2023-05-25 13:47:11,183:INFO:Checking exceptions
2023-05-25 13:47:11,183:INFO:Preloading libraries
2023-05-25 13:47:11,186:INFO:Set up data.
2023-05-25 13:47:11,304:INFO:Set up index.
2023-05-25 13:47:11,630:INFO:Initializing save_model()
2023-05-25 13:47:11,630:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=gbc_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 13:47:11,630:INFO:Adding model into prep_pipe
2023-05-25 13:47:11,650:INFO:gbc_model_file.pkl saved in current working directory
2023-05-25 13:47:11,660:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 13:47:11,660:INFO:save_model() successfully completed......................................
2023-05-25 13:47:40,364:INFO:Initializing predict_model()
2023-05-25 13:47:40,365:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002442030BBE0>)
2023-05-25 13:47:40,365:INFO:Checking exceptions
2023-05-25 13:47:40,365:INFO:Preloading libraries
2023-05-25 13:47:40,367:INFO:Set up data.
2023-05-25 13:47:40,493:INFO:Set up index.
2023-05-25 13:47:40,831:INFO:Initializing save_model()
2023-05-25 13:47:40,831:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=gbc_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 13:47:40,831:INFO:Adding model into prep_pipe
2023-05-25 13:47:40,851:INFO:gbc_model_file.pkl saved in current working directory
2023-05-25 13:47:40,862:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 13:47:40,862:INFO:save_model() successfully completed......................................
2023-05-25 13:47:47,395:INFO:Initializing predict_model()
2023-05-25 13:47:47,395:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024401BC2320>)
2023-05-25 13:47:47,395:INFO:Checking exceptions
2023-05-25 13:47:47,395:INFO:Preloading libraries
2023-05-25 13:47:47,397:INFO:Set up data.
2023-05-25 13:47:47,523:INFO:Set up index.
2023-05-25 13:47:49,270:INFO:Initializing save_model()
2023-05-25 13:47:49,271:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), model_name=ada_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 13:47:49,271:INFO:Adding model into prep_pipe
2023-05-25 13:47:49,305:INFO:ada_model_file.pkl saved in current working directory
2023-05-25 13:47:49,314:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=123))],
         verbose=False)
2023-05-25 13:47:49,314:INFO:save_model() successfully completed......................................
2023-05-25 13:48:17,801:INFO:Initializing predict_model()
2023-05-25 13:48:17,801:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002442030BD90>)
2023-05-25 13:48:17,801:INFO:Checking exceptions
2023-05-25 13:48:17,801:INFO:Preloading libraries
2023-05-25 13:48:17,803:INFO:Set up data.
2023-05-25 13:48:17,912:INFO:Set up index.
2023-05-25 13:48:18,460:INFO:Initializing save_model()
2023-05-25 13:48:18,460:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), model_name=et_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 13:48:18,460:INFO:Adding model into prep_pipe
2023-05-25 13:48:18,640:INFO:et_model_file.pkl saved in current working directory
2023-05-25 13:48:18,650:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=123,
                                      verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 13:48:18,650:INFO:save_model() successfully completed......................................
2023-05-25 13:48:54,114:INFO:Initializing tune_model()
2023-05-25 13:48:54,114:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=30, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024402EA4AC0>)
2023-05-25 13:48:54,114:INFO:Checking exceptions
2023-05-25 13:48:54,115:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-25 13:48:54,564:INFO:Copying training dataset
2023-05-25 13:48:54,623:INFO:Checking base model
2023-05-25 13:48:54,623:INFO:Base model : Random Forest Classifier
2023-05-25 13:48:54,629:INFO:Declaring metric variables
2023-05-25 13:48:54,634:INFO:Defining Hyperparameters
2023-05-25 13:48:54,741:INFO:Tuning with n_jobs=-1
2023-05-25 13:48:54,743:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 13:48:54,743:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 13:48:54,745:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-05-25 13:48:54,746:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-25 13:48:54,752:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-25 13:52:17,656:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:52:19,042:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:54:10,769:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:55:47,384:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:55:48,634:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:56:31,546:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:56:41,342:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 13:59:23,014:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 13:59:24,162:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:02:00,174:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:02:34,957:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:02:44,767:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:05:07,145:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:05:34,612:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:05:36,074:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:06:35,192:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:06:36,323:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:08:31,260:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:08:33,147:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:08:53,820:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:08:55,358:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:08:55,883:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:11:56,595:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:12:11,191:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:12:12,442:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:14:48,152:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:14:50,019:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:14:51,839:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:15:27,117:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:15:39,669:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:15:40,859:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:15:43,489:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:18:02,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:18:25,601:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:19:11,578:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:19:20,553:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:21:12,421:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:21:44,888:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:23:01,090:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:23:01,149:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:23:02,468:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:25:15,548:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:25:54,278:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:25:55,342:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:25:56,081:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:26:30,800:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:28:38,231:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:28:48,920:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:29:00,982:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:29:01,310:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:29:02,701:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:29:02,950:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:29:16,250:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:31:55,390:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:32:36,273:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:34:43,526:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:35:48,197:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:36:31,634:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:37:39,622:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:37:40,877:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:42:19,558:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:44:53,773:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:44:54,981:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:46:16,179:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:46:43,684:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:46:44,881:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 14:47:19,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 14:47:19,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 14:47:19,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 14:47:19,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 14:47:19,962:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-25 14:48:07,122:INFO:PyCaret ClassificationExperiment
2023-05-25 14:48:07,122:INFO:Logging name: clf-default-name
2023-05-25 14:48:07,122:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-25 14:48:07,122:INFO:version 3.0.2
2023-05-25 14:48:07,122:INFO:Initializing setup()
2023-05-25 14:48:07,122:INFO:self.USI: 8dea
2023-05-25 14:48:07,122:INFO:self._variable_keys: {'data', '_available_plots', 'USI', 'seed', 'X_train', 'is_multiclass', 'n_jobs_param', 'logging_param', 'gpu_param', 'exp_name_log', 'pipeline', 'exp_id', 'X_test', 'gpu_n_jobs_param', 'y_train', 'idx', 'target_param', 'fix_imbalance', 'log_plots_param', 'html_param', 'y', '_ml_usecase', 'y_test', 'fold_generator', 'fold_groups_param', 'memory', 'X', 'fold_shuffle_param'}
2023-05-25 14:48:07,122:INFO:Checking environment
2023-05-25 14:48:07,122:INFO:python_version: 3.10.11
2023-05-25 14:48:07,122:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-25 14:48:07,122:INFO:machine: AMD64
2023-05-25 14:48:07,123:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-25 14:48:07,125:INFO:Memory: svmem(total=16889774080, available=8849453056, percent=47.6, used=8040321024, free=8849453056)
2023-05-25 14:48:07,125:INFO:Physical Core: 4
2023-05-25 14:48:07,125:INFO:Logical Core: 8
2023-05-25 14:48:07,125:INFO:Checking libraries
2023-05-25 14:48:07,125:INFO:System:
2023-05-25 14:48:07,125:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-25 14:48:07,125:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-25 14:48:07,125:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-25 14:48:07,125:INFO:PyCaret required dependencies:
2023-05-25 14:48:07,126:INFO:                 pip: 23.0.1
2023-05-25 14:48:07,126:INFO:          setuptools: 66.0.0
2023-05-25 14:48:07,126:INFO:             pycaret: 3.0.2
2023-05-25 14:48:07,126:INFO:             IPython: 8.13.2
2023-05-25 14:48:07,126:INFO:          ipywidgets: 8.0.6
2023-05-25 14:48:07,126:INFO:                tqdm: 4.65.0
2023-05-25 14:48:07,126:INFO:               numpy: 1.23.5
2023-05-25 14:48:07,126:INFO:              pandas: 1.5.3
2023-05-25 14:48:07,126:INFO:              jinja2: 3.1.2
2023-05-25 14:48:07,126:INFO:               scipy: 1.10.1
2023-05-25 14:48:07,126:INFO:              joblib: 1.2.0
2023-05-25 14:48:07,126:INFO:             sklearn: 1.2.2
2023-05-25 14:48:07,126:INFO:                pyod: 1.0.9
2023-05-25 14:48:07,126:INFO:            imblearn: 0.10.1
2023-05-25 14:48:07,126:INFO:   category_encoders: 2.6.1
2023-05-25 14:48:07,126:INFO:            lightgbm: 3.3.5
2023-05-25 14:48:07,126:INFO:               numba: 0.57.0
2023-05-25 14:48:07,126:INFO:            requests: 2.31.0
2023-05-25 14:48:07,126:INFO:          matplotlib: 3.7.1
2023-05-25 14:48:07,126:INFO:          scikitplot: 0.3.7
2023-05-25 14:48:07,126:INFO:         yellowbrick: 1.5
2023-05-25 14:48:07,126:INFO:              plotly: 5.14.1
2023-05-25 14:48:07,126:INFO:             kaleido: 0.2.1
2023-05-25 14:48:07,126:INFO:         statsmodels: 0.14.0
2023-05-25 14:48:07,126:INFO:              sktime: 0.17.0
2023-05-25 14:48:07,126:INFO:               tbats: 1.1.3
2023-05-25 14:48:07,126:INFO:            pmdarima: 2.0.3
2023-05-25 14:48:07,126:INFO:              psutil: 5.9.5
2023-05-25 14:48:07,127:INFO:PyCaret optional dependencies:
2023-05-25 14:48:07,135:INFO:                shap: Not installed
2023-05-25 14:48:07,135:INFO:           interpret: Not installed
2023-05-25 14:48:07,135:INFO:                umap: Not installed
2023-05-25 14:48:07,135:INFO:    pandas_profiling: Not installed
2023-05-25 14:48:07,135:INFO:  explainerdashboard: Not installed
2023-05-25 14:48:07,135:INFO:             autoviz: Not installed
2023-05-25 14:48:07,135:INFO:           fairlearn: Not installed
2023-05-25 14:48:07,136:INFO:             xgboost: Not installed
2023-05-25 14:48:07,136:INFO:            catboost: Not installed
2023-05-25 14:48:07,136:INFO:              kmodes: Not installed
2023-05-25 14:48:07,136:INFO:             mlxtend: Not installed
2023-05-25 14:48:07,136:INFO:       statsforecast: Not installed
2023-05-25 14:48:07,136:INFO:        tune_sklearn: 0.4.5
2023-05-25 14:48:07,136:INFO:                 ray: 2.4.0
2023-05-25 14:48:07,136:INFO:            hyperopt: 0.2.7
2023-05-25 14:48:07,136:INFO:              optuna: 3.1.1
2023-05-25 14:48:07,136:INFO:               skopt: 0.9.0
2023-05-25 14:48:07,136:INFO:              mlflow: Not installed
2023-05-25 14:48:07,136:INFO:              gradio: Not installed
2023-05-25 14:48:07,136:INFO:             fastapi: Not installed
2023-05-25 14:48:07,136:INFO:             uvicorn: Not installed
2023-05-25 14:48:07,136:INFO:              m2cgen: Not installed
2023-05-25 14:48:07,136:INFO:           evidently: Not installed
2023-05-25 14:48:07,136:INFO:               fugue: Not installed
2023-05-25 14:48:07,136:INFO:           streamlit: Not installed
2023-05-25 14:48:07,136:INFO:             prophet: Not installed
2023-05-25 14:48:07,136:INFO:None
2023-05-25 14:48:07,136:INFO:Set up data.
2023-05-25 14:48:07,329:INFO:Set up train/test split.
2023-05-25 14:48:07,421:INFO:Set up index.
2023-05-25 14:48:07,424:INFO:Set up folding strategy.
2023-05-25 14:48:07,425:INFO:Assigning column types.
2023-05-25 14:48:07,481:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-25 14:48:07,518:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 14:48:07,521:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 14:48:07,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:07,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:07,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 14:48:07,631:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 14:48:07,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:07,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:07,664:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-25 14:48:07,723:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 14:48:07,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:07,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:07,812:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 14:48:07,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:07,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:07,847:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-25 14:48:07,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:07,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:08,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:08,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:08,027:INFO:Preparing preprocessing pipeline...
2023-05-25 14:48:08,033:INFO:Set up label encoding.
2023-05-25 14:48:08,033:INFO:Set up simple imputation.
2023-05-25 14:48:08,034:INFO:Set up imbalanced handling.
2023-05-25 14:48:08,040:INFO:Set up column name cleaning.
2023-05-25 14:48:10,446:INFO:Finished creating preprocessing pipeline.
2023-05-25 14:48:10,457:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-25 14:48:10,458:INFO:Creating final display dataframe.
2023-05-25 14:48:13,394:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 505)
5        Transformed data shape              (41153, 505)
6   Transformed train set shape              (30052, 505)
7    Transformed test set shape              (11101, 505)
8              Numeric features                       504
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      8dea
2023-05-25 14:48:13,506:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:13,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:13,592:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:13,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:48:13,593:INFO:setup() successfully completed in 7.03s...............
2023-05-25 14:48:13,635:INFO:Initializing compare_models()
2023-05-25 14:48:13,635:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002631E39B100>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002631E39B100>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-25 14:48:13,635:INFO:Checking exceptions
2023-05-25 14:48:13,683:INFO:Preparing display monitor
2023-05-25 14:48:13,709:INFO:Initializing Logistic Regression
2023-05-25 14:48:13,709:INFO:Total runtime is 0.0 minutes
2023-05-25 14:48:13,714:INFO:SubProcess create_model() called ==================================
2023-05-25 14:48:13,714:INFO:Initializing create_model()
2023-05-25 14:48:13,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002631E39B100>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002631E7AC070>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 14:48:13,714:INFO:Checking exceptions
2023-05-25 14:48:13,716:INFO:Importing libraries
2023-05-25 14:48:13,716:INFO:Copying training dataset
2023-05-25 14:48:13,882:INFO:Defining folds
2023-05-25 14:48:13,883:INFO:Declaring metric variables
2023-05-25 14:48:13,887:INFO:Importing untrained model
2023-05-25 14:48:13,891:INFO:Logistic Regression Imported successfully
2023-05-25 14:48:13,897:INFO:Starting cross validation
2023-05-25 14:48:13,911:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 14:49:30,839:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 14:49:32,001:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 14:49:32,103:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 14:49:34,177:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 14:49:34,670:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 14:49:34,686:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 14:49:35,175:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 14:49:35,857:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 14:57:36,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 14:57:36,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 14:57:36,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 14:57:36,091:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-25 14:57:36,805:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-25 14:57:50,064:INFO:PyCaret ClassificationExperiment
2023-05-25 14:57:50,065:INFO:Logging name: clf-default-name
2023-05-25 14:57:50,065:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-25 14:57:50,065:INFO:version 3.0.2
2023-05-25 14:57:50,066:INFO:Initializing setup()
2023-05-25 14:57:50,066:INFO:self.USI: ae10
2023-05-25 14:57:50,066:INFO:self._variable_keys: {'html_param', 'gpu_param', 'X_test', '_available_plots', 'log_plots_param', 'memory', 'fold_shuffle_param', 'target_param', 'y', 'exp_id', 'exp_name_log', 'logging_param', 'X_train', 'data', 'is_multiclass', 'seed', '_ml_usecase', 'fold_groups_param', 'pipeline', 'fix_imbalance', 'n_jobs_param', 'gpu_n_jobs_param', 'USI', 'X', 'y_test', 'y_train', 'idx', 'fold_generator'}
2023-05-25 14:57:50,066:INFO:Checking environment
2023-05-25 14:57:50,066:INFO:python_version: 3.10.11
2023-05-25 14:57:50,066:INFO:python_build: ('main', 'Apr 20 2023 18:56:50')
2023-05-25 14:57:50,066:INFO:machine: AMD64
2023-05-25 14:57:50,066:INFO:platform: Windows-10-10.0.22621-SP0
2023-05-25 14:57:50,069:INFO:Memory: svmem(total=16889774080, available=8588398592, percent=49.2, used=8301375488, free=8588398592)
2023-05-25 14:57:50,069:INFO:Physical Core: 4
2023-05-25 14:57:50,069:INFO:Logical Core: 8
2023-05-25 14:57:50,070:INFO:Checking libraries
2023-05-25 14:57:50,070:INFO:System:
2023-05-25 14:57:50,070:INFO:    python: 3.10.11 | packaged by Anaconda, Inc. | (main, Apr 20 2023, 18:56:50) [MSC v.1916 64 bit (AMD64)]
2023-05-25 14:57:50,070:INFO:executable: c:\Users\NT550-052\anaconda3\envs\tmp\python.exe
2023-05-25 14:57:50,070:INFO:   machine: Windows-10-10.0.22621-SP0
2023-05-25 14:57:50,070:INFO:PyCaret required dependencies:
2023-05-25 14:57:50,070:INFO:                 pip: 23.0.1
2023-05-25 14:57:50,070:INFO:          setuptools: 66.0.0
2023-05-25 14:57:50,070:INFO:             pycaret: 3.0.2
2023-05-25 14:57:50,070:INFO:             IPython: 8.13.2
2023-05-25 14:57:50,070:INFO:          ipywidgets: 8.0.6
2023-05-25 14:57:50,070:INFO:                tqdm: 4.65.0
2023-05-25 14:57:50,070:INFO:               numpy: 1.23.5
2023-05-25 14:57:50,070:INFO:              pandas: 1.5.3
2023-05-25 14:57:50,071:INFO:              jinja2: 3.1.2
2023-05-25 14:57:50,071:INFO:               scipy: 1.10.1
2023-05-25 14:57:50,071:INFO:              joblib: 1.2.0
2023-05-25 14:57:50,071:INFO:             sklearn: 1.2.2
2023-05-25 14:57:50,071:INFO:                pyod: 1.0.9
2023-05-25 14:57:50,071:INFO:            imblearn: 0.10.1
2023-05-25 14:57:50,071:INFO:   category_encoders: 2.6.1
2023-05-25 14:57:50,071:INFO:            lightgbm: 3.3.5
2023-05-25 14:57:50,071:INFO:               numba: 0.57.0
2023-05-25 14:57:50,071:INFO:            requests: 2.31.0
2023-05-25 14:57:50,071:INFO:          matplotlib: 3.7.1
2023-05-25 14:57:50,071:INFO:          scikitplot: 0.3.7
2023-05-25 14:57:50,071:INFO:         yellowbrick: 1.5
2023-05-25 14:57:50,071:INFO:              plotly: 5.14.1
2023-05-25 14:57:50,071:INFO:             kaleido: 0.2.1
2023-05-25 14:57:50,071:INFO:         statsmodels: 0.14.0
2023-05-25 14:57:50,071:INFO:              sktime: 0.17.0
2023-05-25 14:57:50,072:INFO:               tbats: 1.1.3
2023-05-25 14:57:50,072:INFO:            pmdarima: 2.0.3
2023-05-25 14:57:50,072:INFO:              psutil: 5.9.5
2023-05-25 14:57:50,072:INFO:PyCaret optional dependencies:
2023-05-25 14:57:50,085:INFO:                shap: Not installed
2023-05-25 14:57:50,085:INFO:           interpret: Not installed
2023-05-25 14:57:50,085:INFO:                umap: Not installed
2023-05-25 14:57:50,085:INFO:    pandas_profiling: Not installed
2023-05-25 14:57:50,085:INFO:  explainerdashboard: Not installed
2023-05-25 14:57:50,085:INFO:             autoviz: Not installed
2023-05-25 14:57:50,085:INFO:           fairlearn: Not installed
2023-05-25 14:57:50,085:INFO:             xgboost: Not installed
2023-05-25 14:57:50,086:INFO:            catboost: Not installed
2023-05-25 14:57:50,086:INFO:              kmodes: Not installed
2023-05-25 14:57:50,086:INFO:             mlxtend: Not installed
2023-05-25 14:57:50,086:INFO:       statsforecast: Not installed
2023-05-25 14:57:50,086:INFO:        tune_sklearn: 0.4.5
2023-05-25 14:57:50,086:INFO:                 ray: 2.4.0
2023-05-25 14:57:50,086:INFO:            hyperopt: 0.2.7
2023-05-25 14:57:50,086:INFO:              optuna: 3.1.1
2023-05-25 14:57:50,086:INFO:               skopt: 0.9.0
2023-05-25 14:57:50,087:INFO:              mlflow: Not installed
2023-05-25 14:57:50,087:INFO:              gradio: Not installed
2023-05-25 14:57:50,087:INFO:             fastapi: Not installed
2023-05-25 14:57:50,087:INFO:             uvicorn: Not installed
2023-05-25 14:57:50,087:INFO:              m2cgen: Not installed
2023-05-25 14:57:50,087:INFO:           evidently: Not installed
2023-05-25 14:57:50,087:INFO:               fugue: Not installed
2023-05-25 14:57:50,087:INFO:           streamlit: Not installed
2023-05-25 14:57:50,087:INFO:             prophet: Not installed
2023-05-25 14:57:50,087:INFO:None
2023-05-25 14:57:50,087:INFO:Set up data.
2023-05-25 14:57:50,316:INFO:Set up train/test split.
2023-05-25 14:57:50,410:INFO:Set up index.
2023-05-25 14:57:50,413:INFO:Set up folding strategy.
2023-05-25 14:57:50,413:INFO:Assigning column types.
2023-05-25 14:57:50,466:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-25 14:57:50,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 14:57:50,513:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 14:57:50,548:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-25 14:57:50,618:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 14:57:50,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,642:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-25 14:57:50,682:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 14:57:50,708:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,758:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-25 14:57:50,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,788:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-25 14:57:50,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,869:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,947:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,947:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:50,950:INFO:Preparing preprocessing pipeline...
2023-05-25 14:57:50,956:INFO:Set up label encoding.
2023-05-25 14:57:50,956:INFO:Set up simple imputation.
2023-05-25 14:57:50,956:INFO:Set up imbalanced handling.
2023-05-25 14:57:50,963:INFO:Set up column name cleaning.
2023-05-25 14:57:51,540:INFO:Finished creating preprocessing pipeline.
2023-05-25 14:57:51,552:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-05-25 14:57:51,553:INFO:Creating final display dataframe.
2023-05-25 14:57:53,172:INFO:Setup _display_container:                     Description                     Value
0                    Session id                       123
1                        Target                    Review
2                   Target type                    Binary
3                Target mapping  Negative: 0, Positive: 1
4           Original data shape              (37001, 505)
5        Transformed data shape              (41153, 505)
6   Transformed train set shape              (30052, 505)
7    Transformed test set shape              (11101, 505)
8              Numeric features                       504
9                    Preprocess                      True
10              Imputation type                    simple
11           Numeric imputation                      mean
12       Categorical imputation                      mode
13                Fix imbalance                      True
14         Fix imbalance method                     SMOTE
15               Fold Generator           StratifiedKFold
16                  Fold Number                        10
17                     CPU Jobs                        -1
18                      Use GPU                     False
19               Log Experiment                     False
20              Experiment Name          clf-default-name
21                          USI                      ae10
2023-05-25 14:57:53,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:53,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:53,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:53,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-25 14:57:53,352:INFO:setup() successfully completed in 3.9s...............
2023-05-25 14:57:53,422:INFO:Initializing compare_models()
2023-05-25 14:57:53,422:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-25 14:57:53,423:INFO:Checking exceptions
2023-05-25 14:57:53,471:INFO:Preparing display monitor
2023-05-25 14:57:53,499:INFO:Initializing Logistic Regression
2023-05-25 14:57:53,499:INFO:Total runtime is 0.0 minutes
2023-05-25 14:57:53,504:INFO:SubProcess create_model() called ==================================
2023-05-25 14:57:53,505:INFO:Initializing create_model()
2023-05-25 14:57:53,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 14:57:53,505:INFO:Checking exceptions
2023-05-25 14:57:53,505:INFO:Importing libraries
2023-05-25 14:57:53,505:INFO:Copying training dataset
2023-05-25 14:57:53,588:INFO:Defining folds
2023-05-25 14:57:53,588:INFO:Declaring metric variables
2023-05-25 14:57:53,591:INFO:Importing untrained model
2023-05-25 14:57:53,595:INFO:Logistic Regression Imported successfully
2023-05-25 14:57:53,602:INFO:Starting cross validation
2023-05-25 14:57:53,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 14:58:01,013:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-25 14:58:25,791:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 14:58:26,257:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2023-05-25 14:58:26,927:INFO:Calculating mean and std
2023-05-25 14:58:26,930:INFO:Creating metrics dataframe
2023-05-25 14:58:27,639:INFO:Uploading results into container
2023-05-25 14:58:27,639:INFO:Uploading model into container now
2023-05-25 14:58:27,640:INFO:_master_model_container: 1
2023-05-25 14:58:27,640:INFO:_display_container: 2
2023-05-25 14:58:27,640:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-25 14:58:27,640:INFO:create_model() successfully completed......................................
2023-05-25 14:58:27,737:INFO:SubProcess create_model() end ==================================
2023-05-25 14:58:27,737:INFO:Creating metrics dataframe
2023-05-25 14:58:27,750:INFO:Initializing K Neighbors Classifier
2023-05-25 14:58:27,751:INFO:Total runtime is 0.5708779931068421 minutes
2023-05-25 14:58:27,754:INFO:SubProcess create_model() called ==================================
2023-05-25 14:58:27,755:INFO:Initializing create_model()
2023-05-25 14:58:27,755:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 14:58:27,755:INFO:Checking exceptions
2023-05-25 14:58:27,755:INFO:Importing libraries
2023-05-25 14:58:27,755:INFO:Copying training dataset
2023-05-25 14:58:27,851:INFO:Defining folds
2023-05-25 14:58:27,851:INFO:Declaring metric variables
2023-05-25 14:58:27,855:INFO:Importing untrained model
2023-05-25 14:58:27,858:INFO:K Neighbors Classifier Imported successfully
2023-05-25 14:58:27,871:INFO:Starting cross validation
2023-05-25 14:58:27,874:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 14:58:47,367:INFO:Calculating mean and std
2023-05-25 14:58:47,370:INFO:Creating metrics dataframe
2023-05-25 14:58:48,009:INFO:Uploading results into container
2023-05-25 14:58:48,009:INFO:Uploading model into container now
2023-05-25 14:58:48,009:INFO:_master_model_container: 2
2023-05-25 14:58:48,011:INFO:_display_container: 2
2023-05-25 14:58:48,011:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-25 14:58:48,011:INFO:create_model() successfully completed......................................
2023-05-25 14:58:48,081:INFO:SubProcess create_model() end ==================================
2023-05-25 14:58:48,081:INFO:Creating metrics dataframe
2023-05-25 14:58:48,089:INFO:Initializing Naive Bayes
2023-05-25 14:58:48,089:INFO:Total runtime is 0.909844164053599 minutes
2023-05-25 14:58:48,093:INFO:SubProcess create_model() called ==================================
2023-05-25 14:58:48,093:INFO:Initializing create_model()
2023-05-25 14:58:48,093:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 14:58:48,094:INFO:Checking exceptions
2023-05-25 14:58:48,094:INFO:Importing libraries
2023-05-25 14:58:48,094:INFO:Copying training dataset
2023-05-25 14:58:48,163:INFO:Defining folds
2023-05-25 14:58:48,163:INFO:Declaring metric variables
2023-05-25 14:58:48,168:INFO:Importing untrained model
2023-05-25 14:58:48,171:INFO:Naive Bayes Imported successfully
2023-05-25 14:58:48,179:INFO:Starting cross validation
2023-05-25 14:58:48,183:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 14:58:58,193:INFO:Calculating mean and std
2023-05-25 14:58:58,195:INFO:Creating metrics dataframe
2023-05-25 14:58:58,852:INFO:Uploading results into container
2023-05-25 14:58:58,853:INFO:Uploading model into container now
2023-05-25 14:58:58,854:INFO:_master_model_container: 3
2023-05-25 14:58:58,854:INFO:_display_container: 2
2023-05-25 14:58:58,854:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-25 14:58:58,854:INFO:create_model() successfully completed......................................
2023-05-25 14:58:58,924:INFO:SubProcess create_model() end ==================================
2023-05-25 14:58:58,924:INFO:Creating metrics dataframe
2023-05-25 14:58:58,935:INFO:Initializing Decision Tree Classifier
2023-05-25 14:58:58,935:INFO:Total runtime is 1.09061279296875 minutes
2023-05-25 14:58:58,940:INFO:SubProcess create_model() called ==================================
2023-05-25 14:58:58,940:INFO:Initializing create_model()
2023-05-25 14:58:58,940:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 14:58:58,940:INFO:Checking exceptions
2023-05-25 14:58:58,940:INFO:Importing libraries
2023-05-25 14:58:58,940:INFO:Copying training dataset
2023-05-25 14:58:59,011:INFO:Defining folds
2023-05-25 14:58:59,011:INFO:Declaring metric variables
2023-05-25 14:58:59,015:INFO:Importing untrained model
2023-05-25 14:58:59,020:INFO:Decision Tree Classifier Imported successfully
2023-05-25 14:58:59,027:INFO:Starting cross validation
2023-05-25 14:58:59,031:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 14:59:13,724:INFO:Calculating mean and std
2023-05-25 14:59:13,725:INFO:Creating metrics dataframe
2023-05-25 14:59:14,317:INFO:Uploading results into container
2023-05-25 14:59:14,317:INFO:Uploading model into container now
2023-05-25 14:59:14,318:INFO:_master_model_container: 4
2023-05-25 14:59:14,318:INFO:_display_container: 2
2023-05-25 14:59:14,318:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-25 14:59:14,318:INFO:create_model() successfully completed......................................
2023-05-25 14:59:14,384:INFO:SubProcess create_model() end ==================================
2023-05-25 14:59:14,384:INFO:Creating metrics dataframe
2023-05-25 14:59:14,394:INFO:Initializing SVM - Linear Kernel
2023-05-25 14:59:14,395:INFO:Total runtime is 1.3482727766036986 minutes
2023-05-25 14:59:14,398:INFO:SubProcess create_model() called ==================================
2023-05-25 14:59:14,398:INFO:Initializing create_model()
2023-05-25 14:59:14,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 14:59:14,398:INFO:Checking exceptions
2023-05-25 14:59:14,399:INFO:Importing libraries
2023-05-25 14:59:14,399:INFO:Copying training dataset
2023-05-25 14:59:14,468:INFO:Defining folds
2023-05-25 14:59:14,468:INFO:Declaring metric variables
2023-05-25 14:59:14,472:INFO:Importing untrained model
2023-05-25 14:59:14,477:INFO:SVM - Linear Kernel Imported successfully
2023-05-25 14:59:14,483:INFO:Starting cross validation
2023-05-25 14:59:14,486:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 14:59:17,382:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 14:59:17,585:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 14:59:17,684:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 14:59:17,735:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 14:59:17,844:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 14:59:17,908:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 14:59:17,961:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 14:59:18,838:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 14:59:21,409:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 14:59:22,021:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-25 14:59:24,297:INFO:Calculating mean and std
2023-05-25 14:59:24,298:INFO:Creating metrics dataframe
2023-05-25 14:59:24,875:INFO:Uploading results into container
2023-05-25 14:59:24,876:INFO:Uploading model into container now
2023-05-25 14:59:24,876:INFO:_master_model_container: 5
2023-05-25 14:59:24,876:INFO:_display_container: 2
2023-05-25 14:59:24,877:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-25 14:59:24,877:INFO:create_model() successfully completed......................................
2023-05-25 14:59:24,951:INFO:SubProcess create_model() end ==================================
2023-05-25 14:59:24,952:INFO:Creating metrics dataframe
2023-05-25 14:59:24,963:INFO:Initializing Ridge Classifier
2023-05-25 14:59:24,964:INFO:Total runtime is 1.5244196613629657 minutes
2023-05-25 14:59:24,968:INFO:SubProcess create_model() called ==================================
2023-05-25 14:59:24,969:INFO:Initializing create_model()
2023-05-25 14:59:24,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 14:59:24,969:INFO:Checking exceptions
2023-05-25 14:59:24,969:INFO:Importing libraries
2023-05-25 14:59:24,969:INFO:Copying training dataset
2023-05-25 14:59:25,045:INFO:Defining folds
2023-05-25 14:59:25,045:INFO:Declaring metric variables
2023-05-25 14:59:25,051:INFO:Importing untrained model
2023-05-25 14:59:25,054:INFO:Ridge Classifier Imported successfully
2023-05-25 14:59:25,061:INFO:Starting cross validation
2023-05-25 14:59:25,079:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 14:59:28,059:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 14:59:28,070:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 14:59:28,206:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 14:59:28,207:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 14:59:28,261:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 14:59:28,358:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 14:59:28,361:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 14:59:28,438:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 14:59:31,598:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 14:59:31,694:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-25 14:59:34,411:INFO:Calculating mean and std
2023-05-25 14:59:34,413:INFO:Creating metrics dataframe
2023-05-25 14:59:34,986:INFO:Uploading results into container
2023-05-25 14:59:34,986:INFO:Uploading model into container now
2023-05-25 14:59:34,987:INFO:_master_model_container: 6
2023-05-25 14:59:34,987:INFO:_display_container: 2
2023-05-25 14:59:34,987:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-25 14:59:34,987:INFO:create_model() successfully completed......................................
2023-05-25 14:59:35,055:INFO:SubProcess create_model() end ==================================
2023-05-25 14:59:35,056:INFO:Creating metrics dataframe
2023-05-25 14:59:35,068:INFO:Initializing Random Forest Classifier
2023-05-25 14:59:35,068:INFO:Total runtime is 1.69282697836558 minutes
2023-05-25 14:59:35,073:INFO:SubProcess create_model() called ==================================
2023-05-25 14:59:35,074:INFO:Initializing create_model()
2023-05-25 14:59:35,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 14:59:35,074:INFO:Checking exceptions
2023-05-25 14:59:35,074:INFO:Importing libraries
2023-05-25 14:59:35,074:INFO:Copying training dataset
2023-05-25 14:59:35,142:INFO:Defining folds
2023-05-25 14:59:35,142:INFO:Declaring metric variables
2023-05-25 14:59:35,145:INFO:Importing untrained model
2023-05-25 14:59:35,149:INFO:Random Forest Classifier Imported successfully
2023-05-25 14:59:35,156:INFO:Starting cross validation
2023-05-25 14:59:35,160:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 14:59:56,494:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:59:56,616:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:59:59,074:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-25 14:59:59,864:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.16s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 14:59:59,981:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:00:00,005:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-05-25 15:00:00,359:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:00:00,584:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:00:01,376:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:00:01,654:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:00:01,693:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:00:12,486:INFO:Calculating mean and std
2023-05-25 15:00:12,486:INFO:Creating metrics dataframe
2023-05-25 15:00:13,084:INFO:Uploading results into container
2023-05-25 15:00:13,085:INFO:Uploading model into container now
2023-05-25 15:00:13,085:INFO:_master_model_container: 7
2023-05-25 15:00:13,085:INFO:_display_container: 2
2023-05-25 15:00:13,086:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 15:00:13,086:INFO:create_model() successfully completed......................................
2023-05-25 15:00:13,155:INFO:SubProcess create_model() end ==================================
2023-05-25 15:00:13,156:INFO:Creating metrics dataframe
2023-05-25 15:00:13,167:INFO:Initializing Quadratic Discriminant Analysis
2023-05-25 15:00:13,167:INFO:Total runtime is 2.3278080701828 minutes
2023-05-25 15:00:13,171:INFO:SubProcess create_model() called ==================================
2023-05-25 15:00:13,172:INFO:Initializing create_model()
2023-05-25 15:00:13,172:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:00:13,172:INFO:Checking exceptions
2023-05-25 15:00:13,172:INFO:Importing libraries
2023-05-25 15:00:13,172:INFO:Copying training dataset
2023-05-25 15:00:13,241:INFO:Defining folds
2023-05-25 15:00:13,241:INFO:Declaring metric variables
2023-05-25 15:00:13,245:INFO:Importing untrained model
2023-05-25 15:00:13,250:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-25 15:00:13,257:INFO:Starting cross validation
2023-05-25 15:00:13,260:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 15:00:18,555:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 15:00:18,587:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 15:00:18,658:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 15:00:18,669:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 15:00:18,686:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 15:00:18,687:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 15:00:18,687:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 15:00:18,751:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 15:00:27,727:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 15:00:27,818:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-25 15:00:30,988:INFO:Calculating mean and std
2023-05-25 15:00:30,989:INFO:Creating metrics dataframe
2023-05-25 15:00:31,575:INFO:Uploading results into container
2023-05-25 15:00:31,576:INFO:Uploading model into container now
2023-05-25 15:00:31,577:INFO:_master_model_container: 8
2023-05-25 15:00:31,577:INFO:_display_container: 2
2023-05-25 15:00:31,577:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-25 15:00:31,577:INFO:create_model() successfully completed......................................
2023-05-25 15:00:31,650:INFO:SubProcess create_model() end ==================================
2023-05-25 15:00:31,651:INFO:Creating metrics dataframe
2023-05-25 15:00:31,660:INFO:Initializing Ada Boost Classifier
2023-05-25 15:00:31,660:INFO:Total runtime is 2.6360209663709004 minutes
2023-05-25 15:00:31,664:INFO:SubProcess create_model() called ==================================
2023-05-25 15:00:31,665:INFO:Initializing create_model()
2023-05-25 15:00:31,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:00:31,665:INFO:Checking exceptions
2023-05-25 15:00:31,665:INFO:Importing libraries
2023-05-25 15:00:31,665:INFO:Copying training dataset
2023-05-25 15:00:31,734:INFO:Defining folds
2023-05-25 15:00:31,735:INFO:Declaring metric variables
2023-05-25 15:00:31,738:INFO:Importing untrained model
2023-05-25 15:00:31,742:INFO:Ada Boost Classifier Imported successfully
2023-05-25 15:00:31,749:INFO:Starting cross validation
2023-05-25 15:00:31,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 15:01:02,571:INFO:Calculating mean and std
2023-05-25 15:01:02,572:INFO:Creating metrics dataframe
2023-05-25 15:01:03,203:INFO:Uploading results into container
2023-05-25 15:01:03,203:INFO:Uploading model into container now
2023-05-25 15:01:03,204:INFO:_master_model_container: 9
2023-05-25 15:01:03,204:INFO:_display_container: 2
2023-05-25 15:01:03,204:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 15:01:03,204:INFO:create_model() successfully completed......................................
2023-05-25 15:01:03,275:INFO:SubProcess create_model() end ==================================
2023-05-25 15:01:03,275:INFO:Creating metrics dataframe
2023-05-25 15:01:03,286:INFO:Initializing Gradient Boosting Classifier
2023-05-25 15:01:03,286:INFO:Total runtime is 3.1631216208140054 minutes
2023-05-25 15:01:03,289:INFO:SubProcess create_model() called ==================================
2023-05-25 15:01:03,289:INFO:Initializing create_model()
2023-05-25 15:01:03,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:01:03,289:INFO:Checking exceptions
2023-05-25 15:01:03,290:INFO:Importing libraries
2023-05-25 15:01:03,290:INFO:Copying training dataset
2023-05-25 15:01:03,359:INFO:Defining folds
2023-05-25 15:01:03,359:INFO:Declaring metric variables
2023-05-25 15:01:03,362:INFO:Importing untrained model
2023-05-25 15:01:03,368:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 15:01:03,374:INFO:Starting cross validation
2023-05-25 15:01:03,378:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 15:02:19,522:INFO:Calculating mean and std
2023-05-25 15:02:19,522:INFO:Creating metrics dataframe
2023-05-25 15:02:20,160:INFO:Uploading results into container
2023-05-25 15:02:20,161:INFO:Uploading model into container now
2023-05-25 15:02:20,162:INFO:_master_model_container: 10
2023-05-25 15:02:20,162:INFO:_display_container: 2
2023-05-25 15:02:20,163:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 15:02:20,163:INFO:create_model() successfully completed......................................
2023-05-25 15:02:20,234:INFO:SubProcess create_model() end ==================================
2023-05-25 15:02:20,234:INFO:Creating metrics dataframe
2023-05-25 15:02:20,244:INFO:Initializing Linear Discriminant Analysis
2023-05-25 15:02:20,244:INFO:Total runtime is 4.4457570791244505 minutes
2023-05-25 15:02:20,247:INFO:SubProcess create_model() called ==================================
2023-05-25 15:02:20,247:INFO:Initializing create_model()
2023-05-25 15:02:20,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:02:20,247:INFO:Checking exceptions
2023-05-25 15:02:20,248:INFO:Importing libraries
2023-05-25 15:02:20,248:INFO:Copying training dataset
2023-05-25 15:02:20,322:INFO:Defining folds
2023-05-25 15:02:20,322:INFO:Declaring metric variables
2023-05-25 15:02:20,325:INFO:Importing untrained model
2023-05-25 15:02:20,330:INFO:Linear Discriminant Analysis Imported successfully
2023-05-25 15:02:20,338:INFO:Starting cross validation
2023-05-25 15:02:20,342:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 15:02:41,883:INFO:Calculating mean and std
2023-05-25 15:02:41,885:INFO:Creating metrics dataframe
2023-05-25 15:02:42,506:INFO:Uploading results into container
2023-05-25 15:02:42,506:INFO:Uploading model into container now
2023-05-25 15:02:42,507:INFO:_master_model_container: 11
2023-05-25 15:02:42,507:INFO:_display_container: 2
2023-05-25 15:02:42,507:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-25 15:02:42,507:INFO:create_model() successfully completed......................................
2023-05-25 15:02:42,576:INFO:SubProcess create_model() end ==================================
2023-05-25 15:02:42,576:INFO:Creating metrics dataframe
2023-05-25 15:02:42,588:INFO:Initializing Extra Trees Classifier
2023-05-25 15:02:42,588:INFO:Total runtime is 4.818154819806416 minutes
2023-05-25 15:02:42,592:INFO:SubProcess create_model() called ==================================
2023-05-25 15:02:42,592:INFO:Initializing create_model()
2023-05-25 15:02:42,593:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:02:42,593:INFO:Checking exceptions
2023-05-25 15:02:42,593:INFO:Importing libraries
2023-05-25 15:02:42,593:INFO:Copying training dataset
2023-05-25 15:02:42,662:INFO:Defining folds
2023-05-25 15:02:42,662:INFO:Declaring metric variables
2023-05-25 15:02:42,664:INFO:Importing untrained model
2023-05-25 15:02:42,671:INFO:Extra Trees Classifier Imported successfully
2023-05-25 15:02:42,677:INFO:Starting cross validation
2023-05-25 15:02:42,680:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 15:03:30,181:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:03:30,262:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:03:30,267:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:03:45,494:INFO:Calculating mean and std
2023-05-25 15:03:45,496:INFO:Creating metrics dataframe
2023-05-25 15:03:46,168:INFO:Uploading results into container
2023-05-25 15:03:46,170:INFO:Uploading model into container now
2023-05-25 15:03:46,170:INFO:_master_model_container: 12
2023-05-25 15:03:46,170:INFO:_display_container: 2
2023-05-25 15:03:46,171:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 15:03:46,171:INFO:create_model() successfully completed......................................
2023-05-25 15:03:46,242:INFO:SubProcess create_model() end ==================================
2023-05-25 15:03:46,242:INFO:Creating metrics dataframe
2023-05-25 15:03:46,254:INFO:Initializing Light Gradient Boosting Machine
2023-05-25 15:03:46,254:INFO:Total runtime is 5.87925595442454 minutes
2023-05-25 15:03:46,258:INFO:SubProcess create_model() called ==================================
2023-05-25 15:03:46,258:INFO:Initializing create_model()
2023-05-25 15:03:46,259:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:03:46,259:INFO:Checking exceptions
2023-05-25 15:03:46,259:INFO:Importing libraries
2023-05-25 15:03:46,259:INFO:Copying training dataset
2023-05-25 15:03:46,327:INFO:Defining folds
2023-05-25 15:03:46,327:INFO:Declaring metric variables
2023-05-25 15:03:46,331:INFO:Importing untrained model
2023-05-25 15:03:46,335:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 15:03:46,343:INFO:Starting cross validation
2023-05-25 15:03:46,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 15:04:00,371:INFO:Calculating mean and std
2023-05-25 15:04:00,372:INFO:Creating metrics dataframe
2023-05-25 15:04:01,039:INFO:Uploading results into container
2023-05-25 15:04:01,039:INFO:Uploading model into container now
2023-05-25 15:04:01,040:INFO:_master_model_container: 13
2023-05-25 15:04:01,040:INFO:_display_container: 2
2023-05-25 15:04:01,040:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 15:04:01,040:INFO:create_model() successfully completed......................................
2023-05-25 15:04:01,110:INFO:SubProcess create_model() end ==================================
2023-05-25 15:04:01,111:INFO:Creating metrics dataframe
2023-05-25 15:04:01,124:INFO:Initializing Dummy Classifier
2023-05-25 15:04:01,124:INFO:Total runtime is 6.127081954479217 minutes
2023-05-25 15:04:01,128:INFO:SubProcess create_model() called ==================================
2023-05-25 15:04:01,128:INFO:Initializing create_model()
2023-05-25 15:04:01,128:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E747F70>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:04:01,128:INFO:Checking exceptions
2023-05-25 15:04:01,128:INFO:Importing libraries
2023-05-25 15:04:01,128:INFO:Copying training dataset
2023-05-25 15:04:01,197:INFO:Defining folds
2023-05-25 15:04:01,197:INFO:Declaring metric variables
2023-05-25 15:04:01,201:INFO:Importing untrained model
2023-05-25 15:04:01,205:INFO:Dummy Classifier Imported successfully
2023-05-25 15:04:01,213:INFO:Starting cross validation
2023-05-25 15:04:01,216:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 15:04:02,950:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 15:04:03,086:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 15:04:03,095:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 15:04:03,149:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 15:04:03,152:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 15:04:03,172:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 15:04:03,219:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 15:04:03,257:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 15:04:05,845:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 15:04:05,939:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-25 15:04:08,996:INFO:Calculating mean and std
2023-05-25 15:04:08,997:INFO:Creating metrics dataframe
2023-05-25 15:04:09,622:INFO:Uploading results into container
2023-05-25 15:04:09,622:INFO:Uploading model into container now
2023-05-25 15:04:09,623:INFO:_master_model_container: 14
2023-05-25 15:04:09,623:INFO:_display_container: 2
2023-05-25 15:04:09,623:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-25 15:04:09,623:INFO:create_model() successfully completed......................................
2023-05-25 15:04:09,692:INFO:SubProcess create_model() end ==================================
2023-05-25 15:04:09,693:INFO:Creating metrics dataframe
2023-05-25 15:04:09,714:INFO:Initializing create_model()
2023-05-25 15:04:09,714:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:04:09,714:INFO:Checking exceptions
2023-05-25 15:04:09,716:INFO:Importing libraries
2023-05-25 15:04:09,717:INFO:Copying training dataset
2023-05-25 15:04:09,786:INFO:Defining folds
2023-05-25 15:04:09,786:INFO:Declaring metric variables
2023-05-25 15:04:09,786:INFO:Importing untrained model
2023-05-25 15:04:09,786:INFO:Declaring custom model
2023-05-25 15:04:09,787:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 15:04:09,789:INFO:Cross validation set to False
2023-05-25 15:04:09,789:INFO:Fitting Model
2023-05-25 15:04:12,276:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 15:04:12,276:INFO:create_model() successfully completed......................................
2023-05-25 15:04:12,350:INFO:Initializing create_model()
2023-05-25 15:04:12,350:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:04:12,350:INFO:Checking exceptions
2023-05-25 15:04:12,352:INFO:Importing libraries
2023-05-25 15:04:12,352:INFO:Copying training dataset
2023-05-25 15:04:12,421:INFO:Defining folds
2023-05-25 15:04:12,421:INFO:Declaring metric variables
2023-05-25 15:04:12,421:INFO:Importing untrained model
2023-05-25 15:04:12,421:INFO:Declaring custom model
2023-05-25 15:04:12,421:INFO:Random Forest Classifier Imported successfully
2023-05-25 15:04:12,424:INFO:Cross validation set to False
2023-05-25 15:04:12,424:INFO:Fitting Model
2023-05-25 15:04:16,780:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 15:04:16,780:INFO:create_model() successfully completed......................................
2023-05-25 15:04:16,856:INFO:Initializing create_model()
2023-05-25 15:04:16,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:04:16,857:INFO:Checking exceptions
2023-05-25 15:04:16,859:INFO:Importing libraries
2023-05-25 15:04:16,859:INFO:Copying training dataset
2023-05-25 15:04:16,928:INFO:Defining folds
2023-05-25 15:04:16,928:INFO:Declaring metric variables
2023-05-25 15:04:16,928:INFO:Importing untrained model
2023-05-25 15:04:16,928:INFO:Declaring custom model
2023-05-25 15:04:16,929:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 15:04:16,931:INFO:Cross validation set to False
2023-05-25 15:04:16,931:INFO:Fitting Model
2023-05-25 15:04:41,698:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 15:04:41,698:INFO:create_model() successfully completed......................................
2023-05-25 15:04:41,778:INFO:Initializing create_model()
2023-05-25 15:04:41,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:04:41,778:INFO:Checking exceptions
2023-05-25 15:04:41,781:INFO:Importing libraries
2023-05-25 15:04:41,781:INFO:Copying training dataset
2023-05-25 15:04:41,849:INFO:Defining folds
2023-05-25 15:04:41,849:INFO:Declaring metric variables
2023-05-25 15:04:41,849:INFO:Importing untrained model
2023-05-25 15:04:41,849:INFO:Declaring custom model
2023-05-25 15:04:41,849:INFO:Extra Trees Classifier Imported successfully
2023-05-25 15:04:41,853:INFO:Cross validation set to False
2023-05-25 15:04:41,853:INFO:Fitting Model
2023-05-25 15:04:48,803:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 15:04:48,803:INFO:create_model() successfully completed......................................
2023-05-25 15:04:48,879:INFO:Initializing create_model()
2023-05-25 15:04:48,879:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:04:48,879:INFO:Checking exceptions
2023-05-25 15:04:48,881:INFO:Importing libraries
2023-05-25 15:04:48,881:INFO:Copying training dataset
2023-05-25 15:04:48,952:INFO:Defining folds
2023-05-25 15:04:48,952:INFO:Declaring metric variables
2023-05-25 15:04:48,952:INFO:Importing untrained model
2023-05-25 15:04:48,952:INFO:Declaring custom model
2023-05-25 15:04:48,953:INFO:Ada Boost Classifier Imported successfully
2023-05-25 15:04:48,956:INFO:Cross validation set to False
2023-05-25 15:04:48,956:INFO:Fitting Model
2023-05-25 15:04:57,155:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 15:04:57,155:INFO:create_model() successfully completed......................................
2023-05-25 15:04:57,250:INFO:_master_model_container: 14
2023-05-25 15:04:57,250:INFO:_display_container: 2
2023-05-25 15:04:57,251:INFO:[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)]
2023-05-25 15:04:57,252:INFO:compare_models() successfully completed......................................
2023-05-25 15:04:57,582:INFO:Initializing predict_model()
2023-05-25 15:04:57,582:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020E11789120>)
2023-05-25 15:04:57,582:INFO:Checking exceptions
2023-05-25 15:04:57,582:INFO:Preloading libraries
2023-05-25 15:04:57,586:INFO:Set up data.
2023-05-25 15:04:57,751:INFO:Set up index.
2023-05-25 15:04:58,258:INFO:Initializing save_model()
2023-05-25 15:04:58,258:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=rf_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 15:04:58,258:INFO:Adding model into prep_pipe
2023-05-25 15:04:58,294:INFO:rf_model_file.pkl saved in current working directory
2023-05-25 15:04:58,311:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=123,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-05-25 15:04:58,311:INFO:save_model() successfully completed......................................
2023-05-25 15:04:58,453:INFO:Initializing predict_model()
2023-05-25 15:04:58,453:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020E117889D0>)
2023-05-25 15:04:58,453:INFO:Checking exceptions
2023-05-25 15:04:58,455:INFO:Preloading libraries
2023-05-25 15:04:58,457:INFO:Set up data.
2023-05-25 15:04:58,565:INFO:Set up index.
2023-05-25 15:04:59,021:INFO:Initializing save_model()
2023-05-25 15:04:59,022:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=lgbm_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 15:04:59,022:INFO:Adding model into prep_pipe
2023-05-25 15:04:59,120:INFO:lgbm_model_file.pkl saved in current working directory
2023-05-25 15:04:59,133:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 15:04:59,133:INFO:save_model() successfully completed......................................
2023-05-25 15:04:59,262:INFO:Initializing predict_model()
2023-05-25 15:04:59,262:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020E0E3B9360>)
2023-05-25 15:04:59,262:INFO:Checking exceptions
2023-05-25 15:04:59,262:INFO:Preloading libraries
2023-05-25 15:04:59,264:INFO:Set up data.
2023-05-25 15:04:59,393:INFO:Set up index.
2023-05-25 15:04:59,734:INFO:Initializing save_model()
2023-05-25 15:04:59,734:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=gbc_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 15:04:59,734:INFO:Adding model into prep_pipe
2023-05-25 15:04:59,756:INFO:gbc_model_file.pkl saved in current working directory
2023-05-25 15:04:59,766:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=123, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 15:04:59,766:INFO:save_model() successfully completed......................................
2023-05-25 15:04:59,896:INFO:Initializing predict_model()
2023-05-25 15:04:59,896:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020E11789EA0>)
2023-05-25 15:04:59,896:INFO:Checking exceptions
2023-05-25 15:04:59,896:INFO:Preloading libraries
2023-05-25 15:04:59,899:INFO:Set up data.
2023-05-25 15:05:00,011:INFO:Set up index.
2023-05-25 15:05:00,556:INFO:Initializing save_model()
2023-05-25 15:05:00,556:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), model_name=ada_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 15:05:00,556:INFO:Adding model into prep_pipe
2023-05-25 15:05:00,724:INFO:ada_model_file.pkl saved in current working directory
2023-05-25 15:05:00,734:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=123,
                                      verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 15:05:00,734:INFO:save_model() successfully completed......................................
2023-05-25 15:05:00,852:INFO:Initializing predict_model()
2023-05-25 15:05:00,852:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020E1178AF80>)
2023-05-25 15:05:00,852:INFO:Checking exceptions
2023-05-25 15:05:00,852:INFO:Preloading libraries
2023-05-25 15:05:00,856:INFO:Set up data.
2023-05-25 15:05:00,966:INFO:Set up index.
2023-05-25 15:05:02,689:INFO:Initializing save_model()
2023-05-25 15:05:02,689:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), model_name=et_model_file, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 15:05:02,689:INFO:Adding model into prep_pipe
2023-05-25 15:05:02,724:INFO:et_model_file.pkl saved in current working directory
2023-05-25 15:05:02,733:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=1.0, n_estimators=50,
                                    random_state=123))],
         verbose=False)
2023-05-25 15:05:02,733:INFO:save_model() successfully completed......................................
2023-05-25 15:05:02,897:INFO:Initializing tune_model()
2023-05-25 15:05:02,897:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=20, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>)
2023-05-25 15:05:02,898:INFO:Checking exceptions
2023-05-25 15:05:02,898:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-25 15:05:03,344:INFO:Copying training dataset
2023-05-25 15:05:03,402:INFO:Checking base model
2023-05-25 15:05:03,402:INFO:Base model : Light Gradient Boosting Machine
2023-05-25 15:05:03,409:INFO:Declaring metric variables
2023-05-25 15:05:03,413:INFO:Defining Hyperparameters
2023-05-25 15:05:03,505:INFO:Tuning with n_jobs=-1
2023-05-25 15:05:03,507:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 15:05:03,507:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 15:05:03,507:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-25 15:05:03,512:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-25 15:14:34,469:INFO:best_params: {'actual_estimator__num_leaves': 169, 'actual_estimator__learning_rate': 0.02819787899482023, 'actual_estimator__n_estimators': 219, 'actual_estimator__min_split_gain': 0.33545530702894366, 'actual_estimator__reg_alpha': 5.692120226275844e-10, 'actual_estimator__reg_lambda': 2.8695438010422684e-06, 'actual_estimator__feature_fraction': 0.9428537322514434, 'actual_estimator__bagging_fraction': 0.8322661266697796, 'actual_estimator__bagging_freq': 7, 'actual_estimator__min_child_samples': 43}
2023-05-25 15:14:34,469:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-05-25 15:14:34,470:WARNING:Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2666, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-05-25 15:14:34,470:INFO:Hyperparameter search completed
2023-05-25 15:14:34,470:INFO:SubProcess create_model() called ==================================
2023-05-25 15:14:34,471:INFO:Initializing create_model()
2023-05-25 15:14:34,471:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E6A357B20>, model_only=True, return_train_score=False, kwargs={'num_leaves': 169, 'learning_rate': 0.02819787899482023, 'n_estimators': 219, 'min_split_gain': 0.33545530702894366, 'reg_alpha': 5.692120226275844e-10, 'reg_lambda': 2.8695438010422684e-06, 'feature_fraction': 0.9428537322514434, 'bagging_fraction': 0.8322661266697796, 'bagging_freq': 7, 'min_child_samples': 43})
2023-05-25 15:14:34,471:INFO:Checking exceptions
2023-05-25 15:14:34,471:INFO:Importing libraries
2023-05-25 15:14:34,471:INFO:Copying training dataset
2023-05-25 15:14:34,560:INFO:Defining folds
2023-05-25 15:14:34,561:INFO:Declaring metric variables
2023-05-25 15:14:34,568:INFO:Importing untrained model
2023-05-25 15:14:34,568:INFO:Declaring custom model
2023-05-25 15:14:34,572:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 15:14:34,582:INFO:Starting cross validation
2023-05-25 15:14:34,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 15:14:42,974:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:14:43,064:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:14:43,254:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:14:43,254:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:14:43,258:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:14:43,356:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:14:43,435:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:14:43,465:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:14:51,276:INFO:Calculating mean and std
2023-05-25 15:14:51,277:INFO:Creating metrics dataframe
2023-05-25 15:14:51,284:INFO:Finalizing model
2023-05-25 15:14:52,317:INFO:[LightGBM] [Warning] feature_fraction is set=0.9428537322514434, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9428537322514434
2023-05-25 15:14:52,317:INFO:[LightGBM] [Warning] bagging_fraction is set=0.8322661266697796, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8322661266697796
2023-05-25 15:14:52,317:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2023-05-25 15:14:58,539:INFO:Uploading results into container
2023-05-25 15:14:58,541:INFO:Uploading model into container now
2023-05-25 15:14:58,541:INFO:_master_model_container: 15
2023-05-25 15:14:58,542:INFO:_display_container: 3
2023-05-25 15:14:58,542:INFO:LGBMClassifier(bagging_fraction=0.8322661266697796, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9428537322514434, importance_type='split',
               learning_rate=0.02819787899482023, max_depth=-1,
               min_child_samples=43, min_child_weight=0.001,
               min_split_gain=0.33545530702894366, n_estimators=219, n_jobs=-1,
               num_leaves=169, objective=None, random_state=123,
               reg_alpha=5.692120226275844e-10,
               reg_lambda=2.8695438010422684e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-05-25 15:14:58,542:INFO:create_model() successfully completed......................................
2023-05-25 15:14:58,691:INFO:SubProcess create_model() end ==================================
2023-05-25 15:14:58,691:INFO:choose_better activated
2023-05-25 15:14:58,694:INFO:SubProcess create_model() called ==================================
2023-05-25 15:14:58,695:INFO:Initializing create_model()
2023-05-25 15:14:58,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 15:14:58,695:INFO:Checking exceptions
2023-05-25 15:14:58,697:INFO:Importing libraries
2023-05-25 15:14:58,698:INFO:Copying training dataset
2023-05-25 15:14:58,784:INFO:Defining folds
2023-05-25 15:14:58,784:INFO:Declaring metric variables
2023-05-25 15:14:58,785:INFO:Importing untrained model
2023-05-25 15:14:58,785:INFO:Declaring custom model
2023-05-25 15:14:58,785:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-25 15:14:58,786:INFO:Starting cross validation
2023-05-25 15:14:58,788:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 15:15:07,374:INFO:Calculating mean and std
2023-05-25 15:15:07,375:INFO:Creating metrics dataframe
2023-05-25 15:15:07,377:INFO:Finalizing model
2023-05-25 15:15:08,709:INFO:Uploading results into container
2023-05-25 15:15:08,710:INFO:Uploading model into container now
2023-05-25 15:15:08,710:INFO:_master_model_container: 16
2023-05-25 15:15:08,710:INFO:_display_container: 4
2023-05-25 15:15:08,710:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-25 15:15:08,710:INFO:create_model() successfully completed......................................
2023-05-25 15:15:08,791:INFO:SubProcess create_model() end ==================================
2023-05-25 15:15:08,791:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7402
2023-05-25 15:15:08,792:INFO:LGBMClassifier(bagging_fraction=0.8322661266697796, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9428537322514434, importance_type='split',
               learning_rate=0.02819787899482023, max_depth=-1,
               min_child_samples=43, min_child_weight=0.001,
               min_split_gain=0.33545530702894366, n_estimators=219, n_jobs=-1,
               num_leaves=169, objective=None, random_state=123,
               reg_alpha=5.692120226275844e-10,
               reg_lambda=2.8695438010422684e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) result for Accuracy is 0.7438
2023-05-25 15:15:08,792:INFO:LGBMClassifier(bagging_fraction=0.8322661266697796, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9428537322514434, importance_type='split',
               learning_rate=0.02819787899482023, max_depth=-1,
               min_child_samples=43, min_child_weight=0.001,
               min_split_gain=0.33545530702894366, n_estimators=219, n_jobs=-1,
               num_leaves=169, objective=None, random_state=123,
               reg_alpha=5.692120226275844e-10,
               reg_lambda=2.8695438010422684e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0) is best model
2023-05-25 15:15:08,792:INFO:choose_better completed
2023-05-25 15:15:08,802:INFO:_master_model_container: 16
2023-05-25 15:15:08,803:INFO:_display_container: 3
2023-05-25 15:15:08,803:INFO:LGBMClassifier(bagging_fraction=0.8322661266697796, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9428537322514434, importance_type='split',
               learning_rate=0.02819787899482023, max_depth=-1,
               min_child_samples=43, min_child_weight=0.001,
               min_split_gain=0.33545530702894366, n_estimators=219, n_jobs=-1,
               num_leaves=169, objective=None, random_state=123,
               reg_alpha=5.692120226275844e-10,
               reg_lambda=2.8695438010422684e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2023-05-25 15:15:08,803:INFO:tune_model() successfully completed......................................
2023-05-25 15:15:09,040:INFO:Initializing save_model()
2023-05-25 15:15:09,040:INFO:save_model(model=LGBMClassifier(bagging_fraction=0.8322661266697796, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9428537322514434, importance_type='split',
               learning_rate=0.02819787899482023, max_depth=-1,
               min_child_samples=43, min_child_weight=0.001,
               min_split_gain=0.33545530702894366, n_estimators=219, n_jobs=-1,
               num_leaves=169, objective=None, random_state=123,
               reg_alpha=5.692120226275844e-10,
               reg_lambda=2.8695438010422684e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), model_name=rf_tune_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 15:15:09,040:INFO:Adding model into prep_pipe
2023-05-25 15:15:09,141:INFO:rf_tune_model.pkl saved in current working directory
2023-05-25 15:15:09,158:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                learning_rate=0.02819787899482023, max_depth=-1,
                                min_child_samples=43, min_child_weight=0.001,
                                min_split_gain=0.33545530702894366,
                                n_estimators=219, n_jobs=-1, num_leaves=169,
                                objective=None, random_state=123,
                                reg_alpha=5.692120226275844e-10,
                                reg_lambda=2.8695438010422684e-06,
                                silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-05-25 15:15:09,158:INFO:save_model() successfully completed......................................
2023-05-25 15:15:09,389:INFO:Initializing tune_model()
2023-05-25 15:15:09,390:INFO:tune_model(estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=20, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>)
2023-05-25 15:15:09,390:INFO:Checking exceptions
2023-05-25 15:15:09,390:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-25 15:15:09,489:INFO:Copying training dataset
2023-05-25 15:15:09,555:INFO:Checking base model
2023-05-25 15:15:09,555:INFO:Base model : Random Forest Classifier
2023-05-25 15:15:09,559:INFO:Declaring metric variables
2023-05-25 15:15:09,565:INFO:Defining Hyperparameters
2023-05-25 15:15:09,672:INFO:Tuning with n_jobs=-1
2023-05-25 15:15:09,672:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 15:15:09,672:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 15:15:09,675:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-05-25 15:15:09,675:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-25 15:15:09,675:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-25 15:17:36,622:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:17:39,304:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:17:40,011:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:20:12,574:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:20:19,958:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:20:22,828:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:20:24,368:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:20:45,039:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:22:08,478:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:22:39,032:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:22:58,895:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:23:00,407:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:25:33,701:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:25:39,294:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:25:40,981:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:25:44,210:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:25:46,404:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:25:46,950:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:28:23,103:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:28:24,311:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:29:07,463:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:29:37,806:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:33:23,563:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:33:31,864:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:34:25,079:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.26s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:34:36,014:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:34:46,688:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:36:36,952:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:38:47,931:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:40:57,363:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:40:57,897:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:41:00,635:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:41:17,698:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:42:54,323:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:42:56,548:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:44:08,394:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:44:58,637:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:45:08,052:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:50:10,375:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:50:10,545:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:50:12,905:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:52:48,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:52:50,302:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:54:24,317:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:55:32,496:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:56:12,752:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 6.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 15:58:08,259:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 15:59:28,668:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:00:29,324:INFO:best_params: {'actual_estimator__n_estimators': 112, 'actual_estimator__max_depth': 11, 'actual_estimator__min_impurity_decrease': 1.8342854698547546e-08, 'actual_estimator__max_features': 0.9750285720238467, 'actual_estimator__min_samples_split': 3, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__bootstrap': True, 'actual_estimator__criterion': 'gini', 'actual_estimator__class_weight': 'balanced'}
2023-05-25 16:00:29,324:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-05-25 16:00:29,324:WARNING:Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2666, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-05-25 16:00:29,325:INFO:Hyperparameter search completed
2023-05-25 16:00:29,325:INFO:SubProcess create_model() called ==================================
2023-05-25 16:00:29,326:INFO:Initializing create_model()
2023-05-25 16:00:29,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E0E3BCB20>, model_only=True, return_train_score=False, kwargs={'n_estimators': 112, 'max_depth': 11, 'min_impurity_decrease': 1.8342854698547546e-08, 'max_features': 0.9750285720238467, 'min_samples_split': 3, 'min_samples_leaf': 5, 'bootstrap': True, 'criterion': 'gini', 'class_weight': 'balanced'})
2023-05-25 16:00:29,326:INFO:Checking exceptions
2023-05-25 16:00:29,326:INFO:Importing libraries
2023-05-25 16:00:29,326:INFO:Copying training dataset
2023-05-25 16:00:29,424:INFO:Defining folds
2023-05-25 16:00:29,424:INFO:Declaring metric variables
2023-05-25 16:00:29,428:INFO:Importing untrained model
2023-05-25 16:00:29,428:INFO:Declaring custom model
2023-05-25 16:00:29,434:INFO:Random Forest Classifier Imported successfully
2023-05-25 16:00:29,446:INFO:Starting cross validation
2023-05-25 16:00:29,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 16:00:39,816:INFO:Calculating mean and std
2023-05-25 16:00:39,817:INFO:Creating metrics dataframe
2023-05-25 16:00:39,824:INFO:Finalizing model
2023-05-25 16:01:03,123:INFO:Uploading results into container
2023-05-25 16:01:03,124:INFO:Uploading model into container now
2023-05-25 16:01:03,124:INFO:_master_model_container: 17
2023-05-25 16:01:03,124:INFO:_display_container: 4
2023-05-25 16:01:03,125:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=11,
                       max_features=0.9750285720238467, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.8342854698547546e-08,
                       min_samples_leaf=5, min_samples_split=3,
                       min_weight_fraction_leaf=0.0, n_estimators=112,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2023-05-25 16:01:03,125:INFO:create_model() successfully completed......................................
2023-05-25 16:01:03,242:INFO:SubProcess create_model() end ==================================
2023-05-25 16:01:03,242:INFO:choose_better activated
2023-05-25 16:01:03,248:INFO:SubProcess create_model() called ==================================
2023-05-25 16:01:03,251:INFO:Initializing create_model()
2023-05-25 16:01:03,252:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 16:01:03,252:INFO:Checking exceptions
2023-05-25 16:01:03,255:INFO:Importing libraries
2023-05-25 16:01:03,255:INFO:Copying training dataset
2023-05-25 16:01:03,337:INFO:Defining folds
2023-05-25 16:01:03,337:INFO:Declaring metric variables
2023-05-25 16:01:03,337:INFO:Importing untrained model
2023-05-25 16:01:03,337:INFO:Declaring custom model
2023-05-25 16:01:03,337:INFO:Random Forest Classifier Imported successfully
2023-05-25 16:01:03,337:INFO:Starting cross validation
2023-05-25 16:01:03,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 16:01:29,456:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 16:01:29,964:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 16:01:30,323:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 16:01:31,637:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:01:31,638:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:01:31,784:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 16:01:31,906:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:01:32,091:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 16:01:32,109:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 16:01:32,857:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:01:33,002:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:01:33,129:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:01:33,142:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:01:33,220:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:01:48,046:INFO:Calculating mean and std
2023-05-25 16:01:48,047:INFO:Creating metrics dataframe
2023-05-25 16:01:48,049:INFO:Finalizing model
2023-05-25 16:01:49,620:INFO:Uploading results into container
2023-05-25 16:01:49,620:INFO:Uploading model into container now
2023-05-25 16:01:49,621:INFO:_master_model_container: 18
2023-05-25 16:01:49,621:INFO:_display_container: 5
2023-05-25 16:01:49,622:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 16:01:49,622:INFO:create_model() successfully completed......................................
2023-05-25 16:01:49,716:INFO:SubProcess create_model() end ==================================
2023-05-25 16:01:49,718:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.7392
2023-05-25 16:01:49,718:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight='balanced',
                       criterion='gini', max_depth=11,
                       max_features=0.9750285720238467, max_leaf_nodes=None,
                       max_samples=None,
                       min_impurity_decrease=1.8342854698547546e-08,
                       min_samples_leaf=5, min_samples_split=3,
                       min_weight_fraction_leaf=0.0, n_estimators=112,
                       n_jobs=-1, oob_score=False, random_state=123, verbose=0,
                       warm_start=False) result for Accuracy is 0.7332
2023-05-25 16:01:49,720:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False) is best model
2023-05-25 16:01:49,720:INFO:choose_better completed
2023-05-25 16:01:49,720:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-05-25 16:01:49,730:INFO:_master_model_container: 18
2023-05-25 16:01:49,730:INFO:_display_container: 4
2023-05-25 16:01:49,731:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-25 16:01:49,731:INFO:tune_model() successfully completed......................................
2023-05-25 16:01:50,675:INFO:Initializing save_model()
2023-05-25 16:01:50,675:INFO:save_model(model=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), model_name=lgbm_tune_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 16:01:50,675:INFO:Adding model into prep_pipe
2023-05-25 16:01:50,819:INFO:lgbm_tune_model.pkl saved in current working directory
2023-05-25 16:01:50,830:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,
                                        class_weight=None, criterion='gini',
                                        max_depth=None, max_features='sqrt',
                                        max_leaf_nodes=None, max_samples=None,
                                        min_impurity_decrease=0.0,
                                        min_samples_leaf=1, min_samples_split=2,
                                        min_weight_fraction_leaf=0.0,
                                        n_estimators=100, n_jobs=-1,
                                        oob_score=False, random_state=123,
                                        verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 16:01:50,830:INFO:save_model() successfully completed......................................
2023-05-25 16:01:50,998:INFO:Initializing tune_model()
2023-05-25 16:01:50,998:INFO:tune_model(estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=None, round=4, n_iter=20, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>)
2023-05-25 16:01:50,998:INFO:Checking exceptions
2023-05-25 16:01:50,999:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-25 16:01:51,057:INFO:Copying training dataset
2023-05-25 16:01:51,125:INFO:Checking base model
2023-05-25 16:01:51,125:INFO:Base model : Gradient Boosting Classifier
2023-05-25 16:01:51,128:INFO:Declaring metric variables
2023-05-25 16:01:51,132:INFO:Defining Hyperparameters
2023-05-25 16:01:51,228:INFO:Tuning with n_jobs=-1
2023-05-25 16:01:51,229:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 16:01:51,229:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 16:01:51,230:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-25 16:01:51,230:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-25 16:49:35,846:INFO:best_params: {'actual_estimator__n_estimators': 285, 'actual_estimator__learning_rate': 0.04203458177549724, 'actual_estimator__subsample': 0.8229855461596121, 'actual_estimator__min_samples_split': 4, 'actual_estimator__min_samples_leaf': 1, 'actual_estimator__max_depth': 11, 'actual_estimator__min_impurity_decrease': 5.894982764878127e-09, 'actual_estimator__max_features': 0.7182933122785164}
2023-05-25 16:49:35,847:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-05-25 16:49:35,857:WARNING:Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2666, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-05-25 16:49:35,858:INFO:Hyperparameter search completed
2023-05-25 16:49:35,858:INFO:SubProcess create_model() called ==================================
2023-05-25 16:49:35,858:INFO:Initializing create_model()
2023-05-25 16:49:35,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E6A22AFE0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 285, 'learning_rate': 0.04203458177549724, 'subsample': 0.8229855461596121, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': 11, 'min_impurity_decrease': 5.894982764878127e-09, 'max_features': 0.7182933122785164})
2023-05-25 16:49:35,859:INFO:Checking exceptions
2023-05-25 16:49:35,859:INFO:Importing libraries
2023-05-25 16:49:35,859:INFO:Copying training dataset
2023-05-25 16:49:35,962:INFO:Defining folds
2023-05-25 16:49:35,962:INFO:Declaring metric variables
2023-05-25 16:49:35,966:INFO:Importing untrained model
2023-05-25 16:49:35,966:INFO:Declaring custom model
2023-05-25 16:49:35,972:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 16:49:35,979:INFO:Starting cross validation
2023-05-25 16:49:35,982:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 16:49:52,935:INFO:Calculating mean and std
2023-05-25 16:49:52,936:INFO:Creating metrics dataframe
2023-05-25 16:49:52,945:INFO:Finalizing model
2023-05-25 16:52:51,975:INFO:Uploading results into container
2023-05-25 16:52:51,976:INFO:Uploading model into container now
2023-05-25 16:52:51,977:INFO:_master_model_container: 19
2023-05-25 16:52:51,978:INFO:_display_container: 5
2023-05-25 16:52:51,979:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.04203458177549724, loss='log_loss',
                           max_depth=11, max_features=0.7182933122785164,
                           max_leaf_nodes=None,
                           min_impurity_decrease=5.894982764878127e-09,
                           min_samples_leaf=1, min_samples_split=4,
                           min_weight_fraction_leaf=0.0, n_estimators=285,
                           n_iter_no_change=None, random_state=123,
                           subsample=0.8229855461596121, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 16:52:51,979:INFO:create_model() successfully completed......................................
2023-05-25 16:52:52,077:INFO:SubProcess create_model() end ==================================
2023-05-25 16:52:52,077:INFO:choose_better activated
2023-05-25 16:52:52,081:INFO:SubProcess create_model() called ==================================
2023-05-25 16:52:52,082:INFO:Initializing create_model()
2023-05-25 16:52:52,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 16:52:52,082:INFO:Checking exceptions
2023-05-25 16:52:52,084:INFO:Importing libraries
2023-05-25 16:52:52,084:INFO:Copying training dataset
2023-05-25 16:52:52,156:INFO:Defining folds
2023-05-25 16:52:52,156:INFO:Declaring metric variables
2023-05-25 16:52:52,156:INFO:Importing untrained model
2023-05-25 16:52:52,156:INFO:Declaring custom model
2023-05-25 16:52:52,156:INFO:Gradient Boosting Classifier Imported successfully
2023-05-25 16:52:52,156:INFO:Starting cross validation
2023-05-25 16:52:52,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 16:54:05,018:INFO:Calculating mean and std
2023-05-25 16:54:05,019:INFO:Creating metrics dataframe
2023-05-25 16:54:05,020:INFO:Finalizing model
2023-05-25 16:54:30,936:INFO:Uploading results into container
2023-05-25 16:54:30,937:INFO:Uploading model into container now
2023-05-25 16:54:30,937:INFO:_master_model_container: 20
2023-05-25 16:54:30,937:INFO:_display_container: 6
2023-05-25 16:54:30,937:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 16:54:30,938:INFO:create_model() successfully completed......................................
2023-05-25 16:54:31,024:INFO:SubProcess create_model() end ==================================
2023-05-25 16:54:31,024:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7307
2023-05-25 16:54:31,025:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.04203458177549724, loss='log_loss',
                           max_depth=11, max_features=0.7182933122785164,
                           max_leaf_nodes=None,
                           min_impurity_decrease=5.894982764878127e-09,
                           min_samples_leaf=1, min_samples_split=4,
                           min_weight_fraction_leaf=0.0, n_estimators=285,
                           n_iter_no_change=None, random_state=123,
                           subsample=0.8229855461596121, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) result for Accuracy is 0.7446
2023-05-25 16:54:31,025:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.04203458177549724, loss='log_loss',
                           max_depth=11, max_features=0.7182933122785164,
                           max_leaf_nodes=None,
                           min_impurity_decrease=5.894982764878127e-09,
                           min_samples_leaf=1, min_samples_split=4,
                           min_weight_fraction_leaf=0.0, n_estimators=285,
                           n_iter_no_change=None, random_state=123,
                           subsample=0.8229855461596121, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False) is best model
2023-05-25 16:54:31,025:INFO:choose_better completed
2023-05-25 16:54:31,037:INFO:_master_model_container: 20
2023-05-25 16:54:31,037:INFO:_display_container: 5
2023-05-25 16:54:31,038:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.04203458177549724, loss='log_loss',
                           max_depth=11, max_features=0.7182933122785164,
                           max_leaf_nodes=None,
                           min_impurity_decrease=5.894982764878127e-09,
                           min_samples_leaf=1, min_samples_split=4,
                           min_weight_fraction_leaf=0.0, n_estimators=285,
                           n_iter_no_change=None, random_state=123,
                           subsample=0.8229855461596121, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-25 16:54:31,038:INFO:tune_model() successfully completed......................................
2023-05-25 16:54:32,043:INFO:Initializing save_model()
2023-05-25 16:54:32,044:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.04203458177549724, loss='log_loss',
                           max_depth=11, max_features=0.7182933122785164,
                           max_leaf_nodes=None,
                           min_impurity_decrease=5.894982764878127e-09,
                           min_samples_leaf=1, min_samples_split=4,
                           min_weight_fraction_leaf=0.0, n_estimators=285,
                           n_iter_no_change=None, random_state=123,
                           subsample=0.8229855461596121, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=gbc_tune_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 16:54:32,045:INFO:Adding model into prep_pipe
2023-05-25 16:54:32,120:INFO:gbc_tune_model.pkl saved in current working directory
2023-05-25 16:54:32,134:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                            loss='log_loss', max_depth=11,
                                            max_features=0.7182933122785164,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=5.894982764878127e-09,
                                            min_samples_leaf=1,
                                            min_samples_split=4,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=285,
                                            n_iter_no_change=None,
                                            random_state=123,
                                            subsample=0.8229855461596121,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 16:54:32,134:INFO:save_model() successfully completed......................................
2023-05-25 16:54:32,329:INFO:Initializing tune_model()
2023-05-25 16:54:32,329:INFO:tune_model(estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=None, round=4, n_iter=20, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>)
2023-05-25 16:54:32,329:INFO:Checking exceptions
2023-05-25 16:54:32,329:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-25 16:54:32,383:INFO:Copying training dataset
2023-05-25 16:54:32,504:INFO:Checking base model
2023-05-25 16:54:32,505:INFO:Base model : Extra Trees Classifier
2023-05-25 16:54:32,511:INFO:Declaring metric variables
2023-05-25 16:54:32,515:INFO:Defining Hyperparameters
2023-05-25 16:54:32,618:INFO:Tuning with n_jobs=-1
2023-05-25 16:54:32,618:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 16:54:32,618:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 16:54:32,619:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\distributions.py:535: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains {} which is of type dict.
  warnings.warn(message)

2023-05-25 16:54:32,619:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-25 16:54:32,620:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-25 16:56:10,512:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:56:43,233:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:56:43,243:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:57:04,682:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 16:57:55,471:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:00:38,694:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:00:38,704:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:02:02,300:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:02:33,365:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:04:57,278:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:07:18,578:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:10:00,161:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:11:16,039:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:11:26,382:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:13:06,423:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:13:19,356:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:13:21,303:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:14:51,908:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:14:53,087:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:15:18,858:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:17:16,279:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:17:17,487:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:17:53,386:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:18:01,858:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:20:05,942:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:20:07,339:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:20:08,237:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:20:08,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:20:14,750:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:20:14,890:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:20:22,650:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:20:24,469:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:20:24,857:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:20:25,886:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:22:43,053:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:22:55,382:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:23:03,922:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:25:20,332:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:25:20,348:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:25:21,382:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:27:42,501:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:27:42,763:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:27:43,826:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:29:29,201:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:29:30,836:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:29:50,484:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:29:51,848:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:29:59,565:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:32:18,367:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:32:54,827:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:32:59,549:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:33:00,968:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:34:57,404:INFO:best_params: {'actual_estimator__n_estimators': 183, 'actual_estimator__max_depth': 11, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 3, 'actual_estimator__max_features': 0.7881588152226755, 'actual_estimator__min_impurity_decrease': 2.8148343303116575e-07, 'actual_estimator__criterion': 'entropy', 'actual_estimator__bootstrap': False, 'actual_estimator__class_weight': 'balanced'}
2023-05-25 17:34:57,404:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-05-25 17:34:57,416:WARNING:Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2666, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-05-25 17:34:57,416:INFO:Hyperparameter search completed
2023-05-25 17:34:57,417:INFO:SubProcess create_model() called ==================================
2023-05-25 17:34:57,417:INFO:Initializing create_model()
2023-05-25 17:34:57,417:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E3CB96590>, model_only=True, return_train_score=False, kwargs={'n_estimators': 183, 'max_depth': 11, 'min_samples_split': 9, 'min_samples_leaf': 3, 'max_features': 0.7881588152226755, 'min_impurity_decrease': 2.8148343303116575e-07, 'criterion': 'entropy', 'bootstrap': False, 'class_weight': 'balanced'})
2023-05-25 17:34:57,417:INFO:Checking exceptions
2023-05-25 17:34:57,417:INFO:Importing libraries
2023-05-25 17:34:57,417:INFO:Copying training dataset
2023-05-25 17:34:57,522:INFO:Defining folds
2023-05-25 17:34:57,523:INFO:Declaring metric variables
2023-05-25 17:34:57,529:INFO:Importing untrained model
2023-05-25 17:34:57,529:INFO:Declaring custom model
2023-05-25 17:34:57,533:INFO:Extra Trees Classifier Imported successfully
2023-05-25 17:34:57,541:INFO:Starting cross validation
2023-05-25 17:34:57,545:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 17:35:00,134:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:35:00,291:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:35:00,935:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:35:08,907:INFO:Calculating mean and std
2023-05-25 17:35:08,908:INFO:Creating metrics dataframe
2023-05-25 17:35:08,915:INFO:Finalizing model
2023-05-25 17:35:43,585:INFO:Uploading results into container
2023-05-25 17:35:43,586:INFO:Uploading model into container now
2023-05-25 17:35:43,586:INFO:_master_model_container: 21
2023-05-25 17:35:43,586:INFO:_display_container: 6
2023-05-25 17:35:43,587:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=11,
                     max_features=0.7881588152226755, max_leaf_nodes=None,
                     max_samples=None,
                     min_impurity_decrease=2.8148343303116575e-07,
                     min_samples_leaf=3, min_samples_split=9,
                     min_weight_fraction_leaf=0.0, n_estimators=183, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2023-05-25 17:35:43,587:INFO:create_model() successfully completed......................................
2023-05-25 17:35:43,689:INFO:SubProcess create_model() end ==================================
2023-05-25 17:35:43,689:INFO:choose_better activated
2023-05-25 17:35:43,695:INFO:SubProcess create_model() called ==================================
2023-05-25 17:35:43,695:INFO:Initializing create_model()
2023-05-25 17:35:43,696:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 17:35:43,696:INFO:Checking exceptions
2023-05-25 17:35:43,697:INFO:Importing libraries
2023-05-25 17:35:43,697:INFO:Copying training dataset
2023-05-25 17:35:43,773:INFO:Defining folds
2023-05-25 17:35:43,773:INFO:Declaring metric variables
2023-05-25 17:35:43,773:INFO:Importing untrained model
2023-05-25 17:35:43,773:INFO:Declaring custom model
2023-05-25 17:35:43,773:INFO:Extra Trees Classifier Imported successfully
2023-05-25 17:35:43,774:INFO:Starting cross validation
2023-05-25 17:35:43,777:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 17:36:30,313:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:36:31,807:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:36:32,212:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:36:33,300:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:36:34,003:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:36:34,353:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:36:34,357:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:36:34,430:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:36:45,798:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 17:36:46,901:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 17:36:52,210:INFO:Calculating mean and std
2023-05-25 17:36:52,211:INFO:Creating metrics dataframe
2023-05-25 17:36:52,212:INFO:Finalizing model
2023-05-25 17:37:00,007:INFO:Uploading results into container
2023-05-25 17:37:00,007:INFO:Uploading model into container now
2023-05-25 17:37:00,008:INFO:_master_model_container: 22
2023-05-25 17:37:00,008:INFO:_display_container: 7
2023-05-25 17:37:00,008:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 17:37:00,008:INFO:create_model() successfully completed......................................
2023-05-25 17:37:00,090:INFO:SubProcess create_model() end ==================================
2023-05-25 17:37:00,094:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False) result for Accuracy is 0.7144
2023-05-25 17:37:00,094:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight='balanced',
                     criterion='entropy', max_depth=11,
                     max_features=0.7881588152226755, max_leaf_nodes=None,
                     max_samples=None,
                     min_impurity_decrease=2.8148343303116575e-07,
                     min_samples_leaf=3, min_samples_split=9,
                     min_weight_fraction_leaf=0.0, n_estimators=183, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False) result for Accuracy is 0.689
2023-05-25 17:37:00,095:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False) is best model
2023-05-25 17:37:00,095:INFO:choose_better completed
2023-05-25 17:37:00,095:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-05-25 17:37:00,106:INFO:_master_model_container: 22
2023-05-25 17:37:00,106:INFO:_display_container: 6
2023-05-25 17:37:00,107:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-25 17:37:00,107:INFO:tune_model() successfully completed......................................
2023-05-25 17:37:01,035:INFO:Initializing save_model()
2023-05-25 17:37:01,035:INFO:save_model(model=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False), model_name=ada_tune_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 17:37:01,035:INFO:Adding model into prep_pipe
2023-05-25 17:37:01,238:INFO:ada_tune_model.pkl saved in current working directory
2023-05-25 17:37:01,251:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                 ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0,
                                      class_weight=None, criterion='gini',
                                      max_depth=None, max_features='sqrt',
                                      max_leaf_nodes=None, max_samples=None,
                                      min_impurity_decrease=0.0,
                                      min_samples_leaf=1, min_samples_split=2,
                                      min_weight_fraction_leaf=0.0,
                                      n_estimators=100, n_jobs=-1,
                                      oob_score=False, random_state=123,
                                      verbose=0, warm_start=False))],
         verbose=False)
2023-05-25 17:37:01,251:INFO:save_model() successfully completed......................................
2023-05-25 17:37:01,463:INFO:Initializing tune_model()
2023-05-25 17:37:01,463:INFO:tune_model(estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=None, round=4, n_iter=20, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=optuna, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>)
2023-05-25 17:37:01,463:INFO:Checking exceptions
2023-05-25 17:37:01,463:INFO:Soft dependency imported: optuna: 3.1.1
2023-05-25 17:37:01,517:INFO:Copying training dataset
2023-05-25 17:37:01,584:INFO:Checking base model
2023-05-25 17:37:01,585:INFO:Base model : Ada Boost Classifier
2023-05-25 17:37:01,588:INFO:Declaring metric variables
2023-05-25 17:37:01,593:INFO:Defining Hyperparameters
2023-05-25 17:37:01,687:INFO:Tuning with n_jobs=-1
2023-05-25 17:37:01,687:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:282: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 17:37:01,687:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\optuna\samplers\_tpe\sampler.py:301: ExperimentalWarning: ``constant_liar`` option is an experimental feature. The interface can change in the future.
  warnings.warn(

2023-05-25 17:37:01,688:INFO:Initializing optuna.integration.OptunaSearchCV
2023-05-25 17:37:01,688:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:2439: ExperimentalWarning: OptunaSearchCV is experimental (supported from v0.17.0). The interface can change in the future.
  model_grid = optuna.integration.OptunaSearchCV(  # type: ignore

2023-05-25 18:06:27,045:INFO:best_params: {'actual_estimator__n_estimators': 131, 'actual_estimator__learning_rate': 0.4260735210411416, 'actual_estimator__algorithm': 'SAMME.R'}
2023-05-25 18:06:27,045:WARNING:Couldn't get cv_results from model_grid. Exception:
2023-05-25 18:06:27,045:WARNING:Traceback (most recent call last):
  File "c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 2666, in tune_model
    cv_results = model_grid.cv_results_
AttributeError: 'OptunaSearchCV' object has no attribute 'cv_results_'

2023-05-25 18:06:27,045:INFO:Hyperparameter search completed
2023-05-25 18:06:27,045:INFO:SubProcess create_model() called ==================================
2023-05-25 18:06:27,045:INFO:Initializing create_model()
2023-05-25 18:06:27,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E304EEDD0>, model_only=True, return_train_score=False, kwargs={'n_estimators': 131, 'learning_rate': 0.4260735210411416, 'algorithm': 'SAMME.R'})
2023-05-25 18:06:27,045:INFO:Checking exceptions
2023-05-25 18:06:27,045:INFO:Importing libraries
2023-05-25 18:06:27,045:INFO:Copying training dataset
2023-05-25 18:06:27,172:INFO:Defining folds
2023-05-25 18:06:27,172:INFO:Declaring metric variables
2023-05-25 18:06:27,172:INFO:Importing untrained model
2023-05-25 18:06:27,172:INFO:Declaring custom model
2023-05-25 18:06:27,172:INFO:Ada Boost Classifier Imported successfully
2023-05-25 18:06:27,188:INFO:Starting cross validation
2023-05-25 18:06:27,188:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 18:06:46,130:INFO:Calculating mean and std
2023-05-25 18:06:46,130:INFO:Creating metrics dataframe
2023-05-25 18:06:46,130:INFO:Finalizing model
2023-05-25 18:07:06,609:INFO:Uploading results into container
2023-05-25 18:07:06,611:INFO:Uploading model into container now
2023-05-25 18:07:06,612:INFO:_master_model_container: 23
2023-05-25 18:07:06,613:INFO:_display_container: 7
2023-05-25 18:07:06,614:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.4260735210411416,
                   n_estimators=131, random_state=123)
2023-05-25 18:07:06,614:INFO:create_model() successfully completed......................................
2023-05-25 18:07:06,721:INFO:SubProcess create_model() end ==================================
2023-05-25 18:07:06,721:INFO:choose_better activated
2023-05-25 18:07:06,725:INFO:SubProcess create_model() called ==================================
2023-05-25 18:07:06,725:INFO:Initializing create_model()
2023-05-25 18:07:06,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-25 18:07:06,725:INFO:Checking exceptions
2023-05-25 18:07:06,730:INFO:Importing libraries
2023-05-25 18:07:06,731:INFO:Copying training dataset
2023-05-25 18:07:06,814:INFO:Defining folds
2023-05-25 18:07:06,814:INFO:Declaring metric variables
2023-05-25 18:07:06,814:INFO:Importing untrained model
2023-05-25 18:07:06,814:INFO:Declaring custom model
2023-05-25 18:07:06,815:INFO:Ada Boost Classifier Imported successfully
2023-05-25 18:07:06,815:INFO:Starting cross validation
2023-05-25 18:07:06,818:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 18:07:37,209:INFO:Calculating mean and std
2023-05-25 18:07:37,210:INFO:Creating metrics dataframe
2023-05-25 18:07:37,212:INFO:Finalizing model
2023-05-25 18:07:45,465:INFO:Uploading results into container
2023-05-25 18:07:45,466:INFO:Uploading model into container now
2023-05-25 18:07:45,466:INFO:_master_model_container: 24
2023-05-25 18:07:45,467:INFO:_display_container: 8
2023-05-25 18:07:45,467:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-25 18:07:45,467:INFO:create_model() successfully completed......................................
2023-05-25 18:07:45,551:INFO:SubProcess create_model() end ==================================
2023-05-25 18:07:45,551:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123) result for Accuracy is 0.7137
2023-05-25 18:07:45,552:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.4260735210411416,
                   n_estimators=131, random_state=123) result for Accuracy is 0.721
2023-05-25 18:07:45,552:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.4260735210411416,
                   n_estimators=131, random_state=123) is best model
2023-05-25 18:07:45,552:INFO:choose_better completed
2023-05-25 18:07:45,563:INFO:_master_model_container: 24
2023-05-25 18:07:45,564:INFO:_display_container: 7
2023-05-25 18:07:45,564:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.4260735210411416,
                   n_estimators=131, random_state=123)
2023-05-25 18:07:45,564:INFO:tune_model() successfully completed......................................
2023-05-25 18:07:47,719:INFO:Initializing save_model()
2023-05-25 18:07:47,719:INFO:save_model(model=AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.4260735210411416,
                   n_estimators=131, random_state=123), model_name=et_tune_model, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('balance',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=FixImbalancer(estimator=SMOTE(k_neighbors=5,
                                                                              n_jobs=None,
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-05-25 18:07:47,720:INFO:Adding model into prep_pipe
2023-05-25 18:07:47,781:INFO:et_tune_model.pkl saved in current working directory
2023-05-25 18:07:47,790:INFO:Pipeline(memory=FastMemory(location=C:\Users\NT550-~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['24_Hour_Peak', 'All_time_peak',
                                             'average_forever',
                                             'average_2weeks', 'median_forever',
                                             'median_2weeks...
                                                                              random_state=None,
                                                                              sampling_strategy='auto')))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+'))),
                ('trained_model',
                 AdaBoostClassifier(algorithm='SAMME.R',
                                    base_estimator='deprecated', estimator=None,
                                    learning_rate=0.4260735210411416,
                                    n_estimators=131, random_state=123))],
         verbose=False)
2023-05-25 18:07:47,790:INFO:save_model() successfully completed......................................
2023-05-25 18:24:20,055:INFO:Initializing blend_models()
2023-05-25 18:24:20,055:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator_list=[LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-05-25 18:24:20,055:INFO:Checking exceptions
2023-05-25 18:24:20,119:INFO:Importing libraries
2023-05-25 18:24:20,119:INFO:Copying training dataset
2023-05-25 18:24:20,135:INFO:Getting model names
2023-05-25 18:24:20,135:INFO:SubProcess create_model() called ==================================
2023-05-25 18:24:20,166:INFO:Initializing create_model()
2023-05-25 18:24:20,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             importance_type='split',
                                             learning_rate=0.1, max_depth=-1,
                                             min_child_samples=20,
                                             min_child_weight=0.001,
                                             min_split_gain=0.0,
                                             n_estimators=100, n_jobs=-1,
                                             num_leaves=31, objective=None,
                                             random_state=123, reg_alpha=0.0,
                                             reg_lambd...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=123, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E6A2285B0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 18:24:20,166:INFO:Checking exceptions
2023-05-25 18:24:20,166:INFO:Importing libraries
2023-05-25 18:24:20,166:INFO:Copying training dataset
2023-05-25 18:24:20,293:INFO:Defining folds
2023-05-25 18:24:20,293:INFO:Declaring metric variables
2023-05-25 18:24:20,313:INFO:Importing untrained model
2023-05-25 18:24:20,313:INFO:Declaring custom model
2023-05-25 18:24:20,324:INFO:Voting Classifier Imported successfully
2023-05-25 18:24:20,340:INFO:Starting cross validation
2023-05-25 18:24:20,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 18:26:43,194:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:26:44,212:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:26:44,427:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:26:44,465:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:26:44,467:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:26:44,523:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:26:44,654:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:26:44,714:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:26:44,934:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:26:46,163:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:26:46,400:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:26:46,409:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:26:46,416:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:26:46,764:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:26:46,813:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:26:46,823:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:27:24,827:INFO:Initializing blend_models()
2023-05-25 18:27:24,828:INFO:blend_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator_list=[LGBMClassifier(bagging_fraction=0.8322661266697796, bagging_freq=7,
               boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               feature_fraction=0.9428537322514434, importance_type='split',
               learning_rate=0.02819787899482023, max_depth=-1,
               min_child_samples=43, min_child_weight=0.001,
               min_split_gain=0.33545530702894366, n_estimators=219, n_jobs=-1,
               num_leaves=169, objective=None, random_state=123,
               reg_alpha=5.692120226275844e-10,
               reg_lambda=2.8695438010422684e-06, silent='warn', subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False), GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.04203458177549724, loss='log_loss',
                           max_depth=11, max_features=0.7182933122785164,
                           max_leaf_nodes=None,
                           min_impurity_decrease=5.894982764878127e-09,
                           min_samples_leaf=1, min_samples_split=4,
                           min_weight_fraction_leaf=0.0, n_estimators=285,
                           n_iter_no_change=None, random_state=123,
                           subsample=0.8229855461596121, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=0.4260735210411416,
                   n_estimators=131, random_state=123), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)], fold=None, round=4, choose_better=False, optimize=Accuracy, method=auto, weights=None, fit_kwargs=None, groups=None, probability_threshold=None, verbose=True, return_train_score=False)
2023-05-25 18:27:24,828:INFO:Checking exceptions
2023-05-25 18:27:24,868:INFO:Importing libraries
2023-05-25 18:27:24,868:INFO:Copying training dataset
2023-05-25 18:27:24,868:INFO:Getting model names
2023-05-25 18:27:24,887:INFO:SubProcess create_model() called ==================================
2023-05-25 18:27:24,895:INFO:Initializing create_model()
2023-05-25 18:27:24,895:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020E0FE82AA0>, estimator=VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.8322661266697796,
                                             bagging_freq=7,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.9428537322514434,
                                             importance_type='split',
                                             learning_rate=0.02819787899482023,
                                             max_depth=-1, min_child_samples=43,
                                             min_child_weight=0.001,
                                             min_split_ga...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=123, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000020E1195EDA0>, model_only=True, return_train_score=False, kwargs={})
2023-05-25 18:27:24,895:INFO:Checking exceptions
2023-05-25 18:27:24,895:INFO:Importing libraries
2023-05-25 18:27:24,895:INFO:Copying training dataset
2023-05-25 18:27:25,037:INFO:Defining folds
2023-05-25 18:27:25,037:INFO:Declaring metric variables
2023-05-25 18:27:25,047:INFO:Importing untrained model
2023-05-25 18:27:25,047:INFO:Declaring custom model
2023-05-25 18:27:25,064:INFO:Voting Classifier Imported successfully
2023-05-25 18:27:25,073:INFO:Starting cross validation
2023-05-25 18:27:25,076:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-25 18:35:48,670:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:35:51,348:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:35:51,895:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:35:51,918:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:35:52,053:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:35:53,015:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:35:53,141:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:35:54,407:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:35:54,963:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:35:55,049:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:35:55,202:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:35:56,154:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:35:56,278:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:35:58,460:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:36:05,346:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 3.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:36:09,792:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 2.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-25 18:39:27,641:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:39:28,568:WARNING:c:\Users\NT550-052\anaconda3\envs\tmp\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-05-25 18:39:31,472:INFO:Calculating mean and std
2023-05-25 18:39:31,474:INFO:Creating metrics dataframe
2023-05-25 18:39:31,479:INFO:Finalizing model
2023-05-25 18:42:47,939:INFO:Uploading results into container
2023-05-25 18:42:47,940:INFO:Uploading model into container now
2023-05-25 18:42:47,941:INFO:_master_model_container: 25
2023-05-25 18:42:47,941:INFO:_display_container: 8
2023-05-25 18:42:47,948:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.8322661266697796,
                                             bagging_freq=7,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.9428537322514434,
                                             importance_type='split',
                                             learning_rate=0.02819787899482023,
                                             max_depth=-1, min_child_samples=43,
                                             min_child_weight=0.001,
                                             min_split_ga...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=123, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-05-25 18:42:47,948:INFO:create_model() successfully completed......................................
2023-05-25 18:42:48,057:INFO:SubProcess create_model() end ==================================
2023-05-25 18:42:48,067:INFO:_master_model_container: 25
2023-05-25 18:42:48,068:INFO:_display_container: 8
2023-05-25 18:42:48,074:INFO:VotingClassifier(estimators=[('Light Gradient Boosting Machine',
                              LGBMClassifier(bagging_fraction=0.8322661266697796,
                                             bagging_freq=7,
                                             boosting_type='gbdt',
                                             class_weight=None,
                                             colsample_bytree=1.0,
                                             feature_fraction=0.9428537322514434,
                                             importance_type='split',
                                             learning_rate=0.02819787899482023,
                                             max_depth=-1, min_child_samples=43,
                                             min_child_weight=0.001,
                                             min_split_ga...
                                                   class_weight=None,
                                                   criterion='gini',
                                                   max_depth=None,
                                                   max_features='sqrt',
                                                   max_leaf_nodes=None,
                                                   max_samples=None,
                                                   min_impurity_decrease=0.0,
                                                   min_samples_leaf=1,
                                                   min_samples_split=2,
                                                   min_weight_fraction_leaf=0.0,
                                                   n_estimators=100, n_jobs=-1,
                                                   oob_score=False,
                                                   random_state=123, verbose=0,
                                                   warm_start=False))],
                 flatten_transform=True, n_jobs=-1, verbose=False,
                 voting='soft', weights=None)
2023-05-25 18:42:48,074:INFO:blend_models() successfully completed......................................
